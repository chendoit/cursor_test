"""
Top Traders Unplugged æ’­å®¢çˆ¬èŸ²
- æŠ“å–æœ€æ–°çš„ 5 é›†æ’­å®¢
- ç¯©é¸ç‰¹å®šç³»åˆ—ï¼ˆGM, UGOï¼‰æˆ–è¬›è€…ï¼ˆCem Karsanï¼‰
- ä½¿ç”¨ Async Playwright æå‡æ€§èƒ½
- MongoDB å„²å­˜ã€OpenAI ç¿»è­¯ã€Gmail éƒµä»¶ã€GitHub åœ–åºŠ
"""

import os
import json
import logging
import hashlib
import asyncio
from datetime import datetime
from playwright.async_api import async_playwright
import time
import argparse
from pymongo import MongoClient
from openai import OpenAI
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import traceback
import requests
from github import Github
from io import BytesIO
import base64
import re


# ===== Kaggle & Local ç’°å¢ƒå…¼å®¹ =====
def get_secret(key: str) -> str:
    """
    å–å¾—ç’°å¢ƒè®Šæ•¸æˆ– Kaggle Secretã€‚
    åœ¨æœ¬åœ°ç«¯ä½¿ç”¨ .envï¼Œåœ¨ Kaggle ä½¿ç”¨ UserSecretsClientã€‚
    """
    try:
        # å˜—è©¦åœ¨ Kaggle ç’°å¢ƒè¼‰å…¥
        from kaggle_secrets import UserSecretsClient
        user_secrets = UserSecretsClient()
        secret = user_secrets.get_secret(key)
        logger.debug(f"âœ“ å¾ Kaggle Secrets è¼‰å…¥: {key}")
        return secret
    except Exception:
        # é Kaggle æˆ–æœªè¨­å®š kaggle_secrets
        from dotenv import load_dotenv
        load_dotenv()
        value = os.getenv(key)
        logger.debug(f"âœ“ å¾ .env è¼‰å…¥: {key}")
        return value


def is_kaggle_environment():
    """æª¢æ¸¬æ˜¯å¦åœ¨ Kaggle ç’°å¢ƒ"""
    return os.path.exists('/kaggle/working')


async def setup_playwright_in_kaggle():
    """åœ¨ Kaggle ç’°å¢ƒä¸­è¨­ç½® Playwright"""
    if is_kaggle_environment():
        logger.info("æª¢æ¸¬åˆ° Kaggle ç’°å¢ƒï¼Œå®‰è£ Playwright ç€è¦½å™¨...")
        try:
            import subprocess
            result = subprocess.run(
                ['playwright', 'install', 'chromium'],
                capture_output=True,
                text=True,
                check=True
            )
            logger.info("âœ“ Playwright Chromium å·²å®‰è£")
            
            # å®‰è£ç³»çµ±ä¾è³´
            result = subprocess.run(
                ['playwright', 'install-deps', 'chromium'],
                capture_output=True,
                text=True,
                check=True
            )
            logger.info("âœ“ ç³»çµ±ä¾è³´å·²å®‰è£")
        except Exception as e:
            logger.warning(f"Playwright å®‰è£è­¦å‘Š: {e}")
# ===== çµæŸç’°å¢ƒå…¼å®¹å€åŸŸ =====


# é…ç½® logging
def setup_logging():
    """é…ç½®æ—¥èªŒç³»çµ± - ä¸€å¤©ä¸€å€‹æ—¥èªŒæ–‡ä»¶"""
    log_filename = f'top_trader_scraper_{datetime.now().strftime("%Y%m%d")}.log'
    
    # å‰µå»º logger
    logger = logging.getLogger('TopTraderScraper')
    logger.setLevel(logging.DEBUG)
    
    # æ¸…é™¤å·²æœ‰çš„ handlers
    logger.handlers.clear()
    
    # æ–‡ä»¶ handlerï¼ˆè©³ç´°æ—¥èªŒï¼‰- ä½¿ç”¨ append æ¨¡å¼
    file_handler = logging.FileHandler(log_filename, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    
    # æ§åˆ¶å° handlerï¼ˆç°¡åŒ–æ—¥èªŒï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    
    # æ·»åŠ  handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger, log_filename


# å‰µå»ºå…¨å±€ logger
logger, log_file = setup_logging()


# ç³»åˆ—é…ç½®
SERIES_CONFIG = {
    'gm': {
        'name': 'Global Macro',
        'name_zh': 'å…¨çƒå®è§€',
        'emoji': 'ğŸŒ',
        'prefix': 'gm_'
    },
    # 'ugo': {
    #     'name': 'U Got Options',
    #     'name_zh': 'æœŸæ¬Šè§£æ',
    #     'emoji': 'ğŸ“ˆ',
    #     'prefix': 'ugo_'
    # }
}

# é—œæ³¨çš„è¬›è€…ï¼ˆæ”¯æŒå…¨åæˆ–å§“æ°åŒ¹é…ï¼‰
FEATURED_SPEAKERS = {
    # 'Cem Karsan': ['cem karsan', 'karsan', 'cem'],  # åŒ¹é…å…¨åã€å§“æ°æˆ–åå­—
    # 'Cem Karsan': ['cem karsan'],  # åŒ¹é…å…¨åã€å§“æ°æˆ–åå­—
    'Alan Dunne': ['alan dunne'],
    # å¯ä»¥åœ¨é€™è£¡æ·»åŠ æ›´å¤šè¬›è€…
}


class GitHubImageUploader:
    """GitHub åœ–ç‰‡ä¸Šå‚³å™¨"""
    
    def __init__(self, token, repo_name):
        self.github = Github(token)
        self.repo = self.github.get_repo(repo_name)
        self.uploaded_cache = {}  # å¿«å–å·²ä¸Šå‚³çš„åœ–ç‰‡
        logger.info(f"âœ“ GitHub å€‰åº«å·²é€£æ¥: {repo_name}")
        
        # è¼‰å…¥å·²å­˜åœ¨çš„æª”æ¡ˆåˆ—è¡¨
        self._load_existing_files()
    
    def _load_existing_files(self):
        """è¼‰å…¥ GitHub å€‰åº«ä¸­å·²å­˜åœ¨çš„æª”æ¡ˆ"""
        try:
            logger.debug("è¼‰å…¥ GitHub å€‰åº«ç¾æœ‰æª”æ¡ˆ...")
            contents = self.repo.get_contents("")
            self.existing_files = {content.name for content in contents if content.type == "file"}
            logger.debug(f"  æ‰¾åˆ° {len(self.existing_files)} å€‹ç¾æœ‰æª”æ¡ˆ")
        except Exception as e:
            logger.warning(f"ç„¡æ³•è¼‰å…¥ç¾æœ‰æª”æ¡ˆåˆ—è¡¨: {e}")
            self.existing_files = set()
    
    def generate_filename_from_url(self, original_url):
        """æ ¹æ“š URL ç”Ÿæˆç©©å®šçš„æ–‡ä»¶åï¼ˆç”¨æ–¼æª¢æŸ¥é‡è¤‡ï¼‰"""
        # ä½¿ç”¨å®Œæ•´ URL hash ç¢ºä¿ç›¸åŒ URL ç”Ÿæˆç›¸åŒæª”å
        url_hash = hashlib.md5(original_url.encode()).hexdigest()
        
        # ç²å–åŸå§‹æ–‡ä»¶æ“´å±•å
        ext = original_url.split('.')[-1].split('?')[0].lower()
        if ext not in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            ext = 'jpg'
        
        return f"toptrader_{url_hash}.{ext}"
    
    def check_image_exists(self, filename):
        """æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å·²å­˜åœ¨æ–¼ GitHub"""
        return filename in self.existing_files
    
    def get_github_raw_url(self, filename):
        """ç²å– GitHub raw URL"""
        return f"https://raw.githubusercontent.com/{self.repo.full_name}/main/{filename}"
    
    def upload_image(self, image_url):
        """ä¸Šå‚³åœ–ç‰‡åˆ° GitHub ä¸¦è¿”å› raw URLï¼ˆé¿å…é‡è¤‡ä¸Šå‚³ï¼‰"""
        try:
            # æª¢æŸ¥å¿«å–
            if image_url in self.uploaded_cache:
                logger.debug(f"ä½¿ç”¨å¿«å–: {image_url}")
                return self.uploaded_cache[image_url]
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self.generate_filename_from_url(image_url)
            github_url = self.get_github_raw_url(filename)
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šé API å†æ¬¡ç¢ºèªï¼‰
            try:
                self.repo.get_contents(filename)
                logger.info(f"âœ“ åœ–ç‰‡å·²å­˜åœ¨æ–¼ GitHubï¼Œè·³éä¸Šå‚³: {filename}")
                self.uploaded_cache[image_url] = github_url
                return github_url
            except Exception:
                # æª”æ¡ˆä¸å­˜åœ¨ï¼Œç¹¼çºŒä¸Šå‚³
                pass
            
            # ä¸‹è¼‰åœ–ç‰‡
            logger.debug(f"ä¸‹è¼‰åœ–ç‰‡: {image_url}")
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()
            
            # ä¸Šå‚³åˆ° GitHub
            logger.debug(f"ä¸Šå‚³åˆ° GitHub: {filename}")
            try:
                self.repo.create_file(
                    path=filename,
                    message=f"Add image from Top Traders Unplugged",
                    content=response.content
                )
                logger.info(f"âœ“ åœ–ç‰‡å·²ä¸Šå‚³: {filename}")
            except Exception as e:
                # å¦‚æœå‰µå»ºå¤±æ•—ï¼ˆå¯èƒ½æ˜¯ä¸¦ç™¼å°è‡´çš„é‡è¤‡ï¼‰ï¼Œå˜—è©¦ç²å–ç¾æœ‰æ–‡ä»¶
                if "already exists" in str(e) or "sha" in str(e).lower():
                    logger.info(f"âœ“ åœ–ç‰‡å·²å­˜åœ¨ï¼ˆä¸¦ç™¼æª¢æ¸¬ï¼‰ï¼Œä½¿ç”¨ç¾æœ‰æ–‡ä»¶: {filename}")
                else:
                    raise
            
            # æ·»åŠ åˆ°å¿«å–
            self.uploaded_cache[image_url] = github_url
            
            return github_url
            
        except Exception as e:
            logger.error(f"ä¸Šå‚³åœ–ç‰‡å¤±æ•— {image_url}: {e}")
            logger.debug(traceback.format_exc())
            return image_url  # å¤±æ•—æ™‚è¿”å›åŸå§‹ URL


class TopTraderScraper:
    def __init__(self, test_mode=False):
        logger.info("=" * 70)
        logger.info("åˆå§‹åŒ– Top Traders Unplugged Scraper")
        
        # æª¢æ¸¬ç’°å¢ƒ
        if is_kaggle_environment():
            logger.info("ğŸ” é‹è¡Œç’°å¢ƒ: Kaggle Notebook")
        else:
            logger.info("ğŸ” é‹è¡Œç’°å¢ƒ: æœ¬åœ°ç«¯")
        
        logger.info("=" * 70)
        
        self.test_mode = test_mode
        
        if test_mode:
            logger.warning("æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨ - ä¸æœƒä¿å­˜åˆ° MongoDB")
        
        # é¡¯ç¤ºç¯©é¸é…ç½®
        series_names = ', '.join([f"{c['name']} ({c['name_zh']})" for c in SERIES_CONFIG.values()])
        speaker_names = ', '.join(FEATURED_SPEAKERS.keys())
        logger.info(f"ç³»åˆ—ç¯©é¸: {series_names}")
        logger.info(f"è¬›è€…ç¯©é¸: {speaker_names}")
        
        # MongoDB é…ç½®
        logger.debug("é…ç½® MongoDB é€£æ¥...")
        self.mongodb_url = get_secret('MONGODB_URL')
        if not self.mongodb_url:
            logger.error("MONGODB_URL æœªè¨­ç½®")
            raise ValueError("MONGODB_URL æœªè¨­ç½®")
        
        self.mongo_client = MongoClient(self.mongodb_url)
        self.db = self.mongo_client['top_trader_scraper']
        self.episodes_collection = self.db['episodes']
        
        # ç¢ºä¿ url å­—æ®µçš„å”¯ä¸€ç´¢å¼•
        self.episodes_collection.create_index('url', unique=True)
        logger.info("âœ“ MongoDB å·²é€£æ¥")
        
        # OpenAI é…ç½®
        logger.debug("é…ç½® OpenAI API...")
        self.openai_api_key = get_secret('OPENAI_API_KEY')
        self.model = get_secret('MODEL') or 'gpt-4o-mini'
        if not self.openai_api_key:
            logger.error("OPENAI_API_KEY æœªè¨­ç½®")
            raise ValueError("OPENAI_API_KEY æœªè¨­ç½®")
        
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        logger.info(f"âœ“ OpenAI é…ç½®å®Œæˆ (æ¨¡å‹: {self.model})")
        
        # Gmail é…ç½®
        logger.debug("é…ç½® Gmail SMTP...")
        self.mail_token = get_secret('MAIL_TOKEN')
        self.app_password = get_secret('APP_PASSWORD')
        recipients_str = get_secret('RECIPIENTS') or ''
        self.recipients = [r.strip() for r in recipients_str.split(',') if r.strip()]
        
        if not self.mail_token or not self.app_password:
            logger.error("MAIL_TOKEN æˆ– APP_PASSWORD æœªè¨­ç½®")
            raise ValueError("MAIL_TOKEN æˆ– APP_PASSWORD æœªè¨­ç½®")
        
        # é©—è­‰éƒµä»¶åœ°å€æ ¼å¼
        if '@' not in self.mail_token:
            logger.error(f"MAIL_TOKEN æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚ºå®Œæ•´éƒµç®±åœ°å€: {self.mail_token}")
            raise ValueError("MAIL_TOKEN æ‡‰ç‚ºå®Œæ•´çš„ Gmail åœ°å€ï¼ˆä¾‹å¦‚ï¼šyour_email@gmail.comï¼‰")
        
        logger.info(f"âœ“ Gmail é…ç½®å®Œæˆ (ç™¼ä»¶äºº: {self.mail_token})")
        logger.info(f"  æ”¶ä»¶äºº: {', '.join(self.recipients)}")
        logger.debug(f"  APP_PASSWORD é•·åº¦: {len(self.app_password) if self.app_password else 0}")
        
        # GitHub é…ç½®
        logger.debug("é…ç½® GitHub åœ–ç‰‡ä¸Šå‚³...")
        github_token = get_secret('GITHUB_TOKEN')
        github_repo = get_secret('GITHUB_REPO') or 'chendoit/PicBed'
        
        if not github_token:
            logger.error("GITHUB_TOKEN æœªè¨­ç½®")
            raise ValueError("GITHUB_TOKEN æœªè¨­ç½®")
        
        self.github_uploader = GitHubImageUploader(github_token, github_repo)
    
    def is_already_scraped(self, url):
        """æª¢æŸ¥é›†æ•¸æ˜¯å¦å·²ç¶“æŠ“éï¼ˆé€šé URLï¼‰"""
        if self.test_mode:
            logger.debug(f"æ¸¬è©¦æ¨¡å¼ - è·³éé‡è¤‡æª¢æŸ¥")
            return False
        
        exists = self.episodes_collection.find_one({'url': url}) is not None
        logger.debug(f"URL é‡è¤‡æª¢æŸ¥: {url} - {'å·²å­˜åœ¨' if exists else 'æ–°é›†æ•¸'}")
        return exists
    
    def detect_series(self, img_src):
        """å¾åœ–ç‰‡ URL æª¢æ¸¬ç³»åˆ—"""
        if not img_src:
            return None
        
        # æå–æª”å
        filename = img_src.split('/')[-1].lower()
        
        for series_key, config in SERIES_CONFIG.items():
            if filename.startswith(config['prefix']):
                return series_key
        
        return None
    
    def check_featured_speaker(self, title):
        """æª¢æŸ¥æ¨™é¡Œä¸­æ˜¯å¦åŒ…å«é—œæ³¨çš„è¬›è€…"""
        title_lower = title.lower()
        for speaker_name, patterns in FEATURED_SPEAKERS.items():
            for pattern in patterns:
                if pattern in title_lower:
                    logger.debug(f"åŒ¹é…åˆ°è¬›è€… '{speaker_name}' (æ¨¡å¼: '{pattern}')")
                    return speaker_name
        return None
    
    def should_process_episode(self, series, speaker_found):
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è™•ç†é€™å€‹é›†æ•¸"""
        # åªè™•ç†åœ¨ SERIES_CONFIG ä¸­é…ç½®çš„ç³»åˆ— æˆ– åœ¨ FEATURED_SPEAKERS ä¸­é…ç½®çš„è¬›è€…
        if series or speaker_found:
            return True
        
        return False
    
    async def scrape_latest_episodes(self):
        """æŠ“å–æœ€æ–°çš„ 5 é›†æ’­å®¢ - Async ç‰ˆæœ¬"""
        base_url = 'https://www.toptradersunplugged.com/'
        
        logger.info("\n" + "=" * 70)
        logger.info(f"é–‹å§‹æŠ“å–: Top Traders Unplugged")
        logger.info("=" * 70)
        
        async with async_playwright() as p:
            logger.debug("å•Ÿå‹•ç€è¦½å™¨ (Chromium headless)")
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                logger.info(f"è¨ªå•ç›®æ¨™ç¶²ç«™: {base_url}")
                await page.goto(base_url, timeout=60000)
                
                # ç­‰å¾…é é¢åŠ è¼‰
                await page.wait_for_selector('.latest-episodes-slider__slider__item', timeout=30000)
                
                # æ‰¾åˆ°å‰ 5 å€‹é›†æ•¸
                items = page.locator('.latest-episodes-slider__slider__item').all()
                items_list = await items
                
                logger.info(f"æ‰¾åˆ° {len(items_list)} å€‹é›†æ•¸ï¼Œå°‡è™•ç†å‰ 5 å€‹")
                
                episodes_to_process = []
                
                for i, item in enumerate(items_list[:5]):
                    logger.info(f"\n--- æª¢æŸ¥é›†æ•¸ {i+1}/5 ---")
                    
                    try:
                        # æå–æ¨™é¡Œå’Œéˆæ¥
                        title_link = item.locator('.latest-episodes-slider__slider__item__title')
                        href = await title_link.get_attribute('href')
                        title = await title_link.inner_text()
                        
                        # æå–åœ–ç‰‡
                        img = item.locator('img')
                        img_src = await img.get_attribute('src')
                        
                        logger.info(f"æ¨™é¡Œ: {title}")
                        logger.info(f"éˆæ¥: {href}")
                        logger.info(f"åœ–ç‰‡: {img_src}")
                        
                        # æª¢æ¸¬ç³»åˆ—
                        series = self.detect_series(img_src)
                        series_info = SERIES_CONFIG.get(series, {}) if series else {}
                        
                        if series:
                            logger.info(f"ç³»åˆ—: {series_info.get('emoji', '')} {series_info.get('name', '')} ({series_info.get('name_zh', '')})")
                        else:
                            logger.info(f"ç³»åˆ—: æœªè­˜åˆ¥")
                        
                        # æª¢æŸ¥è¬›è€…
                        speaker_found = self.check_featured_speaker(title)
                        if speaker_found:
                            logger.info(f"ç‰¹è‰²è¬›è€…: â­ {speaker_found}")
                        
                        # åˆ¤æ–·æ˜¯å¦æ‡‰è©²è™•ç†
                        if not self.should_process_episode(series, speaker_found):
                            logger.info("âœ— ä¸ç¬¦åˆç¯©é¸æ¢ä»¶ï¼Œè·³é")
                            continue
                        
                        # æª¢æŸ¥æ˜¯å¦å·²æŠ“å–
                        if self.is_already_scraped(href):
                            if self.test_mode:
                                logger.warning("[æ¸¬è©¦æ¨¡å¼] é›†æ•¸å·²æŠ“å–éï¼Œä½†ç¹¼çºŒåŸ·è¡Œ...")
                            else:
                                logger.info("âœ“ é›†æ•¸å·²å­˜åœ¨æ–¼ MongoDB ä¸­ï¼Œè·³é")
                                continue
                        
                        logger.info("âœ“ ç¬¦åˆæ¢ä»¶ï¼ŒåŠ å…¥è™•ç†åˆ—è¡¨")
                        
                        episodes_to_process.append({
                            'title': title,
                            'url': href,
                            'img_src': img_src,
                            'series': series,
                            'series_info': series_info,
                            'speaker': speaker_found
                        })
                        
                    except Exception as e:
                        logger.error(f"æå–é›†æ•¸ {i+1} ä¿¡æ¯å¤±æ•—: {e}")
                        logger.debug(traceback.format_exc())
                        continue
                
                logger.info(f"\nå…±æœ‰ {len(episodes_to_process)} å€‹é›†æ•¸éœ€è¦è™•ç†")
                
                # è™•ç†æ¯å€‹é›†æ•¸
                for episode_info in episodes_to_process:
                    await self.scrape_episode(page, episode_info)
                
                await browser.close()
                
            except Exception as e:
                logger.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
                logger.debug(traceback.format_exc())
                try:
                    if browser:
                        await browser.close()
                except:
                    pass
    
    async def scrape_episode(self, page, episode_info):
        """æŠ“å–å–®å€‹é›†æ•¸çš„å®Œæ•´å…§å®¹"""
        logger.info("\n" + "=" * 70)
        logger.info(f"é–‹å§‹è™•ç†: {episode_info['title']}")
        logger.info("=" * 70)
        
        try:
            # è¨ªå•é›†æ•¸é é¢
            logger.info(f"è¨ªå•é›†æ•¸é é¢: {episode_info['url']}")
            await page.goto(episode_info['url'], timeout=60000)
            await page.wait_for_timeout(2000)  # ç­‰å¾… 2 ç§’
            
            # æŠ“å– transcript
            logger.info("æŠ“å– transcript...")
            try:
                transcript_section = page.locator('.single-podcast-content__transcript__preview')
                transcript_text = await transcript_section.inner_text()
                
                # æ¸…ç†æ–‡å­—
                transcript_text = transcript_text.strip()
                
                logger.info(f"âœ“ Transcript é•·åº¦: {len(transcript_text)} å­—ç¬¦")
                
                if len(transcript_text) < 50:
                    logger.warning("Transcript å…§å®¹å¤ªå°‘ï¼Œå¯èƒ½æŠ“å–å¤±æ•—")
                    return
                
            except Exception as e:
                logger.error(f"æŠ“å– transcript å¤±æ•—: {e}")
                return
            
            # ä¸Šå‚³åœ–ç‰‡åˆ° GitHub
            logger.info("ä¸Šå‚³å°é¢åœ–ç‰‡åˆ° GitHub...")
            github_img_url = self.github_uploader.upload_image(episode_info['img_src'])
            
            # ç¿»è­¯ transcript
            logger.info("ç¿»è­¯ transcript...")
            translated_paragraphs = self.translate_transcript(transcript_text, episode_info['title'])
            
            if not translated_paragraphs:
                logger.error("ç¿»è­¯å¤±æ•—")
                return
            
            # æº–å‚™é›†æ•¸æ•¸æ“š
            episode_data = {
                'url': episode_info['url'],
                'title': episode_info['title'],
                'img_src': github_img_url,
                'series': episode_info['series'],
                'series_name': episode_info['series_info'].get('name', ''),
                'series_name_zh': episode_info['series_info'].get('name_zh', ''),
                'series_emoji': episode_info['series_info'].get('emoji', 'ğŸ™ï¸'),
                'featured_speaker': episode_info['speaker'],
                'transcript_en': transcript_text,
                'transcript_zh': translated_paragraphs,
                'scraped_at': datetime.now().isoformat()
            }
            
            # ä¿å­˜åˆ° MongoDB
            logger.info("\n" + "-" * 70)
            self.save_to_mongodb(episode_data)
            logger.info("-" * 70 + "\n")
            
            # ç™¼é€éƒµä»¶
            logger.info("-" * 70)
            self.send_email(episode_data)
            logger.info("-" * 70 + "\n")
            
            logger.info("=" * 70)
            logger.info(f"âœ“ {episode_info['title']} è™•ç†å®Œæˆï¼")
            logger.info("=" * 70)
            
        except Exception as e:
            logger.error(f"è™•ç†é›†æ•¸å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())

    def translate_transcript(self, transcript_text, title, batch_size=50):
        """ç¿»è­¯ transcript ç‚ºç¹é«”ä¸­æ–‡ï¼ˆæ®µè½å½¢å¼ï¼Œåˆ†æ‰¹ç¿»è­¯ï¼‰"""
        logger.info("é–‹å§‹ç¿»è­¯ transcript...")
        logger.debug(f"æ–‡å­—é•·åº¦: {len(transcript_text)} å­—ç¬¦")
        
        try:
            # ä¿æŒåŸå§‹åˆ†æ®µï¼ˆæŒ‰æ›è¡Œç¬¦åˆ†å‰²ï¼‰
            # å…ˆå˜—è©¦é›™æ›è¡Œç¬¦ï¼ˆæ®µè½åˆ†éš”ç¬¦ï¼‰
            paragraphs = transcript_text.split('\n\n')
            
            # å¦‚æœæ²’æœ‰é›™æ›è¡Œç¬¦ï¼Œå˜—è©¦å–®æ›è¡Œç¬¦
            if len(paragraphs) == 1:
                paragraphs = transcript_text.split('\n')
            
            # éæ¿¾ç©ºæ®µè½
            paragraphs = [p.strip() for p in paragraphs if p.strip()]
            
            logger.info(f"åŸå§‹åˆ†æ®µ: {len(paragraphs)} å€‹æ®µè½")
            
            # æå–æ™‚é–“æˆ³å’Œè¬›è€…ä¿¡æ¯çš„å‡½æ•¸
            def extract_metadata(text):
                """å¾æ–‡æœ¬ä¸­æå–æ™‚é–“æˆ³å’Œè¬›è€…ï¼Œä¸¦æ¸…ç†æ–‡æœ¬"""
                import re
                
                timestamp = None
                speaker = None
                clean_text = text
                
                # åŒ¹é… [HH:MM:SS] æˆ– [MM:SS] æˆ– [H:MM:SS] æ ¼å¼çš„æ™‚é–“æˆ³
                timestamp_pattern = r'^\[(\d{1,2}:\d{2}(?::\d{2})?)\]\s*'
                timestamp_match = re.match(timestamp_pattern, text)
                
                if timestamp_match:
                    timestamp = timestamp_match.group(1)
                    clean_text = text[timestamp_match.end():]
                    
                    # æå–è¬›è€…åå­—ï¼ˆåœ¨æ™‚é–“æˆ³å¾Œï¼Œå†’è™Ÿå‰ï¼Œå¯èƒ½å¤šæ¬¡å‡ºç¾ï¼‰
                    # åŒ¹é…æ¨¡å¼ï¼šName æˆ– Name: æˆ– Name\n
                    speaker_pattern = r'^([A-Z][a-zA-Z\s]+?)(?:[:ï¼š\s]\s*)'
                    speaker_match = re.match(speaker_pattern, clean_text)
                    
                    if speaker_match:
                        speaker = speaker_match.group(1).strip()
                        # ç§»é™¤è¬›è€…åå­—å’Œå¾Œé¢çš„å†’è™Ÿ/ç©ºæ ¼
                        clean_text = clean_text[speaker_match.end():].strip()
                        
                        # å¦‚æœè¬›è€…åå­—å¾Œé¢é‚„æœ‰é‡è¤‡çš„ï¼Œå†ç§»é™¤ä¸€æ¬¡
                        # ä¾‹å¦‚ "Nigol\nNigol\nå…§å®¹..." -> "å…§å®¹..."
                        repeat_pattern = rf'^{re.escape(speaker)}(?:[:ï¼š\s]\s*)'
                        clean_text = re.sub(repeat_pattern, '', clean_text, flags=re.IGNORECASE).strip()
                
                return timestamp, speaker, clean_text
            
            # è™•ç†æ®µè½ï¼Œæå–å…ƒæ•¸æ“š
            processed_paragraphs = []
            for i, para in enumerate(paragraphs):
                timestamp, speaker, clean_text = extract_metadata(para)
                processed_paragraphs.append({
                    'original': para,
                    'clean': clean_text,
                    'timestamp': timestamp,
                    'speaker': speaker
                })
                
                # èª¿è©¦ï¼šé¡¯ç¤ºå‰ 3 å€‹æ®µè½çš„è™•ç†çµæœ
                if i < 3:
                    logger.debug(f"æ®µè½ {i+1}:")
                    logger.debug(f"  åŸå§‹: {para[:80]}...")
                    logger.debug(f"  æ™‚é–“æˆ³: {timestamp}")
                    logger.debug(f"  è¬›è€…: {speaker}")
                    logger.debug(f"  æ¸…ç†å¾Œ: {clean_text[:80]}...")
            
            # åˆ†æ‰¹ç¿»è­¯ï¼ˆåªç¿»è­¯æ¸…ç†å¾Œçš„æ–‡æœ¬ï¼‰
            all_chinese_paragraphs = []
            total_batches = (len(processed_paragraphs) + batch_size - 1) // batch_size  # å‘ä¸Šå–æ•´
            
            logger.info(f"å°‡åˆ†æˆ {total_batches} æ‰¹é€²è¡Œç¿»è­¯ (æ¯æ‰¹ {batch_size} æ®µ)")
            
            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min((batch_num + 1) * batch_size, len(processed_paragraphs))
                batch_items = processed_paragraphs[start_idx:end_idx]
                batch_texts = [item['clean'] for item in batch_items]
                
                logger.info(f"\n--- ç¿»è­¯æ‰¹æ¬¡ {batch_num + 1}/{total_batches} (æ®µè½ {start_idx + 1}-{end_idx}) ---")
                
                # æº–å‚™ JSON
                paragraphs_json = json.dumps(batch_texts, ensure_ascii=False, indent=2)
                
                prompt = f"""è«‹å°‡ä»¥ä¸‹ JSON æ•¸çµ„ä¸­çš„è‹±æ–‡æ®µè½ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å¿…é ˆè¿”å›ä¸€å€‹ç´” JSON æ•¸çµ„æ ¼å¼: ["ä¸­æ–‡1", "ä¸­æ–‡2", ...]
2. ä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ï¼Œç›´æ¥è¿”å›æ•¸çµ„
3. æ¯å€‹è‹±æ–‡æ®µè½å°æ‡‰ä¸€å€‹ç¹é«”ä¸­æ–‡ç¿»è­¯
4. ä¿æŒæ•¸çµ„é †åºå’Œé•·åº¦ä¸€è‡´
5. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§ï¼ˆç‰¹åˆ¥æ˜¯é‡‘èã€äº¤æ˜“è¡“èªï¼‰
6. ç¿»è­¯æµæš¢è‡ªç„¶ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡

æ’­å®¢æ¨™é¡Œ: {title}

è‹±æ–‡æ®µè½æ•¸çµ„:
{paragraphs_json}

è«‹è¿”å›å°æ‡‰çš„ç¹é«”ä¸­æ–‡ç¿»è­¯æ•¸çµ„ï¼ˆæ ¼å¼ç¤ºä¾‹: ["æ®µè½1ç¿»è­¯", "æ®µè½2ç¿»è­¯", ...]ï¼‰ï¼š
"""
                
                logger.debug(f"èª¿ç”¨ OpenAI API (æ‰¹æ¬¡ {batch_num + 1})...")
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èäº¤æ˜“é ˜åŸŸç¿»è­¯å°ˆå®¶ï¼Œæ“…é•·å°‡è‹±æ–‡æ’­å®¢å…§å®¹ç¿»è­¯æˆæº–ç¢ºæµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚è«‹åš´æ ¼è¿”å› JSON æ•¸çµ„æ ¼å¼ï¼Œä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                
                response_text = response.choices[0].message.content.strip()
                logger.debug(f"API éŸ¿æ‡‰é•·åº¦: {len(response_text)}")
                
                # è§£æ JSON
                chinese_paragraphs = json.loads(response_text)
                
                # å¦‚æœè¿”å›çš„æ˜¯å°è±¡ï¼Œå˜—è©¦æå–æ•¸çµ„
                if isinstance(chinese_paragraphs, dict):
                    possible_keys = [
                        'translations', 'paragraphs', 'chinese', 'result', 'data',
                        'ç¿»è­¯çµæœ', 'ç¿»è¯‘ç»“æœ', 'ç¿»è­¯', 'ä¸­æ–‡', 'æ®µè½', 'çµæœ'
                    ]
                    for key in possible_keys:
                        if key in chinese_paragraphs:
                            chinese_paragraphs = chinese_paragraphs[key]
                            logger.debug(f"å¾éµ '{key}' æå–æ•¸çµ„")
                            break
                
                # ç¢ºä¿æ˜¯åˆ—è¡¨
                if not isinstance(chinese_paragraphs, list):
                    logger.error(f"è¿”å›é¡å‹éŒ¯èª¤: {type(chinese_paragraphs)}")
                    return None
                
                # æª¢æŸ¥æ•¸é‡æ˜¯å¦åŒ¹é…
                if len(chinese_paragraphs) != len(batch_texts):
                    logger.warning(f"ç¿»è­¯æ•¸é‡ä¸åŒ¹é…: é æœŸ {len(batch_texts)}ï¼Œå¯¦éš› {len(chinese_paragraphs)}")
                
                all_chinese_paragraphs.extend(chinese_paragraphs)
                
                logger.info(f"âœ“ æ‰¹æ¬¡ {batch_num + 1} ç¿»è­¯å®Œæˆ (Token: {response.usage.total_tokens})")
            
            # çµ„åˆæˆä¸€å€‹å®Œæ•´çš„ç¿»è­¯ï¼ŒåŒ…å«å…ƒæ•¸æ“š
            combined_translations = []
            for i, (item, zh) in enumerate(zip(processed_paragraphs, all_chinese_paragraphs)):
                combined_translations.append({
                    'index': i,
                    'english': item['clean'],
                    'chinese': zh,
                    'timestamp': item['timestamp'],
                    'speaker': item['speaker']
                })
            
            logger.info(f"âœ“ æ‰€æœ‰ç¿»è­¯å®Œæˆï¼Œå…± {len(combined_translations)} å€‹æ®µè½")
            
            return combined_translations
            
        except Exception as e:
            logger.error(f"ç¿»è­¯å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return None
    
    def save_to_mongodb(self, episode_data):
        """ä¿å­˜é›†æ•¸åˆ° MongoDB"""
        try:
            if self.test_mode:
                logger.warning("[æ¸¬è©¦æ¨¡å¼] è·³éä¿å­˜åˆ° MongoDB")
                return True
            
            logger.debug(f"ä¿å­˜é›†æ•¸åˆ° MongoDB: {episode_data['url']}")
            result = self.episodes_collection.update_one(
                {'url': episode_data['url']},
                {'$set': episode_data},
                upsert=True
            )
            
            if result.upserted_id:
                logger.info(f"âœ“ æ–°é›†æ•¸å·²ä¿å­˜åˆ° MongoDB (ID: {result.upserted_id})")
            else:
                logger.info(f"âœ“ é›†æ•¸å·²æ›´æ–°åˆ° MongoDB")
            
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ° MongoDB å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False
    
    def send_email(self, episode_data):
        """ç™¼é€éƒµä»¶ï¼ˆä¸ä¿ç•™å‚™ä»½ï¼‰"""
        logger.info("æº–å‚™ç™¼é€éƒµä»¶...")
        
        try:
            # å‰µå»ºéƒµä»¶
            msg = MIMEMultipart('alternative')
            msg['From'] = self.mail_token
            msg['To'] = ', '.join(self.recipients)
            
            # æ·»åŠ ä¸ä¿å­˜åˆ°"å·²ç™¼é€"æ–‡ä»¶å¤¾çš„æ¨™é ­
            msg['X-Gm-No-Archive'] = '1'  # Gmail å°ˆç”¨ï¼šä¸ä¿å­˜å‚™ä»½
            
            # éƒµä»¶ä¸»é¡Œ
            series_emoji = episode_data.get('series_emoji', 'ğŸ™ï¸')
            series_name_zh = episode_data.get('series_name_zh', '')
            subject_parts = [f"{series_emoji} Top Traders Unplugged"]
            
            if series_name_zh:
                subject_parts.append(f"- {series_name_zh}")
            
            if episode_data.get('featured_speaker'):
                subject_parts.append(f"- {episode_data['featured_speaker']}")
            
            subject_parts.append(f"- {episode_data['title']}")
            
            msg['Subject'] = ' '.join(subject_parts)
            
            # ç”Ÿæˆ HTML å…§å®¹
            html_content = self._generate_html_email(episode_data)
            
            # æ·»åŠ  HTML éƒ¨åˆ†
            part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(part)
            
            # ç™¼é€éƒµä»¶
            logger.debug("é€£æ¥åˆ° Gmail SMTP æœå‹™å™¨...")
            logger.debug(f"  ä½¿ç”¨å¸³è™Ÿ: {self.mail_token}")
            logger.debug(f"  å¯†ç¢¼é•·åº¦: {len(self.app_password)}")
            logger.info("  å·²è¨­å®šä¸ä¿å­˜éƒµä»¶å‚™ä»½åˆ°ã€Œå·²ç™¼é€ã€æ–‡ä»¶å¤¾")
            
            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                logger.debug("  SMTP é€£æ¥å·²å»ºç«‹")
                server.set_debuglevel(0)  # è¨­ç‚º 1 å¯çœ‹åˆ°æ›´å¤šèª¿è©¦ä¿¡æ¯
                server.login(self.mail_token, self.app_password)
                logger.debug("  ç™»å…¥æˆåŠŸ")
                server.send_message(msg)
                logger.debug("  éƒµä»¶å·²ç™¼é€")
            
            logger.info(f"âœ“ éƒµä»¶å·²ç™¼é€")
            return True
            
        except smtplib.SMTPAuthenticationError as e:
            logger.error(f"Gmail èªè­‰å¤±æ•—: {e}")
            logger.error("è«‹æª¢æŸ¥:")
            logger.error("  1. MAIL_TOKEN æ˜¯å¦ç‚ºå®Œæ•´çš„ Gmail åœ°å€")
            logger.error("  2. APP_PASSWORD æ˜¯å¦æ­£ç¢ºï¼ˆæ‡‰ä½¿ç”¨ Google App Passwordï¼Œè€Œéå¸³è™Ÿå¯†ç¢¼ï¼‰")
            logger.error("  3. æ˜¯å¦å·²å•Ÿç”¨ Google å…©æ­¥é©Ÿé©—è­‰ä¸¦ç”Ÿæˆæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼")
            logger.debug(traceback.format_exc())
            return False
        except Exception as e:
            logger.error(f"ç™¼é€éƒµä»¶å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False
    
    def _generate_html_email(self, episode_data):
        """ç”Ÿæˆ HTML éƒµä»¶å…§å®¹"""
        html_parts = []
        
        series_emoji = episode_data.get('series_emoji', 'ğŸ™ï¸')
        series_name = episode_data.get('series_name', 'Podcast')
        series_name_zh = episode_data.get('series_name_zh', 'æ’­å®¢')
        featured_speaker = episode_data.get('featured_speaker', '')
        
        html_parts.append(f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background-color: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .series-badge {{
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9em;
            margin-bottom: 15px;
            font-weight: 600;
        }}
        .speaker-badge {{
            display: inline-block;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9em;
            margin-bottom: 15px;
            margin-left: 10px;
            font-weight: 600;
        }}
        h1 {{
            color: #1a1a1a;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
            margin-bottom: 25px;
        }}
        .cover-image {{
            text-align: center;
            margin: 30px 0;
        }}
        .cover-image img {{
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        .meta {{
            color: #666;
            font-size: 0.95em;
            margin-bottom: 30px;
            padding: 15px;
            background-color: #f8f9fa;
            border-left: 4px solid #667eea;
        }}
         .transcript-section {{
             margin-top: 30px;
         }}
         .paragraph-block {{
             margin-bottom: 25px;
             padding: 0;
             background-color: transparent;
             position: relative;
         }}
         .speaker-header {{
             display: flex;
             align-items: center;
             gap: 10px;
             margin-bottom: 12px;
         }}
         .speaker-badge {{
             display: inline-flex;
             align-items: center;
             padding: 6px 12px;
             border-radius: 20px;
             font-weight: 600;
             font-size: 0.9em;
             color: white;
             box-shadow: 0 2px 4px rgba(0,0,0,0.1);
         }}
         .speaker-badge.speaker-1 {{
             background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
         }}
         .speaker-badge.speaker-2 {{
             background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
         }}
         .speaker-badge.speaker-3 {{
             background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
         }}
         .speaker-badge.speaker-4 {{
             background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
         }}
         .speaker-badge.speaker-5 {{
             background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
         }}
         .speaker-badge.speaker-default {{
             background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
         }}
         .timestamp {{
             font-size: 0.75em;
             color: #999;
             font-family: 'Courier New', monospace;
             padding: 4px 8px;
             background-color: #f5f5f5;
             border-radius: 4px;
         }}
         .content-card {{
             background-color: white;
             border-radius: 12px;
             padding: 20px;
             box-shadow: 0 2px 8px rgba(0,0,0,0.08);
             border-left: 4px solid #e0e0e0;
         }}
         .content-card.has-speaker-1 {{
             border-left-color: #667eea;
         }}
         .content-card.has-speaker-2 {{
             border-left-color: #f5576c;
         }}
         .content-card.has-speaker-3 {{
             border-left-color: #00f2fe;
         }}
         .content-card.has-speaker-4 {{
             border-left-color: #38f9d7;
         }}
         .content-card.has-speaker-5 {{
             border-left-color: #fa709a;
         }}
         .english {{
            color: #2c3e50;
            line-height: 1.7;
            margin-bottom: 15px;
            padding: 0;
            background-color: transparent;
            border-radius: 0;
            border-left: none;
         }}
         .english::before {{
             content: "ğŸ‡¬ğŸ‡§ ";
             font-weight: bold;
             opacity: 0.6;
         }}
         .chinese {{
             color: #34495e;
             background-color: #f8f9fa;
             padding: 15px;
             border-radius: 8px;
             line-height: 1.7;
         }}
         .chinese::before {{
             content: "ğŸ‡¹ğŸ‡¼ ";
             font-weight: bold;
         }}
        .divider {{
            border-top: 1px solid #e0e0e0;
            margin: 20px 0;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e0e0e0;
            color: #999;
            font-size: 0.9em;
            text-align: center;
        }}
        a {{
            color: #667eea;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="series-badge">{series_emoji} {series_name} / {series_name_zh}</div>
        {f'<div class="speaker-badge">â­ {featured_speaker}</div>' if featured_speaker else ''}
        <h1>{episode_data['title']}</h1>
        
        <div class="cover-image">
            <img src="{episode_data['img_src']}" alt="Episode Cover">
        </div>
        
        <div class="meta">
            <strong>åŸæ–‡é€£çµ / Source:</strong> <a href="{episode_data['url']}" target="_blank">{episode_data['url']}</a><br>
            <strong>æŠ“å–æ™‚é–“ / Scraped:</strong> {episode_data['scraped_at']}
        </div>
        
        <div class="transcript-section">
            <h2>ğŸ“ Transcript / æ–‡å­—ç¨¿</h2>
""")
        
        # æ·»åŠ æ®µè½ï¼ˆè‹±æ–‡ + ç¹é«”ä¸­æ–‡äº¤æ›¿é¡¯ç¤ºï¼Œè¬›è€…æœ‰é¡è‰²æ¨™è¨˜ï¼‰
        # ç‚ºä¸åŒè¬›è€…åˆ†é…é¡è‰²ç·¨è™Ÿ
        speaker_colors = {}
        color_index = 1
        
        for para in episode_data['transcript_zh']:
            # ç²å–è¬›è€…ä¸¦åˆ†é…é¡è‰²
            speaker = para.get('speaker', '')
            timestamp = para.get('timestamp', '')
            
            if speaker and speaker not in speaker_colors:
                speaker_colors[speaker] = color_index
                color_index = (color_index % 5) + 1  # å¾ªç’°ä½¿ç”¨ 1-5
            
            speaker_class = f"speaker-{speaker_colors.get(speaker, 'default')}"
            
            # ç”Ÿæˆé ­éƒ¨ï¼ˆè¬›è€…æ¨™ç±¤ + æ™‚é–“æˆ³ï¼‰
            header_html = ""
            if speaker or timestamp:
                header_parts = []
                if speaker:
                    header_parts.append(f'<span class="speaker-badge {speaker_class}">{speaker}</span>')
                if timestamp:
                    header_parts.append(f'<span class="timestamp">ğŸ• {timestamp}</span>')
                header_html = f'<div class="speaker-header">{"".join(header_parts)}</div>'
            
            card_class = f"has-{speaker_class}" if speaker else ""
            
            html_parts.append(f"""
            <div class="paragraph-block">
                {header_html}
                <div class="content-card {card_class}">
                    <div class="english">{para['english']}</div>
                    <div class="chinese">{para['chinese']}</div>
                </div>
            </div>
""")
        
        html_parts.append("""
        </div>
        
        <div class="footer">
            æ­¤éƒµä»¶ç”± Top Traders Unplugged çˆ¬èŸ²è‡ªå‹•ç™¼é€<br>
            åœ–ç‰‡æ°¸ä¹…ä¿å­˜æ–¼ GitHub | Powered by Async Playwright + OpenAI
        </div>
    </div>
</body>
</html>
""")
        
        return ''.join(html_parts)
    
    async def scrape_all(self):
        """åŸ·è¡Œçˆ¬èŸ²ä»»å‹™ - Async ç‰ˆæœ¬"""
        logger.info("\n" + "=" * 70)
        logger.info("é–‹å§‹åŸ·è¡Œçˆ¬èŸ²ä»»å‹™")
        logger.info("=" * 70)
        
        # åœ¨ Kaggle ç’°å¢ƒä¸­è¨­ç½® Playwright
        await setup_playwright_in_kaggle()
        
        await self.scrape_latest_episodes()
        
        logger.debug("æ¸…ç†è³‡æº...")
        self.mongo_client.close()
        logger.info("\nâœ“ æ‰€æœ‰ä»»å‹™å®Œæˆï¼")


async def main_async():
    """Async main function for both local and Kaggle environments"""
    # è¨­ç½® Windows æ§åˆ¶å°ç·¨ç¢¼
    import sys
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    parser = argparse.ArgumentParser(description='Top Traders Unplugged æ’­å®¢çˆ¬èŸ²')
    parser.add_argument('--test', action='store_true', 
                       help='æ¸¬è©¦æ¨¡å¼ï¼šå¼·åˆ¶é‡æ–°æŠ“å–ï¼Œä¸æ›´æ–° MongoDB è¨˜éŒ„')
    args = parser.parse_args()
    
    logger.info("=" * 70)
    logger.info("  Top Traders Unplugged æ’­å®¢çˆ¬èŸ²")
    logger.info("  Async Playwright + MongoDB + OpenAI + Gmail + GitHub")
    logger.info("=" * 70)
    logger.info(f"æ—¥èªŒæ–‡ä»¶: {log_file}")
    
    if args.test:
        logger.warning("\n[æ¸¬è©¦æ¨¡å¼] æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
        logger.warning("   - å°‡é‡æ–°æŠ“å–å·²æŠ“å–éçš„é›†æ•¸")
        logger.warning("   - ä¸æœƒæ›´æ–° MongoDB è¨˜éŒ„\n")
    
    try:
        scraper = TopTraderScraper(test_mode=args.test)
        await scraper.scrape_all()
    except ValueError as e:
        logger.error(f"é…ç½®éŒ¯èª¤: {e}")
        logger.info("è«‹æª¢æŸ¥ .env æ–‡ä»¶é…ç½®")
        return
    except Exception as e:
        logger.error(f"ç¨‹åºéŒ¯èª¤: {e}")
        logger.debug(traceback.format_exc())
    
    logger.info("\n" + "=" * 70)
    logger.info("  ä»»å‹™çµæŸ")
    logger.info("=" * 70)
    logger.info(f"è©³ç´°æ—¥èªŒå·²ä¿å­˜åˆ°: {log_file}")


def main():
    """Synchronous wrapper for command-line usage"""
    try:
        # æª¢æ¸¬æ˜¯å¦åœ¨å·²æœ‰çš„ event loop ä¸­ï¼ˆå¦‚ Kaggleï¼‰
        loop = asyncio.get_running_loop()
        logger.error("æª¢æ¸¬åˆ°å·²é‹è¡Œçš„ event loopã€‚")
        logger.error("åœ¨ Kaggle/Jupyter ä¸­ï¼Œè«‹ç›´æ¥ä½¿ç”¨: await main_async()")
        return
    except RuntimeError:
        # æ²’æœ‰é‹è¡Œä¸­çš„ loopï¼Œæ­£å¸¸åŸ·è¡Œ
        asyncio.run(main_async())


if __name__ == "__main__":
    main()


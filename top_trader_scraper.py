"""
Top Traders Unplugged æ’­å®¢çˆ¬èŸ²
- æŠ“å–æœ€æ–°çš„ 5 é›†æ’­å®¢
- ç¯©é¸ç‰¹å®šç³»åˆ—ï¼ˆGM, UGOï¼‰æˆ–è¬›è€…ï¼ˆCem Karsanï¼‰
- ä½¿ç”¨ Async Playwright æå‡æ€§èƒ½
- MongoDB å„²å­˜ã€OpenAI ç¿»è­¯ã€Gmail éƒµä»¶ã€GitHub åœ–åºŠ
"""

import os
import json
import logging
import hashlib
import asyncio
from datetime import datetime
from playwright.async_api import async_playwright
import time
import argparse
from pymongo import MongoClient
from openai import OpenAI
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import traceback
import requests
from github import Github
from io import BytesIO
import base64
import re


# ===== Kaggle & Local ç’°å¢ƒå…¼å®¹ =====
def get_secret(key: str) -> str:
    """
    å–å¾—ç’°å¢ƒè®Šæ•¸æˆ– Kaggle Secretã€‚
    åœ¨æœ¬åœ°ç«¯ä½¿ç”¨ .envï¼Œåœ¨ Kaggle ä½¿ç”¨ UserSecretsClientã€‚
    """
    try:
        # å˜—è©¦åœ¨ Kaggle ç’°å¢ƒè¼‰å…¥
        from kaggle_secrets import UserSecretsClient
        user_secrets = UserSecretsClient()
        secret = user_secrets.get_secret(key)
        logger.debug(f"âœ“ å¾ Kaggle Secrets è¼‰å…¥: {key}")
        return secret
    except Exception:
        # é Kaggle æˆ–æœªè¨­å®š kaggle_secrets
        from dotenv import load_dotenv
        load_dotenv()
        value = os.getenv(key)
        logger.debug(f"âœ“ å¾ .env è¼‰å…¥: {key}")
        return value


def is_kaggle_environment():
    """æª¢æ¸¬æ˜¯å¦åœ¨ Kaggle ç’°å¢ƒ"""
    return os.path.exists('/kaggle/working')


async def setup_playwright_in_kaggle():
    """åœ¨ Kaggle ç’°å¢ƒä¸­è¨­ç½® Playwright"""
    if is_kaggle_environment():
        logger.info("æª¢æ¸¬åˆ° Kaggle ç’°å¢ƒï¼Œå®‰è£ Playwright ç€è¦½å™¨...")
        try:
            import subprocess
            result = subprocess.run(
                ['playwright', 'install', 'chromium'],
                capture_output=True,
                text=True,
                check=True
            )
            logger.info("âœ“ Playwright Chromium å·²å®‰è£")
            
            # å®‰è£ç³»çµ±ä¾è³´
            result = subprocess.run(
                ['playwright', 'install-deps', 'chromium'],
                capture_output=True,
                text=True,
                check=True
            )
            logger.info("âœ“ ç³»çµ±ä¾è³´å·²å®‰è£")
        except Exception as e:
            logger.warning(f"Playwright å®‰è£è­¦å‘Š: {e}")
# ===== çµæŸç’°å¢ƒå…¼å®¹å€åŸŸ =====


# é…ç½® logging
def setup_logging():
    """é…ç½®æ—¥èªŒç³»çµ± - ä¸€å¤©ä¸€å€‹æ—¥èªŒæ–‡ä»¶"""
    log_filename = f'top_trader_scraper_{datetime.now().strftime("%Y%m%d")}.log'
    
    # å‰µå»º logger
    logger = logging.getLogger('TopTraderScraper')
    logger.setLevel(logging.DEBUG)
    
    # æ¸…é™¤å·²æœ‰çš„ handlers
    logger.handlers.clear()
    
    # æ–‡ä»¶ handlerï¼ˆè©³ç´°æ—¥èªŒï¼‰- ä½¿ç”¨ append æ¨¡å¼
    file_handler = logging.FileHandler(log_filename, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    
    # æ§åˆ¶å° handlerï¼ˆç°¡åŒ–æ—¥èªŒï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    
    # æ·»åŠ  handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger, log_filename


# å‰µå»ºå…¨å±€ logger
logger, log_file = setup_logging()


# ç³»åˆ—é…ç½®
SERIES_CONFIG = {
    'gm': {
        'name': 'Global Macro',
        'name_zh': 'å…¨çƒå®è§€',
        'emoji': 'ğŸŒ',
        'prefix': 'gm_'
    },
    # 'ugo': {
    #     'name': 'U Got Options',
    #     'name_zh': 'æœŸæ¬Šè§£æ',
    #     'emoji': 'ğŸ“ˆ',
    #     'prefix': 'ugo_'
    # }
}

# é—œæ³¨çš„è¬›è€…ï¼ˆæ”¯æŒå…¨åæˆ–å§“æ°åŒ¹é…ï¼‰
FEATURED_SPEAKERS = {
    # 'Cem Karsan': ['cem karsan', 'karsan', 'cem'],  # åŒ¹é…å…¨åã€å§“æ°æˆ–åå­—
    # 'Cem Karsan': ['cem karsan'],  # åŒ¹é…å…¨åã€å§“æ°æˆ–åå­—
    'Alan Dunne': ['alan dunne'],
    # å¯ä»¥åœ¨é€™è£¡æ·»åŠ æ›´å¤šè¬›è€…
}


class GitHubImageUploader:
    """GitHub åœ–ç‰‡ä¸Šå‚³å™¨"""
    
    def __init__(self, token, repo_name):
        self.github = Github(token)
        self.repo = self.github.get_repo(repo_name)
        self.uploaded_cache = {}  # å¿«å–å·²ä¸Šå‚³çš„åœ–ç‰‡
        logger.info(f"âœ“ GitHub å€‰åº«å·²é€£æ¥: {repo_name}")
        
        # è¼‰å…¥å·²å­˜åœ¨çš„æª”æ¡ˆåˆ—è¡¨
        self._load_existing_files()
    
    def _load_existing_files(self):
        """è¼‰å…¥ GitHub å€‰åº«ä¸­å·²å­˜åœ¨çš„æª”æ¡ˆ"""
        try:
            logger.debug("è¼‰å…¥ GitHub å€‰åº«ç¾æœ‰æª”æ¡ˆ...")
            contents = self.repo.get_contents("")
            self.existing_files = {content.name for content in contents if content.type == "file"}
            logger.debug(f"  æ‰¾åˆ° {len(self.existing_files)} å€‹ç¾æœ‰æª”æ¡ˆ")
        except Exception as e:
            logger.warning(f"ç„¡æ³•è¼‰å…¥ç¾æœ‰æª”æ¡ˆåˆ—è¡¨: {e}")
            self.existing_files = set()
    
    def generate_filename_from_url(self, original_url):
        """æ ¹æ“š URL ç”Ÿæˆç©©å®šçš„æ–‡ä»¶åï¼ˆç”¨æ–¼æª¢æŸ¥é‡è¤‡ï¼‰"""
        # ä½¿ç”¨å®Œæ•´ URL hash ç¢ºä¿ç›¸åŒ URL ç”Ÿæˆç›¸åŒæª”å
        url_hash = hashlib.md5(original_url.encode()).hexdigest()
        
        # ç²å–åŸå§‹æ–‡ä»¶æ“´å±•å
        ext = original_url.split('.')[-1].split('?')[0].lower()
        if ext not in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            ext = 'jpg'
        
        return f"toptrader_{url_hash}.{ext}"
    
    def check_image_exists(self, filename):
        """æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å·²å­˜åœ¨æ–¼ GitHub"""
        return filename in self.existing_files
    
    def get_github_raw_url(self, filename):
        """ç²å– GitHub raw URL"""
        return f"https://raw.githubusercontent.com/{self.repo.full_name}/main/{filename}"
    
    def upload_image(self, image_url):
        """ä¸Šå‚³åœ–ç‰‡åˆ° GitHub ä¸¦è¿”å› raw URLï¼ˆé¿å…é‡è¤‡ä¸Šå‚³ï¼‰"""
        try:
            # æª¢æŸ¥å¿«å–
            if image_url in self.uploaded_cache:
                logger.debug(f"ä½¿ç”¨å¿«å–: {image_url}")
                return self.uploaded_cache[image_url]
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self.generate_filename_from_url(image_url)
            github_url = self.get_github_raw_url(filename)
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šé API å†æ¬¡ç¢ºèªï¼‰
            try:
                self.repo.get_contents(filename)
                logger.info(f"âœ“ åœ–ç‰‡å·²å­˜åœ¨æ–¼ GitHubï¼Œè·³éä¸Šå‚³: {filename}")
                self.uploaded_cache[image_url] = github_url
                return github_url
            except Exception:
                # æª”æ¡ˆä¸å­˜åœ¨ï¼Œç¹¼çºŒä¸Šå‚³
                pass
            
            # ä¸‹è¼‰åœ–ç‰‡
            logger.debug(f"ä¸‹è¼‰åœ–ç‰‡: {image_url}")
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()
            
            # ä¸Šå‚³åˆ° GitHub
            logger.debug(f"ä¸Šå‚³åˆ° GitHub: {filename}")
            try:
                self.repo.create_file(
                    path=filename,
                    message=f"Add image from Top Traders Unplugged",
                    content=response.content
                )
                logger.info(f"âœ“ åœ–ç‰‡å·²ä¸Šå‚³: {filename}")
            except Exception as e:
                # å¦‚æœå‰µå»ºå¤±æ•—ï¼ˆå¯èƒ½æ˜¯ä¸¦ç™¼å°è‡´çš„é‡è¤‡ï¼‰ï¼Œå˜—è©¦ç²å–ç¾æœ‰æ–‡ä»¶
                if "already exists" in str(e) or "sha" in str(e).lower():
                    logger.info(f"âœ“ åœ–ç‰‡å·²å­˜åœ¨ï¼ˆä¸¦ç™¼æª¢æ¸¬ï¼‰ï¼Œä½¿ç”¨ç¾æœ‰æ–‡ä»¶: {filename}")
                else:
                    raise
            
            # æ·»åŠ åˆ°å¿«å–
            self.uploaded_cache[image_url] = github_url
            
            return github_url
            
        except Exception as e:
            logger.error(f"ä¸Šå‚³åœ–ç‰‡å¤±æ•— {image_url}: {e}")
            logger.debug(traceback.format_exc())
            return image_url  # å¤±æ•—æ™‚è¿”å›åŸå§‹ URL


class TopTraderScraper:
    def __init__(self, test_mode=False, enable_translation=True):
        logger.info("=" * 70)
        logger.info("åˆå§‹åŒ– Top Traders Unplugged Scraper")
        
        # æª¢æ¸¬ç’°å¢ƒ
        if is_kaggle_environment():
            logger.info("ğŸ” é‹è¡Œç’°å¢ƒ: Kaggle Notebook")
        else:
            logger.info("ğŸ” é‹è¡Œç’°å¢ƒ: æœ¬åœ°ç«¯")
        
        logger.info("=" * 70)
        
        self.test_mode = test_mode
        self.enable_translation = enable_translation  # ç¿»è­¯é–‹é—œ
        
        if test_mode:
            logger.warning("æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨ - ä¸æœƒä¿å­˜åˆ° MongoDB")
        
        if not enable_translation:
            logger.warning("âš ï¸  ç¿»è­¯åŠŸèƒ½å·²ç¦ç”¨ - åªæœƒä¿å­˜è‹±æ–‡åŸæ–‡")
        
        # é¡¯ç¤ºç¯©é¸é…ç½®
        series_names = ', '.join([f"{c['name']} ({c['name_zh']})" for c in SERIES_CONFIG.values()])
        speaker_names = ', '.join(FEATURED_SPEAKERS.keys())
        logger.info(f"ç³»åˆ—ç¯©é¸: {series_names}")
        logger.info(f"è¬›è€…ç¯©é¸: {speaker_names}")
        
        # MongoDB é…ç½®
        logger.debug("é…ç½® MongoDB é€£æ¥...")
        self.mongodb_url = get_secret('MONGODB_URL')
        if not self.mongodb_url:
            logger.error("MONGODB_URL æœªè¨­ç½®")
            raise ValueError("MONGODB_URL æœªè¨­ç½®")
        
        self.mongo_client = MongoClient(self.mongodb_url)
        self.db = self.mongo_client['top_trader_scraper']
        self.episodes_collection = self.db['episodes']
        
        # ç¢ºä¿ url å­—æ®µçš„å”¯ä¸€ç´¢å¼•
        self.episodes_collection.create_index('url', unique=True)
        logger.info("âœ“ MongoDB å·²é€£æ¥")
        
        # OpenAI é…ç½®
        logger.debug("é…ç½® OpenAI API...")
        self.openai_api_key = get_secret('OPENAI_API_KEY')
        self.model = get_secret('MODEL') or 'gpt-4o-mini'
        if not self.openai_api_key:
            logger.error("OPENAI_API_KEY æœªè¨­ç½®")
            raise ValueError("OPENAI_API_KEY æœªè¨­ç½®")
        
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        logger.info(f"âœ“ OpenAI é…ç½®å®Œæˆ (æ¨¡å‹: {self.model})")
        
        # Gmail é…ç½®
        logger.debug("é…ç½® Gmail SMTP...")
        self.mail_token = get_secret('MAIL_TOKEN')
        self.app_password = get_secret('APP_PASSWORD')
        recipients_str = get_secret('RECIPIENTS') or ''
        self.recipients = [r.strip() for r in recipients_str.split(',') if r.strip()]
        
        if not self.mail_token or not self.app_password:
            logger.error("MAIL_TOKEN æˆ– APP_PASSWORD æœªè¨­ç½®")
            raise ValueError("MAIL_TOKEN æˆ– APP_PASSWORD æœªè¨­ç½®")
        
        # é©—è­‰éƒµä»¶åœ°å€æ ¼å¼
        if '@' not in self.mail_token:
            logger.error(f"MAIL_TOKEN æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚ºå®Œæ•´éƒµç®±åœ°å€: {self.mail_token}")
            raise ValueError("MAIL_TOKEN æ‡‰ç‚ºå®Œæ•´çš„ Gmail åœ°å€ï¼ˆä¾‹å¦‚ï¼šyour_email@gmail.comï¼‰")
        
        logger.info(f"âœ“ Gmail é…ç½®å®Œæˆ (ç™¼ä»¶äºº: {self.mail_token})")
        logger.info(f"  æ”¶ä»¶äºº: {', '.join(self.recipients)}")
        logger.debug(f"  APP_PASSWORD é•·åº¦: {len(self.app_password) if self.app_password else 0}")
        
        # GitHub é…ç½®
        logger.debug("é…ç½® GitHub åœ–ç‰‡ä¸Šå‚³...")
        github_token = get_secret('GITHUB_TOKEN')
        github_repo = get_secret('GITHUB_REPO') or 'chendoit/PicBed'
        
        if not github_token:
            logger.error("GITHUB_TOKEN æœªè¨­ç½®")
            raise ValueError("GITHUB_TOKEN æœªè¨­ç½®")
        
        self.github_uploader = GitHubImageUploader(github_token, github_repo)
    
    def is_already_scraped(self, url):
        """æª¢æŸ¥é›†æ•¸æ˜¯å¦å·²ç¶“æŠ“éï¼ˆé€šé URLï¼‰"""
        if self.test_mode:
            logger.debug(f"æ¸¬è©¦æ¨¡å¼ - è·³éé‡è¤‡æª¢æŸ¥")
            return False
        
        exists = self.episodes_collection.find_one({'url': url}) is not None
        logger.debug(f"URL é‡è¤‡æª¢æŸ¥: {url} - {'å·²å­˜åœ¨' if exists else 'æ–°é›†æ•¸'}")
        return exists
    
    def detect_series(self, img_src):
        """å¾åœ–ç‰‡ URL æª¢æ¸¬ç³»åˆ—"""
        if not img_src:
            return None
        
        # æå–æª”å
        filename = img_src.split('/')[-1].lower()
        
        for series_key, config in SERIES_CONFIG.items():
            if filename.startswith(config['prefix']):
                return series_key
        
        return None
    
    def check_featured_speaker(self, title):
        """æª¢æŸ¥æ¨™é¡Œä¸­æ˜¯å¦åŒ…å«é—œæ³¨çš„è¬›è€…"""
        title_lower = title.lower()
        for speaker_name, patterns in FEATURED_SPEAKERS.items():
            for pattern in patterns:
                if pattern in title_lower:
                    logger.debug(f"åŒ¹é…åˆ°è¬›è€… '{speaker_name}' (æ¨¡å¼: '{pattern}')")
                    return speaker_name
        return None
    
    def should_process_episode(self, series, speaker_found):
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²è™•ç†é€™å€‹é›†æ•¸"""
        # åªè™•ç†åœ¨ SERIES_CONFIG ä¸­é…ç½®çš„ç³»åˆ— æˆ– åœ¨ FEATURED_SPEAKERS ä¸­é…ç½®çš„è¬›è€…
        if series or speaker_found:
            return True
        
        return False
    
    async def scrape_latest_episodes(self):
        """æŠ“å–æœ€æ–°çš„ 5 é›†æ’­å®¢ - Async ç‰ˆæœ¬"""
        base_url = 'https://www.toptradersunplugged.com/'
        
        logger.info("\n" + "=" * 70)
        logger.info(f"é–‹å§‹æŠ“å–: Top Traders Unplugged")
        logger.info("=" * 70)
        
        async with async_playwright() as p:
            logger.debug("å•Ÿå‹•ç€è¦½å™¨ (Chromium headless)")
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                logger.info(f"è¨ªå•ç›®æ¨™ç¶²ç«™: {base_url}")
                await page.goto(base_url, timeout=60000)
                
                # ç­‰å¾…é é¢åŠ è¼‰
                await page.wait_for_selector('.latest-episodes-slider__slider__item', timeout=30000)
                
                # æ‰¾åˆ°å‰ 5 å€‹é›†æ•¸
                items = page.locator('.latest-episodes-slider__slider__item').all()
                items_list = await items
                
                logger.info(f"æ‰¾åˆ° {len(items_list)} å€‹é›†æ•¸ï¼Œå°‡è™•ç†å‰ 5 å€‹")
                
                episodes_to_process = []
                
                for i, item in enumerate(items_list[:5]):
                    logger.info(f"\n--- æª¢æŸ¥é›†æ•¸ {i+1}/5 ---")
                    
                    try:
                        # æå–æ¨™é¡Œå’Œéˆæ¥
                        title_link = item.locator('.latest-episodes-slider__slider__item__title')
                        href = await title_link.get_attribute('href')
                        title = await title_link.inner_text()
                        
                        # æå–åœ–ç‰‡
                        img = item.locator('img')
                        img_src = await img.get_attribute('src')
                        
                        logger.info(f"æ¨™é¡Œ: {title}")
                        logger.info(f"éˆæ¥: {href}")
                        logger.info(f"åœ–ç‰‡: {img_src}")
                        
                        # æª¢æ¸¬ç³»åˆ—
                        series = self.detect_series(img_src)
                        series_info = SERIES_CONFIG.get(series, {}) if series else {}
                        
                        if series:
                            logger.info(f"ç³»åˆ—: {series_info.get('emoji', '')} {series_info.get('name', '')} ({series_info.get('name_zh', '')})")
                        else:
                            logger.info(f"ç³»åˆ—: æœªè­˜åˆ¥")
                        
                        # æª¢æŸ¥è¬›è€…
                        speaker_found = self.check_featured_speaker(title)
                        if speaker_found:
                            logger.info(f"ç‰¹è‰²è¬›è€…: â­ {speaker_found}")
                        
                        # åˆ¤æ–·æ˜¯å¦æ‡‰è©²è™•ç†
                        if not self.should_process_episode(series, speaker_found):
                            logger.info("âœ— ä¸ç¬¦åˆç¯©é¸æ¢ä»¶ï¼Œè·³é")
                            continue
                        
                        # æª¢æŸ¥æ˜¯å¦å·²æŠ“å–
                        if self.is_already_scraped(href):
                            if self.test_mode:
                                logger.warning("[æ¸¬è©¦æ¨¡å¼] é›†æ•¸å·²æŠ“å–éï¼Œä½†ç¹¼çºŒåŸ·è¡Œ...")
                            else:
                                logger.info("âœ“ é›†æ•¸å·²å­˜åœ¨æ–¼ MongoDB ä¸­ï¼Œè·³é")
                                continue
                        
                        logger.info("âœ“ ç¬¦åˆæ¢ä»¶ï¼ŒåŠ å…¥è™•ç†åˆ—è¡¨")
                        
                        episodes_to_process.append({
                            'title': title,
                            'url': href,
                            'img_src': img_src,
                            'series': series,
                            'series_info': series_info,
                            'speaker': speaker_found
                        })
                        
                    except Exception as e:
                        logger.error(f"æå–é›†æ•¸ {i+1} ä¿¡æ¯å¤±æ•—: {e}")
                        logger.debug(traceback.format_exc())
                        continue
                
                logger.info(f"\nå…±æœ‰ {len(episodes_to_process)} å€‹é›†æ•¸éœ€è¦è™•ç†")
                
                # è™•ç†æ¯å€‹é›†æ•¸
                for episode_info in episodes_to_process:
                    await self.scrape_episode(page, episode_info)
                
                await browser.close()
                
            except Exception as e:
                logger.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
                logger.debug(traceback.format_exc())
                try:
                    if browser:
                        await browser.close()
                except:
                    pass
    
    async def scrape_episode(self, page, episode_info):
        """æŠ“å–å–®å€‹é›†æ•¸çš„å®Œæ•´å…§å®¹"""
        logger.info("\n" + "=" * 70)
        logger.info(f"é–‹å§‹è™•ç†: {episode_info['title']}")
        logger.info("=" * 70)
        
        try:
            # è¨ªå•é›†æ•¸é é¢
            logger.info(f"è¨ªå•é›†æ•¸é é¢: {episode_info['url']}")
            await page.goto(episode_info['url'], timeout=60000)
            await page.wait_for_timeout(2000)  # ç­‰å¾… 2 ç§’
            
            # æŠ“å– transcript
            logger.info("æŠ“å– transcript...")
            try:
                transcript_section = page.locator('.single-podcast-content__transcript__preview')
                transcript_text = await transcript_section.inner_text()
                
                # æ¸…ç†æ–‡å­—
                transcript_text = transcript_text.strip()
                
                logger.info(f"âœ“ Transcript é•·åº¦: {len(transcript_text)} å­—ç¬¦")
                
                if len(transcript_text) < 50:
                    logger.warning("Transcript å…§å®¹å¤ªå°‘ï¼Œå¯èƒ½æŠ“å–å¤±æ•—")
                    return
                
            except Exception as e:
                logger.error(f"æŠ“å– transcript å¤±æ•—: {e}")
                return
            
            # ä¸Šå‚³åœ–ç‰‡åˆ° GitHub
            logger.info("ä¸Šå‚³å°é¢åœ–ç‰‡åˆ° GitHub...")
            github_img_url = self.github_uploader.upload_image(episode_info['img_src'])
            
            # ç¿»è­¯ transcriptï¼ˆæ ¹æ“šè¨­å®šæ±ºå®šæ˜¯å¦ç¿»è­¯ï¼‰
            if self.enable_translation:
                logger.info("ç¿»è­¯ transcript...")
                translated_paragraphs = self.translate_transcript(transcript_text, episode_info['title'])
                
                if not translated_paragraphs:
                    logger.error("ç¿»è­¯å¤±æ•—")
                    return
            else:
                logger.info("âš ï¸  è·³éç¿»è­¯ - åªä¿å­˜è‹±æ–‡åŸæ–‡")
                # ä¸ç¿»è­¯ï¼Œå‰µå»ºåªæœ‰è‹±æ–‡çš„æ®µè½
                paragraphs = transcript_text.split('\n')
                paragraphs = [p.strip() for p in paragraphs if p.strip()]
                
                translated_paragraphs = []
                for i, para in enumerate(paragraphs):
                    translated_paragraphs.append({
                        'index': i,
                        'english': para,
                        'chinese': '',  # ç©ºçš„ä¸­æ–‡
                        'timestamp': None,
                        'speaker': None
                    })
            
            # æº–å‚™é›†æ•¸æ•¸æ“š
            episode_data = {
                'url': episode_info['url'],
                'title': episode_info['title'],
                'img_src': github_img_url,
                'series': episode_info['series'],
                'series_name': episode_info['series_info'].get('name', ''),
                'series_name_zh': episode_info['series_info'].get('name_zh', ''),
                'series_emoji': episode_info['series_info'].get('emoji', 'ğŸ™ï¸'),
                'featured_speaker': episode_info['speaker'],
                'transcript_en': transcript_text,
                'transcript_zh': translated_paragraphs,
                'scraped_at': datetime.now().isoformat()
            }
            
            # ä¿å­˜åˆ° MongoDB
            logger.info("\n" + "-" * 70)
            self.save_to_mongodb(episode_data)
            logger.info("-" * 70 + "\n")
            
            # ç™¼é€éƒµä»¶
            logger.info("-" * 70)
            self.send_email(episode_data)
            logger.info("-" * 70 + "\n")
            
            logger.info("=" * 70)
            logger.info(f"âœ“ {episode_info['title']} è™•ç†å®Œæˆï¼")
            logger.info("=" * 70)
            
        except Exception as e:
            logger.error(f"è™•ç†é›†æ•¸å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())

    # ==============================================================================
    # =====â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼ æ ¸å¿ƒä¿®æ”¹å€åŸŸ â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼=====
    # ==============================================================================
    def translate_transcript(self, transcript_text, title, batch_size=50):
        """ç¿»è­¯ transcript ç‚ºç¹é«”ä¸­æ–‡ï¼ˆæ®µè½å½¢å¼ï¼Œåˆ†æ‰¹ç¿»è­¯ï¼‰- (å·²ä¿®æ”¹ï¼Œå¢åŠ è¬›è€…ä¸Šä¸‹æ–‡è¿½è¹¤)"""
        logger.info("é–‹å§‹ç¿»è­¯ transcript (ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‚è¼¯)...")
        logger.debug(f"æ–‡å­—é•·åº¦: {len(transcript_text)} å­—ç¬¦")

        try:
            # ä¿æŒåŸå§‹åˆ†æ®µ
            paragraphs = transcript_text.split('\n')
            paragraphs = [p.strip() for p in paragraphs if p.strip()]

            logger.info(f"åŸå§‹åˆ†æ®µ: {len(paragraphs)} å€‹æ®µè½")

            # ç”¨æ–¼æå–æ™‚é–“æˆ³çš„å‡½æ•¸
            def extract_timestamp(text):
                import re
                timestamp_pattern = r'^\[(\d{1,2}:\d{2}(?::\d{2})?)\]\s*'
                timestamp_match = re.match(timestamp_pattern, text)
                if timestamp_match:
                    timestamp = timestamp_match.group(1)
                    clean_text = text[timestamp_match.end():].strip()
                    return timestamp, clean_text
                return None, text

            processed_paragraphs = []
            current_speaker = None  # ç‹€æ…‹è®Šæ•¸ï¼šè¿½è¹¤ç•¶å‰è¬›è€…

            # ç”¨æ–¼è­˜åˆ¥ä¸€è¡Œæ–‡å­—æ˜¯å¦å¯èƒ½ç‚ºè¬›è€…åç¨±çš„æ­£è¦è¡¨é”å¼
            # æ¢ä»¶ï¼š1-3å€‹å–®è©ï¼Œé¦–å­—æ¯å¤§å¯«ï¼Œä¸ä»¥æ¨™é»ç¬¦è™Ÿçµå°¾
            speaker_name_pattern = re.compile(r'^[A-Z][a-zA-Z\s]+$')

            for para in paragraphs:
                timestamp, clean_text = extract_timestamp(para)

                # åˆ¤æ–·æ­¤è¡Œæ˜¯å¦ç‚ºè¬›è€…åç¨±
                # æ¢ä»¶: 1. ç¬¦åˆæ­£è¦è¡¨é”å¼ 2. å–®è©æ•¸è¼ƒå°‘ (<= 3) 3. ä¸æ˜¯ä¸€å¥å®Œæ•´çš„é•·å¥
                if speaker_name_pattern.match(clean_text) and len(clean_text.split()) <= 3:
                    # æª¢æŸ¥æ˜¯å¦ç‚ºå¸¸è¦‹çš„éè¬›è€…çŸ­èªï¼Œé¿å…èª¤åˆ¤
                    if clean_text.lower() not in ['outro', 'intro', 'introduction', 'conclusion']:
                        current_speaker = clean_text  # æ›´æ–°ç•¶å‰è¬›è€…
                        logger.debug(f"âœ“ è­˜åˆ¥åˆ°æ–°è¬›è€…: {current_speaker}")
                        continue # é€™æ˜¯è¬›è€…æ¨™ç±¤ï¼Œä¸æ˜¯å°è©±å…§å®¹ï¼Œè·³éæ­¤è¡Œ

                # å¦‚æœä¸æ˜¯è¬›è€…æ¨™ç±¤ï¼Œå‰‡è¦–ç‚ºå°è©±å…§å®¹
                # å°‡å…¶èˆ‡ç•¶å‰çš„è¬›è€…é—œè¯èµ·ä¾†
                if clean_text:
                    processed_paragraphs.append({
                        'original': para,
                        'clean': clean_text,
                        'timestamp': timestamp,
                        'speaker': current_speaker  # â˜… é—œéµï¼šé—œè¯ç•¶å‰è¬›è€…
                    })

            logger.info(f"è™•ç†å¾Œï¼Œå…±æœ‰ {len(processed_paragraphs)} æ®µæœ‰æ•ˆå°è©±éœ€è¦ç¿»è­¯")

            if not processed_paragraphs:
                logger.warning("æ²’æœ‰æ‰¾åˆ°å¯ç¿»è­¯çš„å°è©±å…§å®¹ã€‚")
                return []

            # åˆ†æ‰¹ç¿»è­¯ï¼ˆåªç¿»è­¯æ¸…ç†å¾Œçš„æ–‡æœ¬ï¼‰
            all_chinese_paragraphs = []
            total_batches = (len(processed_paragraphs) + batch_size - 1) // batch_size

            logger.info(f"å°‡åˆ†æˆ {total_batches} æ‰¹é€²è¡Œç¿»è­¯ (æ¯æ‰¹ {batch_size} æ®µ)")

            for batch_num in range(total_batches):
                start_idx = batch_num * batch_size
                end_idx = min((batch_num + 1) * batch_size, len(processed_paragraphs))
                batch_items = processed_paragraphs[start_idx:end_idx]
                batch_texts = [item['clean'] for item in batch_items]

                logger.info(f"\n--- ç¿»è­¯æ‰¹æ¬¡ {batch_num + 1}/{total_batches} (æ®µè½ {start_idx + 1}-{end_idx}) ---")

                paragraphs_json = json.dumps(batch_texts, ensure_ascii=False, indent=2)

                prompt = f"""è«‹å°‡ä»¥ä¸‹ JSON æ•¸çµ„ä¸­çš„è‹±æ–‡æ®µè½ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å¿…é ˆè¿”å›ä¸€å€‹ç´” JSON æ•¸çµ„æ ¼å¼: ["ä¸­æ–‡1", "ä¸­æ–‡2", ...]
2. ä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ï¼Œç›´æ¥è¿”å›æ•¸çµ„
3. æ¯å€‹è‹±æ–‡æ®µè½å°æ‡‰ä¸€å€‹ç¹é«”ä¸­æ–‡ç¿»è­¯
4. ä¿æŒæ•¸çµ„é †åºå’Œé•·åº¦ä¸€è‡´
5. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§ï¼ˆç‰¹åˆ¥æ˜¯é‡‘èã€äº¤æ˜“è¡“èªï¼‰
6. ç¿»è­¯æµæš¢è‡ªç„¶ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡

æ’­å®¢æ¨™é¡Œ: {title}

è‹±æ–‡æ®µè½æ•¸çµ„:
{paragraphs_json}

è«‹è¿”å›å°æ‡‰çš„ç¹é«”ä¸­æ–‡ç¿»è­¯æ•¸çµ„ï¼ˆæ ¼å¼ç¤ºä¾‹: ["æ®µè½1ç¿»è­¯", "æ®µè½2ç¿»è­¯", ...]ï¼‰ï¼š
"""

                logger.debug(f"èª¿ç”¨ OpenAI API (æ‰¹æ¬¡ {batch_num + 1})...")
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èäº¤æ˜“é ˜åŸŸç¿»è­¯å°ˆå®¶ï¼Œæ“…é•·å°‡è‹±æ–‡æ’­å®¢å…§å®¹ç¿»è­¯æˆæº–ç¢ºæµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚è«‹åš´æ ¼è¿”å› JSON æ•¸çµ„æ ¼å¼ï¼Œä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )

                response_text = response.choices[0].message.content.strip()
                logger.debug(f"API éŸ¿æ‡‰é•·åº¦: {len(response_text)}")

                chinese_paragraphs = json.loads(response_text)

                if isinstance(chinese_paragraphs, dict):
                    possible_keys = ['translations', 'paragraphs', 'chinese', 'result', 'data', 'ç¿»è­¯çµæœ', 'ç¿»è¯‘ç»“æœ', 'ç¿»è­¯', 'ä¸­æ–‡', 'æ®µè½', 'çµæœ']
                    for key in possible_keys:
                        if key in chinese_paragraphs:
                            chinese_paragraphs = chinese_paragraphs[key]
                            logger.debug(f"å¾éµ '{key}' æå–æ•¸çµ„")
                            break

                if not isinstance(chinese_paragraphs, list):
                    logger.error(f"è¿”å›é¡å‹éŒ¯èª¤: {type(chinese_paragraphs)}")
                    return None

                if len(chinese_paragraphs) != len(batch_texts):
                    logger.warning(f"ç¿»è­¯æ•¸é‡ä¸åŒ¹é…: é æœŸ {len(batch_texts)}ï¼Œå¯¦éš› {len(chinese_paragraphs)}")

                all_chinese_paragraphs.extend(chinese_paragraphs)

                logger.info(f"âœ“ æ‰¹æ¬¡ {batch_num + 1} ç¿»è­¯å®Œæˆ (Token: {response.usage.total_tokens})")

            combined_translations = []
            for i, (item, zh) in enumerate(zip(processed_paragraphs, all_chinese_paragraphs)):
                combined_translations.append({
                    'index': i,
                    'english': item['clean'],
                    'chinese': zh,
                    'timestamp': item['timestamp'],
                    'speaker': item['speaker']
                })

            logger.info(f"âœ“ æ‰€æœ‰ç¿»è­¯å®Œæˆï¼Œå…± {len(combined_translations)} å€‹æ®µè½")

            return combined_translations

        except Exception as e:
            logger.error(f"ç¿»è­¯å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return None
    # ==============================================================================
    # =====â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² æ ¸å¿ƒä¿®æ”¹å€åŸŸ â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²=====
    # ==============================================================================

    def save_to_mongodb(self, episode_data):
        """ä¿å­˜é›†æ•¸åˆ° MongoDB"""
        try:
            if self.test_mode:
                logger.warning("[æ¸¬è©¦æ¨¡å¼] è·³éä¿å­˜åˆ° MongoDB")
                return True

            logger.debug(f"ä¿å­˜é›†æ•¸åˆ° MongoDB: {episode_data['url']}")
            result = self.episodes_collection.update_one(
                {'url': episode_data['url']},
                {'$set': episode_data},
                upsert=True
            )

            if result.upserted_id:
                logger.info(f"âœ“ æ–°é›†æ•¸å·²ä¿å­˜åˆ° MongoDB (ID: {result.upserted_id})")
            else:
                logger.info(f"âœ“ é›†æ•¸å·²æ›´æ–°åˆ° MongoDB")

            return True
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ° MongoDB å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False

    def send_email(self, episode_data):
        """ç™¼é€éƒµä»¶ï¼ˆä¸ä¿ç•™å‚™ä»½ï¼‰"""
        logger.info("æº–å‚™ç™¼é€éƒµä»¶...")

        try:
            # å‰µå»ºéƒµä»¶
            msg = MIMEMultipart('alternative')
            msg['From'] = self.mail_token
            msg['To'] = ', '.join(self.recipients)
            
            # å¤šç¨®æ–¹æ³•å˜—è©¦ä¸ä¿å­˜å‚™ä»½
            msg['X-Gm-No-Archive'] = '1'  # Gmail å°ˆç”¨ï¼šä¸ä¿å­˜å‚™ä»½
            msg['Disposition-Notification-To'] = ''  # ä¸è¦æ±‚é€é”é€šçŸ¥
            
            # æ³¨æ„ï¼šGmail çš„ã€Œå·²ç™¼é€ã€ä¿å­˜è¡Œç‚ºå¯èƒ½å—å¸³è™Ÿè¨­å®šå½±éŸ¿
            # å¦‚æœä»¥ä¸Šæ–¹æ³•ç„¡æ•ˆï¼Œè«‹å‰å¾€ Gmail è¨­å®š â†’ ä¸€èˆ¬è¨­å®š â†’ å–æ¶ˆå‹¾é¸ã€Œå°‡å‰¯æœ¬ä¿å­˜åœ¨å·²ç™¼é€éƒµä»¶ä¸­ã€

            # éƒµä»¶ä¸»é¡Œ
            series_emoji = episode_data.get('series_emoji', 'ğŸ™ï¸')
            series_name_zh = episode_data.get('series_name_zh', '')
            subject_parts = [f"{series_emoji} Top Traders Unplugged"]

            if series_name_zh:
                subject_parts.append(f"- {series_name_zh}")

            if episode_data.get('featured_speaker'):
                subject_parts.append(f"- {episode_data['featured_speaker']}")

            subject_parts.append(f"- {episode_data['title']}")

            msg['Subject'] = ' '.join(subject_parts)

            # ç”Ÿæˆ HTML å…§å®¹
            html_content = self._generate_html_email(episode_data)

            # æ·»åŠ  HTML éƒ¨åˆ†
            part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(part)

            # ç™¼é€éƒµä»¶
            logger.debug("é€£æ¥åˆ° Gmail SMTP æœå‹™å™¨...")
            logger.debug(f"  ä½¿ç”¨å¸³è™Ÿ: {self.mail_token}")
            logger.debug(f"  å¯†ç¢¼é•·åº¦: {len(self.app_password)}")
            logger.info("  å·²è¨­å®šä¸ä¿å­˜éƒµä»¶å‚™ä»½åˆ°ã€Œå·²ç™¼é€ã€æ–‡ä»¶å¤¾")

            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                logger.debug("  SMTP é€£æ¥å·²å»ºç«‹")
                server.set_debuglevel(0)  # è¨­ç‚º 1 å¯çœ‹åˆ°æ›´å¤šèª¿è©¦ä¿¡æ¯
                server.login(self.mail_token, self.app_password)
                logger.debug("  ç™»å…¥æˆåŠŸ")
                server.send_message(msg)
                logger.debug("  éƒµä»¶å·²ç™¼é€")

            logger.info(f"âœ“ éƒµä»¶å·²ç™¼é€")
            return True

        except smtplib.SMTPAuthenticationError as e:
            logger.error(f"Gmail èªè­‰å¤±æ•—: {e}")
            logger.error("è«‹æª¢æŸ¥:")
            logger.error("  1. MAIL_TOKEN æ˜¯å¦ç‚ºå®Œæ•´çš„ Gmail åœ°å€")
            logger.error("  2. APP_PASSWORD æ˜¯å¦æ­£ç¢ºï¼ˆæ‡‰ä½¿ç”¨ Google App Passwordï¼Œè€Œéå¸³è™Ÿå¯†ç¢¼ï¼‰")
            logger.error("  3. æ˜¯å¦å·²å•Ÿç”¨ Google å…©æ­¥é©Ÿé©—è­‰ä¸¦ç”Ÿæˆæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼")
            logger.debug(traceback.format_exc())
            return False
        except Exception as e:
            logger.error(f"ç™¼é€éƒµä»¶å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False

    def _generate_html_email(self, episode_data):
        """ç”Ÿæˆ HTML éƒµä»¶å…§å®¹"""
        html_parts = []

        series_emoji = episode_data.get('series_emoji', 'ğŸ™ï¸')
        series_name = episode_data.get('series_name', 'Podcast')
        series_name_zh = episode_data.get('series_name_zh', 'æ’­å®¢')
        featured_speaker = episode_data.get('featured_speaker', '')

        html_parts.append(f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            font-size: 16px;  /* åŸºç¡€å­—ä½“ï¼š16pxï¼ˆåŸ14pxï¼‰ */
        }}
        .container {{
            background-color: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .series-badge {{
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 1em;  /* 16px */
            margin-bottom: 15px;
            font-weight: 600;
        }}
        .speaker-badge {{
            display: inline-block;
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 1em;  /* 16px */
            margin-bottom: 15px;
            margin-left: 10px;
            font-weight: 600;
        }}
        h1 {{
            color: #1a1a1a;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
            margin-bottom: 25px;
            font-size: 2em;  /* 32pxï¼ˆåŸ28pxï¼‰ */
        }}
        h2 {{
            font-size: 1.5em;  /* 24pxï¼ˆåŸ20pxï¼‰ */
        }}
        .cover-image {{
            text-align: center;
            margin: 30px 0;
        }}
        .cover-image img {{
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        .meta {{
            color: #666;
            font-size: 1em;  /* 16pxï¼ˆåŸ14pxï¼‰ */
            margin-bottom: 30px;
            padding: 15px;
            background-color: #f8f9fa;
            border-left: 4px solid #667eea;
        }}
         .transcript-section {{
             margin-top: 30px;
         }}
         .paragraph-block {{
             margin-bottom: 25px;
             padding: 0;
             background-color: transparent;
             position: relative;
         }}
         .speaker-header {{
             display: flex;
             align-items: center;
             gap: 10px;
             margin-bottom: 12px;
         }}
         .speaker-name-badge {{ /* Renamed for clarity */
             display: inline-flex;
             align-items: center;
             padding: 6px 12px;
             border-radius: 20px;
             font-weight: 600;
             font-size: 1em;  /* 16pxï¼ˆåŸ14pxï¼‰ */
             color: white;
             box-shadow: 0 2px 4px rgba(0,0,0,0.1);
         }}
         .speaker-name-badge.speaker-1 {{
             background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
         }}
         .speaker-name-badge.speaker-2 {{
             background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
         }}
         .speaker-name-badge.speaker-3 {{
             background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
         }}
         .speaker-name-badge.speaker-4 {{
             background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
         }}
         .speaker-name-badge.speaker-5 {{
             background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
         }}
         .speaker-name-badge.speaker-default {{
             background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
         }}
         .timestamp {{
             font-size: 0.875em;  /* 14pxï¼ˆåŸ12pxï¼‰ */
             color: #999;
             font-family: 'Courier New', monospace;
             padding: 4px 8px;
             background-color: #f5f5f5;
             border-radius: 4px;
         }}
         .content-card {{
             background-color: white;
             border-radius: 12px;
             padding: 20px;
             box-shadow: 0 2px 8px rgba(0,0,0,0.08);
             border-left: 4px solid #e0e0e0;
         }}
         .content-card.has-speaker-1 {{
             border-left-color: #667eea;
         }}
         .content-card.has-speaker-2 {{
             border-left-color: #f5576c;
         }}
         .content-card.has-speaker-3 {{
             border-left-color: #00f2fe;
         }}
         .content-card.has-speaker-4 {{
             border-left-color: #38f9d7;
         }}
         .content-card.has-speaker-5 {{
             border-left-color: #fa709a;
         }}
         .english {{
            color: #2c3e50;
            line-height: 1.7;
            margin-bottom: 15px;
            padding: 0;
            background-color: transparent;
            border-radius: 0;
            border-left: none;
            font-size: 1.0625em;  /* 17pxï¼ˆåŸ15pxï¼‰ */
         }}
         .english::before {{
             content: "ğŸ‡¬ğŸ‡§ ";
             font-weight: bold;
             opacity: 0.6;
         }}
         .chinese {{
             color: #34495e;
             background-color: #f8f9fa;
             padding: 15px;
             border-radius: 8px;
             line-height: 1.7;
             font-size: 1.0625em;  /* 17pxï¼ˆåŸ15pxï¼‰ */
         }}
         .chinese::before {{
             content: "ğŸ‡¹ğŸ‡¼ ";
             font-weight: bold;
         }}
        .divider {{
            border-top: 1px solid #e0e0e0;
            margin: 20px 0;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e0e0e0;
            color: #999;
            font-size: 0.9em;  /* 14.4pxï¼ˆåŸ12.6pxï¼‰ */
            text-align: center;
        }}
        a {{
            color: #667eea;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="series-badge">{series_emoji} {series_name} / {series_name_zh}</div>
        {f'<div class="speaker-badge">â­ {featured_speaker}</div>' if featured_speaker else ''}
        <h1>{episode_data['title']}</h1>
        
        <div class="cover-image">
            <img src="{episode_data['img_src']}" alt="Episode Cover">
        </div>
        
        <div class="meta">
            <strong>åŸæ–‡é€£çµ / Source:</strong> <a href="{episode_data['url']}" target="_blank">{episode_data['url']}</a><br>
            <strong>æŠ“å–æ™‚é–“ / Scraped:</strong> {episode_data['scraped_at']}
        </div>
        
        <div class="transcript-section">
            <h2>ğŸ“ Transcript / æ–‡å­—ç¨¿</h2>
""")

        # ç‚ºä¸åŒè¬›è€…åˆ†é…é¡è‰²ç·¨è™Ÿ
        speaker_colors = {}
        color_index = 1
        previous_speaker = None  # è¿½è¹¤ä¸Šä¸€å€‹è¬›è€…

        for para in episode_data['transcript_zh']:
            # ç²å–è¬›è€…ä¸¦åˆ†é…é¡è‰²
            speaker = para.get('speaker', '')
            timestamp = para.get('timestamp', '')

            if speaker and speaker not in speaker_colors:
                speaker_colors[speaker] = color_index
                color_index = (color_index % 5) + 1  # å¾ªç’°ä½¿ç”¨ 1-5

            speaker_class_num = speaker_colors.get(speaker, 'default')
            speaker_class = f"speaker-{speaker_class_num}"

            # ç”Ÿæˆé ­éƒ¨ï¼ˆè¬›è€…æ¨™ç±¤ + æ™‚é–“æˆ³ï¼‰
            # â˜… åªåœ¨è¬›è€…æ”¹è®Šæ™‚é¡¯ç¤ºè¬›è€…æ¨™ç±¤
            header_html = ""
            if speaker or timestamp:
                header_parts = []
                
                # åªæœ‰ç•¶è¬›è€…æ”¹è®Šæ™‚æ‰é¡¯ç¤ºè¬›è€…æ¨™ç±¤
                if speaker and speaker != previous_speaker:
                    header_parts.append(f'<span class="speaker-name-badge {speaker_class}">{speaker}</span>')
                    previous_speaker = speaker  # æ›´æ–°ä¸Šä¸€å€‹è¬›è€…
                
                # æ™‚é–“æˆ³å§‹çµ‚é¡¯ç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
                if timestamp:
                    header_parts.append(f'<span class="timestamp">ğŸ• {timestamp}</span>')
                
                if header_parts:  # åªæœ‰ç•¶æœ‰å…§å®¹æ™‚æ‰å‰µå»º header
                    header_html = f'<div class="speaker-header">{"".join(header_parts)}</div>'

            card_class = f"has-speaker-{speaker_class_num}" if speaker else ""

            html_parts.append(f"""
            <div class="paragraph-block">
                {header_html}
                <div class="content-card {card_class}">
                    <div class="english">{para['english']}</div>
                    {'<div class="chinese">' + para['chinese'] + '</div>' if para.get('chinese') else ''}
                </div>
            </div>
""")

        html_parts.append("""
        </div>
        
        <div class="footer">
            æ­¤éƒµä»¶ç”± Top Traders Unplugged çˆ¬èŸ²è‡ªå‹•ç™¼é€<br>
            åœ–ç‰‡æ°¸ä¹…ä¿å­˜æ–¼ GitHub | Powered by Async Playwright + OpenAI
        </div>
    </div>
</body>
</html>
""")

        return ''.join(html_parts)

    async def scrape_all(self):
        """åŸ·è¡Œçˆ¬èŸ²ä»»å‹™ - Async ç‰ˆæœ¬"""
        logger.info("\n" + "=" * 70)
        logger.info("é–‹å§‹åŸ·è¡Œçˆ¬èŸ²ä»»å‹™")
        logger.info("=" * 70)

        # åœ¨ Kaggle ç’°å¢ƒä¸­è¨­ç½® Playwright
        await setup_playwright_in_kaggle()

        await self.scrape_latest_episodes()

        logger.debug("æ¸…ç†è³‡æº...")
        self.mongo_client.close()
        logger.info("\nâœ“ æ‰€æœ‰ä»»å‹™å®Œæˆï¼")


async def main_async():
    """Async main function for both local and Kaggle environments"""
    # è¨­ç½® Windows æ§åˆ¶å°ç·¨ç¢¼
    import sys
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

    parser = argparse.ArgumentParser(description='Top Traders Unplugged æ’­å®¢çˆ¬èŸ²')
    parser.add_argument('--test', action='store_true',
                       help='æ¸¬è©¦æ¨¡å¼ï¼šå¼·åˆ¶é‡æ–°æŠ“å–ï¼Œä¸æ›´æ–° MongoDB è¨˜éŒ„')
    parser.add_argument('--no-translation', action='store_true',
                       help='ç¦ç”¨ç¿»è­¯åŠŸèƒ½ï¼šåªä¿å­˜è‹±æ–‡åŸæ–‡ï¼Œä¸å‘¼å« OpenAI API')
    args = parser.parse_args()
    
    enable_translation = not args.no_translation  # é»˜èªå•Ÿç”¨ç¿»è­¯

    logger.info("=" * 70)
    logger.info("  Top Traders Unplugged æ’­å®¢çˆ¬èŸ²")
    logger.info("  Async Playwright + MongoDB + OpenAI + Gmail + GitHub")
    logger.info("=" * 70)
    logger.info(f"æ—¥èªŒæ–‡ä»¶: {log_file}")

    if args.test:
        logger.warning("\n[æ¸¬è©¦æ¨¡å¼] æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
        logger.warning("   - å°‡é‡æ–°æŠ“å–å·²æŠ“å–éçš„é›†æ•¸")
        logger.warning("   - ä¸æœƒæ›´æ–° MongoDB è¨˜éŒ„\n")
    
    if not enable_translation:
        logger.warning("\n[ç¿»è­¯å·²ç¦ç”¨] ç¿»è­¯åŠŸèƒ½å·²é—œé–‰")
        logger.warning("   - åªæœƒä¿å­˜è‹±æ–‡åŸæ–‡")
        logger.warning("   - ä¸æœƒå‘¼å« OpenAI API")
        logger.warning("   - éƒµä»¶ä¸­ä¸æœƒé¡¯ç¤ºä¸­æ–‡ç¿»è­¯\n")
    
    try:
        scraper = TopTraderScraper(test_mode=args.test, enable_translation=enable_translation)
        await scraper.scrape_all()
    except ValueError as e:
        logger.error(f"é…ç½®éŒ¯èª¤: {e}")
        logger.info("è«‹æª¢æŸ¥ .env æ–‡ä»¶é…ç½®")
        return
    except Exception as e:
        logger.error(f"ç¨‹åºéŒ¯èª¤: {e}")
        logger.debug(traceback.format_exc())

    logger.info("\n" + "=" * 70)
    logger.info("  ä»»å‹™çµæŸ")
    logger.info("=" * 70)
    logger.info(f"è©³ç´°æ—¥èªŒå·²ä¿å­˜åˆ°: {log_file}")


def main():
    """Synchronous wrapper for command-line usage"""
    try:
        # æª¢æ¸¬æ˜¯å¦åœ¨å·²æœ‰çš„ event loop ä¸­ï¼ˆå¦‚ Kaggleï¼‰
        loop = asyncio.get_running_loop()
        logger.error("æª¢æ¸¬åˆ°å·²é‹è¡Œçš„ event loopã€‚")
        logger.error("åœ¨ Kaggle/Jupyter ä¸­ï¼Œè«‹ç›´æ¥ä½¿ç”¨: await main_async()")
        return
    except RuntimeError:
        # æ²’æœ‰é‹è¡Œä¸­çš„ loopï¼Œæ­£å¸¸åŸ·è¡Œ
        asyncio.run(main_async())


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
æ‰¹é‡ Dailymotion è¦–é »ä¸‹è¼‰å™¨
å°ˆç‚º Evan ç³»åˆ—è¦–é »è¨­è¨ˆ
ä¿®æ”¹ç‰ˆï¼šé †åºä¸‹è¼‰ï¼Œæ¯æ¬¡ä¸‹è¼‰å¾Œä¼‘æ¯æŒ‡å®šæ™‚é–“
"""

import os
import sys
import requests
import re
import json
import time
from urllib.parse import urljoin
from pathlib import Path

# è¦–é »åˆ—è¡¨æ•¸æ“š
VIDEO_LIST = [
    # Evan æŒ‡æ¨™ç¤ºç¯„ç³»åˆ—
    # {
    #     "date": "20250302",
    #     "title": "EvanæŒ‡æ¨™ç¤ºç¯„",
    #     "url": "https://dai.ly/k2SbEZbmP4zlcCDttky",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250309",
    #     "title": "EvanæŒ‡æ¨™ç¤ºç¯„",
    #     "url": "https://dai.ly/k12MpdqZOuexYADtt26",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250316",
    #     "title": "EvanæŒ‡æ¨™ç¤ºç¯„",
    #     "url": "https://dai.ly/k6phxwIGeNn8ksDrRoY",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250323",
    #     "title": "EvanæŒ‡æ¨™ç¤ºç¯„",
    #     "url": "https://dai.ly/k5nJbTwmwFlBHkDrRig",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250330",
    #     "title": "EvanæŒ‡æ¨™ç¤ºç¯„",
    #     "url": "https://dai.ly/k5ohjU4x4sZuySDrRaQ",
    #     "category": "Evan"
    # },
    # # Evan å››æœˆç³»åˆ—
    # {
    #     "date": "20250406",
    #     "title": "Evan",
    #     "url": "https://dai.ly/k3uJNpXP1P1YHeDrNWk",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250413",
    #     "title": "Evan",
    #     "url": "https://dai.ly/k5S6IWSwnyLDUADdKqi",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250420",
    #     "title": "Evan",
    #     "url": "https://dai.ly/k4BhkhDqoV1XK9DdJQG",
    #     "category": "Evan"
    # },
    # {
    #     "date": "20250427",
    #     "title": "Evan",
    #     "url": "https://dai.ly/k1gilUnlBXffc9DdJOw",
    #     "category": "Evan"
    # },
    # # å…­æœˆéŒ„å½±ç³»åˆ—
    # {
    #     "date": "20250601",
    #     "title": "å…­æœˆéŒ„å½±",
    #     "url": "https://dai.ly/k3cAldu0Abe2t4Dce1C",
    #     "category": "å…­æœˆéŒ„å½±"
    # },
    # {
    #     "date": "20250608",
    #     "title": "å…­æœˆéŒ„å½±",
    #     "url": "https://dai.ly/k13OAErmzmbSBCDdup4",
    #     "category": "å…­æœˆéŒ„å½±"
    # },
    # {
    #     "date": "20250615",
    #     "title": "å…­æœˆéŒ„å½±",
    #     "url": "https://dai.ly/k3vtkVI6imtIYbDgisS",
    #     "category": "å…­æœˆéŒ„å½±"
    # },
    # {
    #     "date": "20250622",
    #     "title": "å…­æœˆéŒ„å½±",
    #     "url": "https://dai.ly/k4rPETjJJ6JVSMDivzY",
    #     "category": "å…­æœˆéŒ„å½±"
    # },
    # {
    #     "date": "20250629",
    #     "title": "å…­æœˆéŒ„å½±",
    #     "url": "https://dai.ly/k7IkBjMpBsfIT9DkXT0",
    #     "category": "å…­æœˆéŒ„å½±"
    # },
    # # Feng ç³»åˆ—
    # {
    #     "date": "20250616",
    #     "title": "Feng Part1",
    #     "url": "https://dai.ly/ks8AfDqYosbWOpDgJVM",
    #     "category": "Feng"
    # },
    # {
    #     "date": "20250616",
    #     "title": "Feng Part2",
    #     "url": "https://dai.ly/kryB7XTzDuBvbsDgJVK",
    #     "category": "Feng"
    # },
    # {
    #     "date": "20250616",
    #     "title": "Feng Part3",
    #     "url": "https://dai.ly/k5O2vhyEr4i9myDgKg8",
    #     "category": "Feng"
    # },
    # {
    #     "date": "20250630",
    #     "title": "Feng Part1",
    #     "url": "https://dai.ly/k1jqw7wpSs67zgDlebW",
    #     "category": "Feng"
    # },
    # {
    #     "date": "20250630",
    #     "title": "Feng Part2",
    #     "url": "https://dai.ly/k4cJwzh0549HznDlekG",
    #     "category": "Feng"
    # },
    # # FOMC ç³»åˆ—
    # {
    #     "date": "20250618",
    #     "title": "FOMC Part1",
    #     "url": "https://dai.ly/k5WjJ9aYyteKLgDhpfM",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250618",
    #     "title": "FOMC Part2",
    #     "url": "https://dai.ly/k3IHCzl8GENCzMDhph8",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250618",
    #     "title": "FOMC Part3",
    #     "url": "https://dai.ly/k3EryXrBZhjOBbDhpmI",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250618",
    #     "title": "FOMC Part4",
    #     "url": "https://dai.ly/k6qLyg1nNH8ucEDhpmK",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250706",
    #     "title": "FOMC",
    #     "url": "https://dai.ly/k2p1kJzlJLQOvsDns1Y",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250713",
    #     "title": "FOMC",
    #     "url": "https://dai.ly/k14iU8Eyti07a8DqlhW",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250720",
    #     "title": "FOMC (ç„¡è²)",
    #     "url": "https://dai.ly/k1p9A7iupdf1LZDtmOi",
    #     "category": "FOMC"
    # },
    # {
    #     "date": "20250727",
    #     "title": "FOMC",
    #     "url": "https://dai.ly/k1HMgyh29Vy5H2Dw6De",
    #     "category": "FOMC"
    # },

    # {
    #     "date": "20250803",
    #     "title": "",
    #     "url": "https://dai.ly/k3TorJITDenrebDzdZO",
    #     "category": ""
    # },
    # {
    #     "date": "20250810",
    #     "title": "",
    #     "url": "https://dai.ly/k4VWX633An9C6NDC5gU",
    #     "category": ""
    # },
    # {
    #     "date": "20250817",
    #     "title": "",
    #     "url": "https://dai.ly/knuvFmC19J9AwaDF7Wc",
    #     "category": ""
    # },
    # {
    #     "date": "20250824",
    #     "title": "",
    #     "url": "https://dai.ly/k34VcMVuhQ5Ve8DIa20",
    #     "category": ""
    # },
    # {
    #     "date": "20250831",
    #     "title": "VIXèˆ‡æŒ‡æ•¸å‰µé«˜",
    #     "url": "https://dai.ly/k4YfFXCbCJ8jmzDKVNQ",
    #     "category": "VIXèˆ‡æŒ‡æ•¸å‰µé«˜"
    # },
    # {
    #     "date": "20250907",
    #     "title": "avoid lunch hours",
    #     "url": "https://dai.ly/k72B2LGkqBoLsODNFd4",
    #     "category": "avoid lunch hours"
    # },
    # {
    #     "date": "20250914",
    #     "title": "",
    #     "url": "https://dai.ly/k4bNknOFZ8zqOvDQlze",
    #     "category": ""
    # },
    # {
    #     "date": "20250921",
    #     "title": "æ”¶åœ¨collarä¹‹ä¸Š å°±buy the dip",
    #     "url": "https://dai.ly/k15hdZ3HS9xOuYDTdBi",
    #     "category": "æ”¶åœ¨collarä¹‹ä¸Š å°±buy the dip"
    # },
    # {
    #     "date": "20250928",
    #     "title": "é€™é€±å¯èƒ½æ˜¯ Bear çš„æœ€å¾Œçª—å£",
    #     "url": "https://dai.ly/k10oapvDVn2muMDW2Lk",
    #     "category": "é€™é€±å¯èƒ½æ˜¯ Bear çš„æœ€å¾Œçª—å£"
    # }
    # {
    #     "date": "20251012",
    #     "title": "å°å¿ƒ VIX åˆ° 25 ä¹‹ä¸Š ",
    #     "url": "https://dai.ly/k4N5xqFXdhgjOhE0Vg2",
    #     "category": "Generate"
    # },
    # {
    #     "date": "2025-12-15",
    #     "title": "trendline & volume profile ",
    #     "url": " https://dai.ly/k3B15npViEfsIdEqLvo",
    #     "category": "trendline & volume profile"
    # },
    # {
    #     "date": "2025-12-21",
    #     "title": "2026 jan new high",
    #     "url": "https://dai.ly/k1R4FmICvtm96DEtZnK",
    #     "category": "2026 jan new high"
    # },
    # {
    #     "date": "2025-12-28",
    #     "title": " fp fp ce spread  ",
    #     "url": "https://dai.ly/kcUQOHjMgtBy8REwXsC",
    #     "category": "fp fp ce spread"
    # },
    # {
    #     "date": "2026-01-04",
    #     "title": "Captain Condor",
    #     "url": "https://dai.ly/k5IMvJho26WpACEAkRQ",
    #     "category": "Captain Condor"
    # },
    # {
    #     "date": "2026-01-11",
    #     "title": "2026 New guidance",
    #     "url": "https://dai.ly/k5VFJTe1MP6ZpqEDSvC",
    #     "category": "2026 New guidance"
    # },
    # {
    #     "date": "2026-01-18",
    #     "title": "Kevin Warsh and superboy",
    #     "url": "https://dai.ly/kC6GE06533vsCLEH8JW",
    #     "category": "Kevin Warsh and superboy"
    # },
    {
        "date": "2026-01-18",
        "title": "feng ç¶“é©—ç²¾è¯",
        "url": "https://dai.ly/k1qGUheiUO85IUEKpPq",
        "category": "feng best sharing"
    },
]


class SequentialDailymotionDownloader:
    def __init__(self, rest_interval=120):  # é è¨­ä¼‘æ¯ 2 åˆ†é˜ (120 ç§’)
        """é †åºä¸‹è¼‰å™¨åˆå§‹åŒ–"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.rest_interval = rest_interval  # ä¼‘æ¯é–“éš”ï¼ˆç§’ï¼‰
        self.download_stats = {
            'success': 0,
            'failed': 0,
            'skipped': 0,
            'total': 0
        }

    def set_rest_interval(self, seconds):
        """è¨­å®šä¼‘æ¯é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰"""
        self.rest_interval = seconds
        print(f"ä¼‘æ¯é–“éš”å·²è¨­å®šç‚º {seconds} ç§’ ({seconds / 60:.1f} åˆ†é˜)")

    def sanitize_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶å"""
        invalid_chars = r'<>:"/\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        return filename.strip()

    # def download_with_yt_dlp_single(self, video_info, output_dir):
    #     """ä½¿ç”¨ yt-dlp ä¸‹è¼‰å–®å€‹è¦–é »"""
    #     try:
    #         import yt_dlp
    #
    #         # å‰µå»ºåˆ†é¡æ–‡ä»¶å¤¾
    #         category_dir = os.path.join(output_dir, video_info['category'])
    #         Path(category_dir).mkdir(parents=True, exist_ok=True)
    #
    #         # è‡ªå®šç¾©æ–‡ä»¶åæ¨¡æ¿
    #         filename_template = f"{video_info['date']}_{video_info['title']}_%(id)s.%(ext)s"
    #         safe_filename = self.sanitize_filename(filename_template)
    #
    #         ydl_opts = {
    #             'outtmpl': os.path.join(category_dir, safe_filename),
    #             # 'format': 'best[height<=1080]',
    #             'format': 'best[height<=720]',
    #             'concurrent_fragment_downloads': 2,  # é™ä½ä½µç™¼æ•¸
    #             'http_chunk_size': 5242880,  # 5MB å¡Šå¤§å°
    #             'retries': 3,
    #             'fragment_retries': 3,
    #             'writesubtitles': False,
    #             'writeautomaticsub': False,
    #             'ignoreerrors': True,
    #             'quiet': False,  # é¡¯ç¤ºä¸‹è¼‰é€²åº¦
    #             'no_warnings': False,
    #         }
    #
    #         with yt_dlp.YoutubeDL(ydl_opts) as ydl:
    #             ydl.download([video_info['url']])
    #
    #         return True, f"æˆåŠŸä¸‹è¼‰: {video_info['date']} {video_info['title']}"
    #
    #     except ImportError:
    #         return False, "yt-dlp æœªå®‰è£"
    #     except Exception as e:
    #         return False, f"ä¸‹è¼‰å¤±æ•—: {str(e)}"

    def download_with_yt_dlp_single(self, video_info, output_dir):
        """ä½¿ç”¨ yt-dlp ä¸‹è¼‰å–®å€‹è¦–é »"""
        try:
            import yt_dlp

            category_dir = os.path.join(output_dir, video_info['category'])
            Path(category_dir).mkdir(parents=True, exist_ok=True)

            filename_template = f"{video_info['date']}_{video_info['title']}_%(id)s.%(ext)s"
            safe_filename = self.sanitize_filename(filename_template)

            # å®Œæ•´è¼¸å‡ºè·¯å¾‘
            outtmpl_path = os.path.join(category_dir, safe_filename)

            ydl_opts = {
                'outtmpl': outtmpl_path,
                'format': 'best[height<=1024]',
                'concurrent_fragment_downloads': 5,
                'retries': 5,
                'fragment_retries': 5,
                # --- é—œéµä¿®æ­£ ---
                'ignoreerrors': False,  # æ”¹ç‚º Falseï¼Œé€™æ¨£å¤±æ•—æ™‚æœƒæ‹‹å‡ºç•°å¸¸
                'no_warnings': False,
                'quiet': False,
                # 'cookiesfrombrowser': ('chrome',), # å¦‚æœæŒçºŒ 403ï¼Œè«‹å–æ¶ˆæ­¤è¡Œè¨»é‡‹
            }

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                # åŸ·è¡Œä¸‹è¼‰
                result = ydl.download([video_info['url']])
                # ydl.download è¿”å›çš„æ˜¯éŒ¯èª¤è¨ˆæ•¸ï¼Œ0 è¡¨ç¤ºæˆåŠŸ
                if result != 0:
                    return False, "yt-dlp ä¸‹è¼‰å›å‚³éŒ¯èª¤ç¢¼"

            return True, f"æˆåŠŸä¸‹è¼‰: {video_info['date']} {video_info['title']}"

        except Exception as e:
            return False, f"yt-dlp åŸ·è¡Œç•°å¸¸: {str(e)}"
    def check_existing_file(self, video_info, output_dir):
        """æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨"""
        category_dir = os.path.join(output_dir, video_info['category'])
        if not os.path.exists(category_dir):
            return False

        # æª¢æŸ¥å¯èƒ½çš„æ–‡ä»¶åè®Šé«”
        patterns = [
            f"{video_info['date']}_{video_info['title']}_*.mp4",
            f"{video_info['date']}_{video_info['title']}_*.mkv",
            f"{video_info['date']}_{video_info['title']}_*.webm"
        ]

        import glob
        for pattern in patterns:
            if glob.glob(os.path.join(category_dir, pattern)):
                return True
        return False

    def download_single_video(self, video_info, output_dir, skip_existing=True):
        """ä¸‹è¼‰å–®å€‹è¦–é »"""
        try:
            print(f"\nè™•ç†: [{video_info['category']}] {video_info['date']} - {video_info['title']}")
            print(f"URL: {video_info['url']}")

            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if skip_existing and self.check_existing_file(video_info, output_dir):
                print("âœ“ æª”æ¡ˆå·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰")
                self.download_stats['skipped'] += 1
                return True, "æª”æ¡ˆå·²å­˜åœ¨"

            # é¡¯ç¤ºä¸‹è¼‰é–‹å§‹æ™‚é–“
            start_time = time.time()
            print(f"â° é–‹å§‹ä¸‹è¼‰æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")

            # å˜—è©¦ä½¿ç”¨ yt-dlp ä¸‹è¼‰
            success, message = self.download_with_yt_dlp_single(video_info, output_dir)

            # è¨ˆç®—ä¸‹è¼‰è€—æ™‚
            elapsed_time = time.time() - start_time

            if success:
                print(f"âœ“ ä¸‹è¼‰å®Œæˆ (è€—æ™‚: {elapsed_time:.1f}ç§’)")
                self.download_stats['success'] += 1
            else:
                print(f"âœ— ä¸‹è¼‰å¤±æ•—: {message} (è€—æ™‚: {elapsed_time:.1f}ç§’)")
                self.download_stats['failed'] += 1

            return success, message

        except Exception as e:
            error_msg = f"è™•ç†è¦–é »æ™‚å‡ºéŒ¯: {str(e)}"
            print(f"âœ— {error_msg}")
            self.download_stats['failed'] += 1
            return False, error_msg

    def countdown_timer(self, seconds):
        """å€’æ•¸è¨ˆæ™‚å™¨"""
        print(f"\nâ³ ä¼‘æ¯ {seconds} ç§’ ({seconds / 60:.1f} åˆ†é˜)...")

        # é¡¯ç¤ºå€’æ•¸è¨ˆæ™‚
        for remaining in range(seconds, 0, -1):
            mins, secs = divmod(remaining, 60)
            timer = f"{mins:02d}:{secs:02d}"
            print(f"\râ±ï¸  å‰©é¤˜æ™‚é–“: {timer}", end='', flush=True)
            time.sleep(1)

        print(f"\râœ… ä¼‘æ¯å®Œç•¢ï¼Œç¹¼çºŒä¸‹è¼‰...     ")

    def sequential_download(self, video_list=None, output_dir="lieta_downloads",
                            categories=None, skip_existing=True, rest_interval=None):
        """é †åºä¸‹è¼‰è¦–é »ï¼ˆä¸€æ¬¡ä¸‹è¼‰ä¸€å€‹ï¼Œæ¯æ¬¡ä¸‹è¼‰å¾Œä¼‘æ¯ï¼‰"""
        if video_list is None:
            video_list = VIDEO_LIST

        # è¨­å®šä¼‘æ¯é–“éš”
        if rest_interval is not None:
            self.rest_interval = rest_interval

        # éæ¿¾åˆ†é¡
        if categories:
            video_list = [v for v in video_list if v['category'] in categories]

        self.download_stats['total'] = len(video_list)

        print(f"é †åºä¸‹è¼‰é–‹å§‹...")
        print(f"ç¸½å…± {len(video_list)} å€‹è¦–é »")
        print(f"è¼¸å‡ºç›®éŒ„: {output_dir}")
        print(f"æ¯æ¬¡ä¸‹è¼‰å¾Œä¼‘æ¯: {self.rest_interval} ç§’ ({self.rest_interval / 60:.1f} åˆ†é˜)")
        print(f"è·³éå·²å­˜åœ¨æª”æ¡ˆ: {'æ˜¯' if skip_existing else 'å¦'}")
        print("=" * 60)

        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        Path(output_dir).mkdir(exist_ok=True)

        # é †åºè™•ç†æ¯å€‹è¦–é »
        for i, video in enumerate(video_list, 1):
            print(f"\nğŸ“¹ é€²åº¦: {i}/{len(video_list)}")

            try:
                # ä¸‹è¼‰è¦–é »
                success, message = self.download_single_video(video, output_dir, skip_existing)

                # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€å€‹è¦–é »ï¼Œå‰‡ä¼‘æ¯æŒ‡å®šæ™‚é–“
                if i < len(video_list):
                    if self.rest_interval > 0:
                        self.countdown_timer(self.rest_interval)
                    else:
                        print("â­ï¸  ç«‹å³ç¹¼çºŒä¸‹ä¸€å€‹è¦–é »...")

            except KeyboardInterrupt:
                print(f"\n\nâš ï¸  ç”¨æˆ¶ä¸­æ–·ä¸‹è¼‰")
                print(f"å·²è™•ç† {i - 1}/{len(video_list)} å€‹è¦–é »")
                break
            except Exception as e:
                print(f"è™•ç†è¦–é »æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}")
                self.download_stats['failed'] += 1
                continue

        # é¡¯ç¤ºçµ±è¨ˆçµæœ
        self.print_summary()

    def print_summary(self):
        """é¡¯ç¤ºä¸‹è¼‰çµ±è¨ˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ä¸‹è¼‰å®Œæˆçµ±è¨ˆ:")
        print(f"ç¸½æ•¸: {self.download_stats['total']}")
        print(f"âœ… æˆåŠŸ: {self.download_stats['success']}")
        print(f"âŒ å¤±æ•—: {self.download_stats['failed']}")
        print(f"â­ï¸  è·³é: {self.download_stats['skipped']}")

        if self.download_stats['total'] > 0:
            success_rate = (self.download_stats['success'] / self.download_stats['total'] * 100)
            print(f"æˆåŠŸç‡: {success_rate:.1f}%")

        print(f"â° å®Œæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")

    def list_categories(self):
        """åˆ—å‡ºæ‰€æœ‰åˆ†é¡"""
        categories = set(video['category'] for video in VIDEO_LIST)
        return sorted(categories)

    def list_videos_by_category(self, category):
        """æŒ‰åˆ†é¡åˆ—å‡ºè¦–é »"""
        videos = [v for v in VIDEO_LIST if v['category'] == category]
        return videos


def main():
    print("é †åº Dailymotion è¦–é »ä¸‹è¼‰å™¨")
    print("=" * 40)

    # æª¢æŸ¥ yt-dlp
    try:
        import yt_dlp
        print("âœ“ yt-dlp å¯ç”¨")
    except ImportError:
        print("âœ— yt-dlp æœªå®‰è£ï¼Œè«‹åŸ·è¡Œ: pip install yt-dlp")
        return

    rest_interval_seconds = 600  # ä¼‘æ¯é–“éš”ï¼ˆç§’ï¼‰- å¯ä»¥æ–¹ä¾¿ä¿®æ”¹é€™è£¡
    # å‰µå»ºä¸‹è¼‰å™¨ï¼Œè¨­å®šä¼‘æ¯é–“éš”ç‚º 2 åˆ†é˜ (120 ç§’)
    downloader = SequentialDailymotionDownloader(rest_interval=rest_interval_seconds)

    # é¡¯ç¤ºå¯ç”¨åˆ†é¡
    categories = downloader.list_categories()
    print(f"\nå¯ç”¨åˆ†é¡: {', '.join(categories)}")

    # === è¨­å®šå€åŸŸ - å¯ä»¥æ–¹ä¾¿ä¿®æ”¹çš„åƒæ•¸ ===
    output_directory = "downloads"  # ä¸‹è¼‰ç›®éŒ„
    skip_existing_files = True  # è·³éå·²å­˜åœ¨çš„æª”æ¡ˆ
    selected_categories = None  # é¸æ“‡çš„åˆ†é¡ï¼ŒNone = å…¨éƒ¨ä¸‹è¼‰

    # å…¶ä»–ä¼‘æ¯é–“éš”é¸é …:
    # rest_interval_seconds = 60    # 1åˆ†é˜
    # rest_interval_seconds = 180   # 3åˆ†é˜
    # rest_interval_seconds = 300   # 5åˆ†é˜
    # rest_interval_seconds = 0     # ä¸ä¼‘æ¯ï¼Œé€£çºŒä¸‹è¼‰

    # åˆ†é¡é¸æ“‡ç¯„ä¾‹:
    # selected_categories = ['Evan']              # åªä¸‹è¼‰ Evan ç³»åˆ—
    # selected_categories = ['Evan', 'FOMC']      # ä¸‹è¼‰ Evan å’Œ FOMC ç³»åˆ—
    # selected_categories = ['å…­æœˆéŒ„å½±']           # åªä¸‹è¼‰å…­æœˆéŒ„å½±ç³»åˆ—
    # ========================================

    print(f"\né–‹å§‹é †åºä¸‹è¼‰...")
    print(f"é¸æ“‡çš„åˆ†é¡: {'å…¨éƒ¨' if selected_categories is None else ', '.join(selected_categories)}")
    print(f"ä¼‘æ¯é–“éš”: {rest_interval_seconds} ç§’ ({rest_interval_seconds / 60:.1f} åˆ†é˜)")

    # é–‹å§‹é †åºä¸‹è¼‰
    downloader.sequential_download(
        output_dir=output_directory,
        categories=selected_categories,
        skip_existing=skip_existing_files,
        rest_interval=rest_interval_seconds
    )


def download_specific_category_with_custom_interval():
    """ä¸‹è¼‰ç‰¹å®šåˆ†é¡ä¸¦è‡ªå®šç¾©ä¼‘æ¯é–“éš”çš„ç¯„ä¾‹"""
    downloader = SequentialDailymotionDownloader()

    # è¨­å®š 3 åˆ†é˜ä¼‘æ¯é–“éš”ï¼Œåªä¸‹è¼‰ Evan ç³»åˆ—
    downloader.sequential_download(
        output_dir="downloads",
        categories=['Evan'],
        skip_existing=True,
        rest_interval=180  # 3 åˆ†é˜
    )


def download_without_rest():
    """é€£çºŒä¸‹è¼‰ä¸ä¼‘æ¯çš„ç¯„ä¾‹"""
    downloader = SequentialDailymotionDownloader()

    # è¨­å®š 0 ç§’ä¼‘æ¯é–“éš”ï¼ˆé€£çºŒä¸‹è¼‰ï¼‰
    downloader.sequential_download(
        output_dir="downloads",
        categories=None,  # å…¨éƒ¨åˆ†é¡
        skip_existing=True,
        rest_interval=0  # ä¸ä¼‘æ¯
    )


if __name__ == "__main__":
    main()

    # å…¶ä»–ä½¿ç”¨æ–¹å¼çš„ç¯„ä¾‹:
    # download_specific_category_with_custom_interval()  # è‡ªå®šç¾©é–“éš”ä¸‹è¼‰ç‰¹å®šåˆ†é¡
    # download_without_rest()                           # é€£çºŒä¸‹è¼‰ä¸ä¼‘æ¯
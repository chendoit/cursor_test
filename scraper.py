"""
Citadel Securities æ–°èçˆ¬èŸ²
- æ”¯æŒå¤šå€‹ç³»åˆ—ï¼šGlobal Market Intelligenceã€Macro Thoughts
- ä½¿ç”¨ Async Playwright æå‡æ€§èƒ½
- MongoDB å„²å­˜ã€OpenAI ç¿»è­¯ã€Gmail éƒµä»¶ã€GitHub åœ–åºŠ
"""

import os
import json
import logging
import hashlib
import asyncio
from datetime import datetime
from playwright.async_api import async_playwright
import time
import argparse
from dotenv import load_dotenv
from pymongo import MongoClient
from openai import OpenAI
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import traceback
import requests
from github import Github
from io import BytesIO
import base64


# é…ç½® logging
def setup_logging():
    """é…ç½®æ—¥èªŒç³»çµ± - ä¸€å¤©ä¸€å€‹æ—¥èªŒæ–‡ä»¶"""
    log_filename = f'scraper_{datetime.now().strftime("%Y%m%d")}.log'
    
    # å‰µå»º logger
    logger = logging.getLogger('CitadelScraper')
    logger.setLevel(logging.DEBUG)
    
    # æ¸…é™¤å·²æœ‰çš„ handlers
    logger.handlers.clear()
    
    # æ–‡ä»¶ handlerï¼ˆè©³ç´°æ—¥èªŒï¼‰- ä½¿ç”¨ append æ¨¡å¼
    file_handler = logging.FileHandler(log_filename, mode='a', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(file_formatter)
    
    # æ§åˆ¶å° handlerï¼ˆç°¡åŒ–æ—¥èªŒï¼‰
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(levelname)s - %(message)s')
    console_handler.setFormatter(console_formatter)
    
    # æ·»åŠ  handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger, log_filename


# å‰µå»ºå…¨å±€ logger
logger, log_file = setup_logging()


# ç³»åˆ—é…ç½®
SERIES_CONFIG = {
    'global-market-intelligence': {
        'name': 'Global Market Intelligence',
        'name_zh': 'å…¨çƒå¸‚å ´æƒ…å ±',
        'url': 'https://www.citadelsecurities.com/news-and-insights/series/global-market-intelligence/',
        'emoji': 'ğŸ“Š'
    },
    'macro-thoughts': {
        'name': 'Macro Thoughts',
        'name_zh': 'å®è§€æ€è€ƒ',
        'url': 'https://www.citadelsecurities.com/news-and-insights/series/macro-thoughts/',
        'emoji': 'ğŸŒ'
    }
}


class GitHubImageUploader:
    """GitHub åœ–ç‰‡ä¸Šå‚³å™¨"""
    
    def __init__(self, token, repo_name):
        self.github = Github(token)
        self.repo = self.github.get_repo(repo_name)
        self.uploaded_cache = {}  # å¿«å–å·²ä¸Šå‚³çš„åœ–ç‰‡
        logger.info(f"âœ“ GitHub å€‰åº«å·²é€£æ¥: {repo_name}")
        
        # è¼‰å…¥å·²å­˜åœ¨çš„æª”æ¡ˆåˆ—è¡¨
        self._load_existing_files()
    
    def _load_existing_files(self):
        """è¼‰å…¥ GitHub å€‰åº«ä¸­å·²å­˜åœ¨çš„æª”æ¡ˆ"""
        try:
            logger.debug("è¼‰å…¥ GitHub å€‰åº«ç¾æœ‰æª”æ¡ˆ...")
            contents = self.repo.get_contents("")
            self.existing_files = {content.name for content in contents if content.type == "file"}
            logger.debug(f"  æ‰¾åˆ° {len(self.existing_files)} å€‹ç¾æœ‰æª”æ¡ˆ")
        except Exception as e:
            logger.warning(f"ç„¡æ³•è¼‰å…¥ç¾æœ‰æª”æ¡ˆåˆ—è¡¨: {e}")
            self.existing_files = set()
    
    def generate_filename_from_url(self, original_url):
        """æ ¹æ“š URL ç”Ÿæˆç©©å®šçš„æ–‡ä»¶åï¼ˆç”¨æ–¼æª¢æŸ¥é‡è¤‡ï¼‰"""
        # ä½¿ç”¨å®Œæ•´ URL hash ç¢ºä¿ç›¸åŒ URL ç”Ÿæˆç›¸åŒæª”å
        url_hash = hashlib.md5(original_url.encode()).hexdigest()
        
        # ç²å–åŸå§‹æ–‡ä»¶æ“´å±•å
        ext = original_url.split('.')[-1].split('?')[0].lower()
        if ext not in ['jpg', 'jpeg', 'png', 'gif', 'webp']:
            ext = 'jpg'
        
        return f"citadel_{url_hash}.{ext}"
    
    def check_image_exists(self, filename):
        """æª¢æŸ¥åœ–ç‰‡æ˜¯å¦å·²å­˜åœ¨æ–¼ GitHub"""
        return filename in self.existing_files
    
    def get_github_raw_url(self, filename):
        """ç²å– GitHub raw URL"""
        return f"https://raw.githubusercontent.com/{self.repo.full_name}/main/{filename}"
    
    def upload_image(self, image_url):
        """ä¸Šå‚³åœ–ç‰‡åˆ° GitHub ä¸¦è¿”å› raw URLï¼ˆé¿å…é‡è¤‡ä¸Šå‚³ï¼‰"""
        try:
            # æª¢æŸ¥å¿«å–
            if image_url in self.uploaded_cache:
                logger.debug(f"ä½¿ç”¨å¿«å–: {image_url}")
                return self.uploaded_cache[image_url]
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self.generate_filename_from_url(image_url)
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if self.check_image_exists(filename):
                github_url = self.get_github_raw_url(filename)
                logger.info(f"âœ“ åœ–ç‰‡å·²å­˜åœ¨ï¼Œè·³éä¸Šå‚³: {filename}")
                self.uploaded_cache[image_url] = github_url
                return github_url
            
            # ä¸‹è¼‰åœ–ç‰‡
            logger.debug(f"ä¸‹è¼‰åœ–ç‰‡: {image_url}")
            response = requests.get(image_url, timeout=30)
            response.raise_for_status()
            
            # ä¸Šå‚³åˆ° GitHub
            logger.debug(f"ä¸Šå‚³åˆ° GitHub: {filename}")
            self.repo.create_file(
                path=filename,
                message=f"Add image from Citadel Securities",
                content=response.content
            )
            
            # æ·»åŠ åˆ°å·²å­˜åœ¨åˆ—è¡¨å’Œå¿«å–
            self.existing_files.add(filename)
            github_url = self.get_github_raw_url(filename)
            self.uploaded_cache[image_url] = github_url
            
            logger.info(f"âœ“ åœ–ç‰‡å·²ä¸Šå‚³: {filename}")
            
            return github_url
            
        except Exception as e:
            logger.error(f"ä¸Šå‚³åœ–ç‰‡å¤±æ•— {image_url}: {e}")
            logger.debug(traceback.format_exc())
            return image_url  # å¤±æ•—æ™‚è¿”å›åŸå§‹ URL


class ContentElement:
    """å…§å®¹å…ƒç´ ï¼ˆæ–‡å­—æˆ–åœ–ç‰‡ï¼‰"""
    def __init__(self, element_type, content, order):
        self.type = element_type  # 'text' or 'image'
        self.content = content
        self.order = order


class CitadelScraper:
    def __init__(self, test_mode=False, series_list=None):
        # åŠ è¼‰ç’°å¢ƒè®Šé‡
        load_dotenv()
        logger.info("=" * 70)
        logger.info("åˆå§‹åŒ– Citadel Scraper")
        logger.info("=" * 70)
        
        self.test_mode = test_mode
        self.series_list = series_list or ['global-market-intelligence']  # é»˜èªæŠ“å– GMI
        
        if test_mode:
            logger.warning("æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨ - ä¸æœƒä¿å­˜åˆ° MongoDB")
        
        logger.info(f"å°‡æŠ“å–ä»¥ä¸‹ç³»åˆ—: {', '.join([SERIES_CONFIG[s]['name'] for s in self.series_list])}")
        
        # MongoDB é…ç½®
        logger.debug("é…ç½® MongoDB é€£æ¥...")
        self.mongodb_url = os.getenv('MONGODB_URL')
        if not self.mongodb_url:
            logger.error("MONGODB_URL æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
            raise ValueError("MONGODB_URL æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
        
        self.mongo_client = MongoClient(self.mongodb_url)
        self.db = self.mongo_client['citadel_scraper']
        self.articles_collection = self.db['articles']
        
        # ç¢ºä¿ href å­—æ®µçš„å”¯ä¸€ç´¢å¼•
        self.articles_collection.create_index('url', unique=True)
        logger.info("âœ“ MongoDB å·²é€£æ¥")
        
        # OpenAI é…ç½®
        logger.debug("é…ç½® OpenAI API...")
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('MODEL', 'gpt-4o-mini')
        if not self.openai_api_key:
            logger.error("OPENAI_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
            raise ValueError("OPENAI_API_KEY æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
        
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        logger.info(f"âœ“ OpenAI é…ç½®å®Œæˆ (æ¨¡å‹: {self.model})")
        
        # Gmail é…ç½®
        logger.debug("é…ç½® Gmail SMTP...")
        self.mail_token = os.getenv('MAIL_TOKEN')
        self.app_password = os.getenv('APP_PASSWORD')
        self.recipients = os.getenv('RECIPIENTS', '').split(',')
        
        if not self.mail_token or not self.app_password:
            logger.error("MAIL_TOKEN æˆ– APP_PASSWORD æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
            raise ValueError("MAIL_TOKEN æˆ– APP_PASSWORD æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
        
        logger.info(f"âœ“ Gmail é…ç½®å®Œæˆ (ç™¼ä»¶äºº: {self.mail_token})")
        logger.info(f"  æ”¶ä»¶äºº: {', '.join(self.recipients)}")
        
        # GitHub é…ç½®
        logger.debug("é…ç½® GitHub åœ–ç‰‡ä¸Šå‚³...")
        github_token = os.getenv('GITHUB_TOKEN')
        github_repo = os.getenv('GITHUB_REPO', 'chendoit/PicBed')
        
        if not github_token:
            logger.error("GITHUB_TOKEN æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
            raise ValueError("GITHUB_TOKEN æœªåœ¨ .env æ–‡ä»¶ä¸­è¨­ç½®")
        
        self.github_uploader = GitHubImageUploader(github_token, github_repo)
    
    def is_already_scraped(self, url):
        """æª¢æŸ¥æ–‡ç« æ˜¯å¦å·²ç¶“æŠ“éï¼ˆé€šé URLï¼‰"""
        if self.test_mode:
            logger.debug(f"æ¸¬è©¦æ¨¡å¼ - è·³éé‡è¤‡æª¢æŸ¥")
            return False
        
        exists = self.articles_collection.find_one({'url': url}) is not None
        logger.debug(f"URL é‡è¤‡æª¢æŸ¥: {url} - {'å·²å­˜åœ¨' if exists else 'æ–°æ–‡ç« '}")
        return exists
    
    async def scrape_content_with_order(self, page):
        """æŒ‰é †åºæŠ“å–å…§å®¹ï¼ˆæ–‡å­—å’Œåœ–ç‰‡ï¼‰- Async ç‰ˆæœ¬"""
        logger.info("æŒ‰é †åºæŠ“å–æ–‡ç« å…§å®¹...")
        
        try:
            content_elements = []
            order = 0
            
            # ç²å–ä¸»è¦å…§å®¹å€åŸŸ
            content_section = page.locator('div.section-intro.is-top-padding.is-bottom-padding').first
            
            # ä½¿ç”¨ JavaScript ç²å–æ‰€æœ‰å­å…ƒç´ ï¼ˆæ–‡å­—æ®µè½å’Œåœ–ç‰‡ï¼‰
            elements = await content_section.evaluate('''
                (element) => {
                    const result = [];
                    const walker = document.createTreeWalker(
                        element,
                        NodeFilter.SHOW_ELEMENT | NodeFilter.SHOW_TEXT,
                        null,
                        false
                    );
                    
                    let node;
                    let currentParagraph = '';
                    
                    while (node = walker.nextNode()) {
                        if (node.nodeType === Node.TEXT_NODE) {
                            const text = node.textContent.trim();
                            if (text) {
                                currentParagraph += text + ' ';
                            }
                        } else if (node.nodeName === 'IMG') {
                            // å…ˆä¿å­˜ç•¶å‰æ®µè½
                            if (currentParagraph.trim()) {
                                result.push({type: 'text', content: currentParagraph.trim()});
                                currentParagraph = '';
                            }
                            // æ·»åŠ åœ–ç‰‡
                            result.push({type: 'image', content: node.src});
                        } else if (node.nodeName === 'P' || node.nodeName === 'DIV') {
                            // æ®µè½çµæŸ
                            if (currentParagraph.trim()) {
                                result.push({type: 'text', content: currentParagraph.trim()});
                                currentParagraph = '';
                            }
                        }
                    }
                    
                    // ä¿å­˜æœ€å¾Œçš„æ®µè½
                    if (currentParagraph.trim()) {
                        result.push({type: 'text', content: currentParagraph.trim()});
                    }
                    
                    return result;
                }
            ''')
            
            # è½‰æ›ç‚º ContentElement å°è±¡
            for element in elements:
                content_elements.append(
                    ContentElement(
                        element_type=element['type'],
                        content=element['content'],
                        order=order
                    )
                )
                order += 1
            
            logger.info(f"âœ“ æ‰¾åˆ° {len(content_elements)} å€‹å…§å®¹å…ƒç´ ")
            
            # çµ±è¨ˆ
            text_count = sum(1 for e in content_elements if e.type == 'text')
            image_count = sum(1 for e in content_elements if e.type == 'image')
            logger.debug(f"  æ–‡å­—æ®µè½: {text_count}, åœ–ç‰‡: {image_count}")
            
            return content_elements
            
        except Exception as e:
            logger.error(f"æŠ“å–å…§å®¹å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return []
    
    def translate_paragraphs(self, text_paragraphs, title):
        """ç¿»è­¯æ–‡å­—æ®µè½ç‚ºç¹é«”ä¸­æ–‡"""
        logger.info("é–‹å§‹ç¿»è­¯æ–‡å­—æ®µè½...")
        logger.debug(f"å…± {len(text_paragraphs)} å€‹æ®µè½")
        
        try:
            # æº–å‚™ JSON list
            paragraphs_json = json.dumps(text_paragraphs, ensure_ascii=False, indent=2)
            
            prompt = f"""è«‹å°‡ä»¥ä¸‹ JSON æ•¸çµ„ä¸­çš„è‹±æ–‡æ®µè½ç¿»è­¯æˆç¹é«”ä¸­æ–‡ã€‚

è¦æ±‚ï¼š
1. å¿…é ˆè¿”å›ä¸€å€‹ç´” JSON æ•¸çµ„æ ¼å¼: ["ä¸­æ–‡1", "ä¸­æ–‡2", ...]
2. ä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ï¼Œç›´æ¥è¿”å›æ•¸çµ„
3. æ¯å€‹è‹±æ–‡æ®µè½å°æ‡‰ä¸€å€‹ç¹é«”ä¸­æ–‡ç¿»è­¯
4. ä¿æŒæ•¸çµ„é †åºå’Œé•·åº¦ä¸€è‡´
5. ä¿æŒå°ˆæ¥­è¡“èªçš„æº–ç¢ºæ€§ï¼ˆç‰¹åˆ¥æ˜¯é‡‘èè¡“èªï¼‰
6. ç¿»è­¯æµæš¢è‡ªç„¶ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡

æ–‡ç« æ¨™é¡Œ: {title}

è‹±æ–‡æ®µè½æ•¸çµ„:
{paragraphs_json}

è«‹è¿”å›å°æ‡‰çš„ç¹é«”ä¸­æ–‡ç¿»è­¯æ•¸çµ„ï¼ˆæ ¼å¼ç¤ºä¾‹: ["æ®µè½1ç¿»è­¯", "æ®µè½2ç¿»è­¯", ...]ï¼‰ï¼š
"""
            
            logger.debug("èª¿ç”¨ OpenAI API...")
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èé ˜åŸŸç¿»è­¯å°ˆå®¶ï¼Œæ“…é•·å°‡è‹±æ–‡é‡‘èæ–‡ç« ç¿»è­¯æˆæº–ç¢ºæµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚è«‹åš´æ ¼è¿”å› JSON æ•¸çµ„æ ¼å¼ï¼Œä¸è¦åŒ…è£åœ¨å°è±¡ä¸­ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            
            response_text = response.choices[0].message.content.strip()
            logger.debug(f"API éŸ¿æ‡‰é•·åº¦: {len(response_text)}")
            
            # è§£æ JSON
            chinese_paragraphs = json.loads(response_text)
            
            # å¦‚æœè¿”å›çš„æ˜¯å°è±¡ï¼Œå˜—è©¦æå–æ•¸çµ„
            if isinstance(chinese_paragraphs, dict):
                possible_keys = [
                    'translations', 'paragraphs', 'chinese', 'result', 'data',
                    'ç¿»è­¯çµæœ', 'ç¿»è¯‘ç»“æœ', 'ç¿»è­¯', 'ä¸­æ–‡', 'æ®µè½', 'çµæœ'
                ]
                for key in possible_keys:
                    if key in chinese_paragraphs:
                        chinese_paragraphs = chinese_paragraphs[key]
                        logger.debug(f"å¾éµ '{key}' æå–æ•¸çµ„")
                        break
            
            # ç¢ºä¿æ˜¯åˆ—è¡¨
            if not isinstance(chinese_paragraphs, list):
                logger.error(f"è¿”å›é¡å‹éŒ¯èª¤: {type(chinese_paragraphs)}")
                return None
            
            logger.info(f"âœ“ ç¿»è­¯å®Œæˆ (Token: {response.usage.total_tokens})")
            
            return chinese_paragraphs
            
        except Exception as e:
            logger.error(f"ç¿»è­¯å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return None
    
    def process_content_elements(self, content_elements, title):
        """è™•ç†å…§å®¹å…ƒç´ ï¼šç¿»è­¯æ–‡å­—ã€ä¸Šå‚³åœ–ç‰‡"""
        logger.info("\n" + "-" * 70)
        logger.info("è™•ç†å…§å®¹å…ƒç´ ...")
        
        # åˆ†é›¢æ–‡å­—å’Œåœ–ç‰‡
        text_paragraphs = []
        text_indices = []
        
        for i, element in enumerate(content_elements):
            if element.type == 'text':
                text_paragraphs.append(element.content)
                text_indices.append(i)
        
        # ç¿»è­¯æ–‡å­—
        chinese_paragraphs = self.translate_paragraphs(text_paragraphs, title)
        if not chinese_paragraphs:
            logger.error("ç¿»è­¯å¤±æ•—")
            return None
        
        # å‰µå»ºç¿»è­¯æ˜ å°„
        translation_map = dict(zip(text_indices, chinese_paragraphs))
        
        # ä¸Šå‚³åœ–ç‰‡åˆ° GitHub
        logger.info("\nä¸Šå‚³åœ–ç‰‡åˆ° GitHub...")
        for element in content_elements:
            if element.type == 'image':
                original_url = element.content
                github_url = self.github_uploader.upload_image(original_url)
                element.content = github_url  # æ›¿æ›ç‚º GitHub URL
        
        logger.info("-" * 70 + "\n")
        
        return translation_map
    
    def save_to_mongodb(self, article_data):
        """ä¿å­˜æ–‡ç« åˆ° MongoDB"""
        try:
            if self.test_mode:
                logger.warning("[æ¸¬è©¦æ¨¡å¼] è·³éä¿å­˜åˆ° MongoDB")
                return True
            
            logger.debug(f"ä¿å­˜æ–‡ç« åˆ° MongoDB: {article_data['url']}")
            result = self.articles_collection.update_one(
                {'url': article_data['url']},
                {'$set': article_data},
                upsert=True
            )
            
            if result.upserted_id:
                logger.info(f"âœ“ æ–°æ–‡ç« å·²ä¿å­˜åˆ° MongoDB (ID: {result.upserted_id})")
            else:
                logger.info(f"âœ“ æ–‡ç« å·²æ›´æ–°åˆ° MongoDB")
            
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ° MongoDB å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False
    
    def send_email(self, article_data, content_elements, translation_map):
        """ç™¼é€éƒµä»¶"""
        logger.info("æº–å‚™ç™¼é€éƒµä»¶...")
        
        try:
            # å‰µå»ºéƒµä»¶
            msg = MIMEMultipart('alternative')
            msg['From'] = self.mail_token
            msg['To'] = ', '.join(self.recipients)
            
            # éƒµä»¶ä¸»é¡ŒåŒ…å«ç³»åˆ—åç¨±
            series_emoji = article_data.get('series_emoji', 'ğŸ“°')
            series_name_zh = article_data.get('series_name_zh', '')
            msg['Subject'] = f"{series_emoji} Citadel Securities - {series_name_zh} - {article_data['title']}"
            
            # ç”Ÿæˆ HTML å…§å®¹
            html_content = self._generate_html_email(article_data, content_elements, translation_map)
            
            # æ·»åŠ  HTML éƒ¨åˆ†
            part = MIMEText(html_content, 'html', 'utf-8')
            msg.attach(part)
            
            # ç™¼é€éƒµä»¶
            logger.debug("é€£æ¥åˆ° Gmail SMTP æœå‹™å™¨...")
            with smtplib.SMTP_SSL('smtp.gmail.com', 465) as server:
                server.login(self.mail_token, self.app_password)
                server.send_message(msg)
            
            logger.info(f"âœ“ éƒµä»¶å·²ç™¼é€")
            return True
            
        except Exception as e:
            logger.error(f"ç™¼é€éƒµä»¶å¤±æ•—: {e}")
            logger.debug(traceback.format_exc())
            return False
    
    def _generate_html_email(self, article_data, content_elements, translation_map):
        """ç”Ÿæˆ HTML éƒµä»¶å…§å®¹ï¼ˆä½¿ç”¨ GitHub åœ–ç‰‡é€£çµï¼‰"""
        html_parts = []
        
        series_emoji = article_data.get('series_emoji', 'ğŸ“°')
        series_name = article_data.get('series_name', 'News')
        series_name_zh = article_data.get('series_name_zh', 'æ–°è')
        
        html_parts.append(f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background-color: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        .series-badge {{
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.9em;
            margin-bottom: 15px;
            font-weight: 600;
        }}
        h1 {{
            color: #1a1a1a;
            border-bottom: 3px solid #0066cc;
            padding-bottom: 15px;
            margin-bottom: 25px;
        }}
        .meta {{
            color: #666;
            font-size: 0.95em;
            margin-bottom: 30px;
            padding: 15px;
            background-color: #f8f9fa;
            border-left: 4px solid #0066cc;
        }}
        .content-element {{
            margin-bottom: 25px;
        }}
        .text-paragraph {{
            margin-bottom: 10px;
        }}
        .english {{
            color: #2c3e50;
            line-height: 1.7;
            margin-bottom: 10px;
        }}
        .chinese {{
            color: #34495e;
            background-color: #f0f7ff;
            padding: 12px;
            border-radius: 5px;
            border-left: 4px solid #0066cc;
            line-height: 1.7;
            margin-bottom: 15px;
        }}
        .chinese::before {{
            content: "ğŸ‡¹ğŸ‡¼ ";
            font-weight: bold;
        }}
        .image-container {{
            text-align: center;
            margin: 30px 0;
        }}
        .article-image {{
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        .image-caption {{
            color: #999;
            font-size: 0.85em;
            margin-top: 8px;
            font-style: italic;
        }}
        .divider {{
            border-top: 1px solid #e0e0e0;
            margin: 20px 0;
        }}
        .footer {{
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #e0e0e0;
            color: #999;
            font-size: 0.9em;
            text-align: center;
        }}
        a {{
            color: #0066cc;
            text-decoration: none;
        }}
        a:hover {{
            text-decoration: underline;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="series-badge">{series_emoji} {series_name} / {series_name_zh}</div>
        <h1>{article_data['title']}</h1>
        
        <div class="meta">
            <strong>ç™¼å¸ƒæ—¥æœŸ / Date:</strong> {article_data['date']}<br>
            <strong>åŸæ–‡é€£çµ / Source:</strong> <a href="{article_data['url']}" target="_blank">{article_data['url']}</a><br>
            <strong>æŠ“å–æ™‚é–“ / Scraped:</strong> {article_data['scraped_at']}
        </div>
""")
        
        # æŒ‰é †åºæ·»åŠ å…§å®¹å…ƒç´ ï¼ˆç¢ºä¿ä½¿ç”¨ GitHub é€£çµï¼‰
        text_index = 0
        for element in content_elements:
            if element.type == 'text':
                # æ–‡å­—æ®µè½ï¼ˆè‹±æ–‡ + ç¹é«”ä¸­æ–‡ï¼‰
                english_text = element.content
                chinese_text = translation_map.get(text_index, "")
                
                html_parts.append(f"""
        <div class="content-element text-paragraph">
            <div class="english">{english_text}</div>
            <div class="chinese">{chinese_text}</div>
        </div>
        <div class="divider"></div>
""")
                text_index += 1
                
            elif element.type == 'image':
                # åœ–ç‰‡ï¼ˆç¢ºä¿ä½¿ç”¨ GitHub raw URLï¼‰
                github_url = element.content
                
                # é©—è­‰æ˜¯å¦ç‚º GitHub URL
                if 'raw.githubusercontent.com' in github_url or 'github.com' in github_url:
                    caption = "åœ–ç‰‡ä¾†è‡ª GitHubï¼ˆæ°¸ä¹…ä¿å­˜ï¼‰"
                else:
                    caption = "åŸå§‹åœ–ç‰‡é€£çµ"
                
                html_parts.append(f"""
        <div class="content-element image-container">
            <img src="{github_url}" alt="Article Image" class="article-image">
            <div class="image-caption">{caption}</div>
        </div>
""")
        
        html_parts.append("""
        <div class="footer">
            æ­¤éƒµä»¶ç”± Citadel Securities æ–°èçˆ¬èŸ²è‡ªå‹•ç™¼é€<br>
            åœ–ç‰‡æ°¸ä¹…ä¿å­˜æ–¼ GitHub | Powered by Async Playwright + OpenAI
        </div>
    </div>
</body>
</html>
""")
        
        return ''.join(html_parts)
    
    async def scrape_series(self, series_key):
        """æŠ“å–å–®å€‹ç³»åˆ—çš„æœ€æ–°æ–‡ç«  - Async ç‰ˆæœ¬"""
        series_config = SERIES_CONFIG[series_key]
        base_url = series_config['url']
        series_name = series_config['name']
        series_name_zh = series_config['name_zh']
        series_emoji = series_config['emoji']
        
        logger.info("\n" + "=" * 70)
        logger.info(f"é–‹å§‹æŠ“å–ç³»åˆ—: {series_emoji} {series_name} ({series_name_zh})")
        logger.info("=" * 70)
        
        async with async_playwright() as p:
            logger.debug("å•Ÿå‹•ç€è¦½å™¨ (Chromium headless)")
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                logger.info(f"è¨ªå•ç›®æ¨™ç¶²ç«™: {base_url}")
                await page.goto(base_url, timeout=60000)
                
                # ç­‰å¾…é é¢åŠ è¼‰
                await page.wait_for_selector('.post-listing__list', timeout=30000)
                
                # æ‰¾åˆ°ç¬¬ä¸€å€‹æ–‡ç« 
                first_card = page.locator('.post-listing__list .post-listing__box-card').first
                link = first_card.locator('.post-listing__box-card__link a').first
                aria_label = await link.get_attribute('aria-label')
                href = await link.get_attribute('href')
                
                logger.info(f"æ‰¾åˆ°æ–‡ç« : {aria_label}")
                logger.info(f"éˆæ¥: {href}")
                
                # æª¢æŸ¥æ˜¯å¦å·²ç¶“æŠ“é
                if self.is_already_scraped(href):
                    if self.test_mode:
                        logger.warning("[æ¸¬è©¦æ¨¡å¼] æ–‡ç« å·²æŠ“å–éï¼Œä½†ç¹¼çºŒåŸ·è¡Œ...")
                    else:
                        logger.info("âœ“ æ–‡ç« å·²å­˜åœ¨æ–¼ MongoDB ä¸­ï¼Œè·³é")
                        await browser.close()
                        return
                
                # è¨ªå•æ–‡ç« é é¢
                logger.info("è¨ªå•æ–‡ç« é é¢...")
                await page.goto(href, timeout=60000)
                await page.wait_for_timeout(2000)  # ç­‰å¾… 2 ç§’
                
                # æŠ“å–æ¨™é¡Œ
                try:
                    heading = page.locator('span.heading-inner').first
                    title = await heading.inner_text()
                    logger.info(f"æ¨™é¡Œ: {title}")
                except:
                    title = aria_label
                
                # æŠ“å–æ—¥æœŸ
                try:
                    date_element = page.locator('p.page-section__article-header__date').first
                    date = await date_element.inner_text()
                    logger.info(f"æ—¥æœŸ: {date}")
                except:
                    date = ""
                
                # æŒ‰é †åºæŠ“å–å…§å®¹ï¼ˆæ–‡å­—å’Œåœ–ç‰‡ï¼‰
                content_elements = await self.scrape_content_with_order(page)
                
                # âœ… æŠ“å–å®Œæˆï¼Œç«‹å³é—œé–‰ç€è¦½å™¨
                logger.debug("âœ“ å…§å®¹æŠ“å–å®Œæˆï¼Œé—œé–‰ç€è¦½å™¨")
                await browser.close()
                
                if not content_elements:
                    logger.error("å…§å®¹æŠ“å–å¤±æ•—")
                    return
                
                # è™•ç†å…§å®¹ï¼šç¿»è­¯æ–‡å­—ã€ä¸Šå‚³åœ–ç‰‡åˆ° GitHub
                translation_map = self.process_content_elements(content_elements, title)
                if translation_map is None:
                    logger.error("å…§å®¹è™•ç†å¤±æ•—")
                    return
                
                # æº–å‚™æ–‡ç« æ•¸æ“š
                article_data = {
                    'url': href,
                    'aria_label': aria_label,
                    'title': title,
                    'date': date,
                    'series': series_key,
                    'series_name': series_name,
                    'series_name_zh': series_name_zh,
                    'series_emoji': series_emoji,
                    'content_elements': [
                        {'type': e.type, 'content': e.content, 'order': e.order}
                        for e in content_elements
                    ],
                    'scraped_at': datetime.now().isoformat(),
                    'translated': True
                }
                
                # ä¿å­˜åˆ° MongoDB
                logger.info("\n" + "-" * 70)
                self.save_to_mongodb(article_data)
                logger.info("-" * 70 + "\n")
                
                # ç™¼é€éƒµä»¶
                logger.info("-" * 70)
                self.send_email(article_data, content_elements, translation_map)
                logger.info("-" * 70 + "\n")
                
                logger.info("=" * 70)
                logger.info(f"âœ“ {series_name} æŠ“å–å®Œæˆï¼")
                logger.info("=" * 70)
                
            except Exception as e:
                logger.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
                logger.debug(traceback.format_exc())
                # å¦‚æœç€è¦½å™¨é‚„é–‹è‘—ï¼Œé—œé–‰å®ƒ
                try:
                    if browser:
                        await browser.close()
                except:
                    pass
    
    async def scrape_all(self):
        """æŠ“å–æ‰€æœ‰é…ç½®çš„ç³»åˆ— - Async ç‰ˆæœ¬"""
        logger.info("\n" + "=" * 70)
        logger.info("é–‹å§‹åŸ·è¡Œçˆ¬èŸ²ä»»å‹™")
        logger.info(f"ç³»åˆ—æ•¸é‡: {len(self.series_list)}")
        logger.info("=" * 70)
        
        for series_key in self.series_list:
            await self.scrape_series(series_key)
        
        logger.debug("æ¸…ç†è³‡æº...")
        self.mongo_client.close()
        logger.info("\nâœ“ æ‰€æœ‰ç³»åˆ—æŠ“å–å®Œæˆï¼")


def main():
    # è¨­ç½® Windows æ§åˆ¶å°ç·¨ç¢¼
    import sys
    if sys.platform == 'win32':
        import io
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')
    
    parser = argparse.ArgumentParser(description='Citadel Securities æ–°èçˆ¬èŸ²')
    parser.add_argument('--test', action='store_true', 
                       help='æ¸¬è©¦æ¨¡å¼ï¼šå¼·åˆ¶é‡æ–°æŠ“å–ï¼Œä¸æ›´æ–° MongoDB è¨˜éŒ„')
    parser.add_argument('--series', nargs='+', 
                       choices=['global-market-intelligence', 'macro-thoughts', 'all'],
                       default=['all'],
                       help='è¦æŠ“å–çš„ç³»åˆ—ï¼ˆå¯å¤šé¸ï¼‰ï¼šglobal-market-intelligence, macro-thoughts, all')
    args = parser.parse_args()
    
    # è™•ç†ç³»åˆ—é¸æ“‡
    if 'all' in args.series:
        series_list = list(SERIES_CONFIG.keys())
    else:
        series_list = args.series
    
    logger.info("=" * 70)
    logger.info("  Citadel Securities æ–°èçˆ¬èŸ²")
    logger.info("  Async Playwright + MongoDB + OpenAI + Gmail + GitHub")
    logger.info("=" * 70)
    logger.info(f"æ—¥èªŒæ–‡ä»¶: {log_file}")
    
    if args.test:
        logger.warning("\n[æ¸¬è©¦æ¨¡å¼] æ¸¬è©¦æ¨¡å¼å·²å•Ÿç”¨")
        logger.warning("   - å°‡é‡æ–°æŠ“å–å·²æŠ“å–éçš„æ–‡ç« ")
        logger.warning("   - ä¸æœƒæ›´æ–° MongoDB è¨˜éŒ„\n")
    
    try:
        scraper = CitadelScraper(test_mode=args.test, series_list=series_list)
        asyncio.run(scraper.scrape_all())
    except ValueError as e:
        logger.error(f"é…ç½®éŒ¯èª¤: {e}")
        logger.info("è«‹æª¢æŸ¥ .env æ–‡ä»¶é…ç½®ï¼Œåƒè€ƒ env_template.txt")
        return
    except Exception as e:
        logger.error(f"ç¨‹åºéŒ¯èª¤: {e}")
        logger.debug(traceback.format_exc())
    
    logger.info("\n" + "=" * 70)
    logger.info("  ä»»å‹™çµæŸ")
    logger.info("=" * 70)
    logger.info(f"è©³ç´°æ—¥èªŒå·²ä¿å­˜åˆ°: {log_file}")


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±å·¥å…·
ä½¿ç”¨ Playwright å’Œ Google Gemini API é€²è¡Œé©—è­‰ç¢¼è¾¨è­˜å’Œè‡ªå‹•å€Ÿé–±
"""

import asyncio
import os
import re
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from urllib.parse import urljoin
import hashlib

from dotenv import load_dotenv
from playwright.async_api import async_playwright, Page, Browser, FrameLocator
import httpx

try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False


class HyReadScraper:
    """æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±é¡åˆ¥"""
    
    def __init__(self, env_file: str = ".env_hyread"):
        """
        åˆå§‹åŒ–å€Ÿé–±å™¨
        
        Args:
            env_file: ç’°å¢ƒè®Šæ•¸æª”æ¡ˆè·¯å¾‘
        """
        # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
        env_path = Path(env_file)
        if not env_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸æª”æ¡ˆ: {env_file}")
        
        load_dotenv(env_path)
        
        # è®€å–è¨­å®š
        self.account = os.getenv("HYREAD_ACCOUNT")
        self.password = os.getenv("HYREAD_PASSWORD")
        self.google_api_key = os.getenv("OPENAI_API_KEY")
        self.model_name = os.getenv("OPENAI_MODEL", "gemini-2.0-flash-exp")
        self.book_id = os.getenv("HYREAD_BOOK_ID", "279235")  # é è¨­æ›¸ç± ID
        self.captcha_mode = os.getenv("CAPTCHA_MODE", "manual").lower()  # é©—è­‰ç¢¼æ¨¡å¼
        self.enable_scraping = os.getenv("ENABLE_SCRAPING", "true").lower() == "true"  # æ˜¯å¦å•Ÿç”¨çˆ¬èŸ²
        self.max_pages = int(os.getenv("MAX_PAGES", "999"))  # æœ€å¤§çˆ¬å–é æ•¸
        self.download_images = os.getenv("DOWNLOAD_IMAGES", "true").lower() == "true"  # æ˜¯å¦ä¸‹è¼‰åœ–ç‰‡
        
        # åœ–ç‰‡ä¸‹è¼‰ç›¸é—œ
        self.images_dir = None
        self.downloaded_images = {}  # URL -> æœ¬åœ°è·¯å¾‘æ˜ å°„
        
        # é©—è­‰å¿…è¦åƒæ•¸
        if not all([self.account, self.password]):
            raise ValueError("è«‹ç¢ºä¿ .env_hyread ä¸­åŒ…å« HYREAD_ACCOUNT å’Œ HYREAD_PASSWORD")
        
        # å¦‚æœä½¿ç”¨è‡ªå‹•æ¨¡å¼ï¼Œéœ€è¦æª¢æŸ¥ API Key å’Œ Gemini SDK
        if self.captcha_mode == "auto":
            if not self.google_api_key:
                raise ValueError("è‡ªå‹•æ¨¡å¼éœ€è¦ OPENAI_API_KEYï¼Œæˆ–å°‡ CAPTCHA_MODE è¨­ç‚º manual")
            
            if not HAS_GEMINI:
                raise ImportError(
                    "è«‹å®‰è£ Google Gemini SDK:\n"
                    "pip install google-generativeai Pillow"
                )
            
            # è¨­å®š Gemini API
            genai.configure(api_key=self.google_api_key)
            
            # åˆå§‹åŒ–æ¨¡å‹
            self.model = genai.GenerativeModel(self.model_name)
        
        # URL è¨­å®š
        self.login_url = "https://tycccgov.ebook.hyread.com.tw/Template/RWD3.0/liblogin.jsp"
        self.base_url = "https://tycccgov.ebook.hyread.com.tw"
        
        print(f"âœ… å·²è¼‰å…¥è¨­å®š:")
        print(f"   - å¸³è™Ÿ: {self.account}")
        print(f"   - é©—è­‰ç¢¼æ¨¡å¼: {'è‡ªå‹•è¾¨è­˜ (Gemini)' if self.captcha_mode == 'auto' else 'æ‰‹å‹•è¼¸å…¥'}")
        if self.captcha_mode == "auto":
            print(f"   - Gemini æ¨¡å‹: {self.model_name}")
        print(f"   - ç›®æ¨™æ›¸ç± ID: {self.book_id}")
        print(f"   - çˆ¬èŸ²æ¨¡å¼: {'å•Ÿç”¨' if self.enable_scraping else 'åœç”¨'}")
        if self.enable_scraping:
            print(f"   - æœ€å¤§çˆ¬å–é æ•¸: {self.max_pages}")
            print(f"   - ä¸‹è¼‰åœ–ç‰‡: {'æ˜¯' if self.download_images else 'å¦'}")
    
    async def solve_captcha(self, page: Page) -> str:
        """
        è§£æ±ºé©—è­‰ç¢¼
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            è¾¨è­˜å‡ºçš„é©—è­‰ç¢¼æ–‡å­—
        """
        # å®šä½é©—è­‰ç¢¼åœ–ç‰‡
        captcha_img = page.locator("#conImg")
        await captcha_img.wait_for(state="visible", timeout=10000)
        
        if self.captcha_mode == "manual":
            # æ‰‹å‹•æ¨¡å¼ï¼šé¡¯ç¤ºé©—è­‰ç¢¼ä¸¦ç­‰å¾…ä½¿ç”¨è€…è¼¸å…¥
            print("ğŸ“¸ é©—è­‰ç¢¼åœ–ç‰‡å·²é¡¯ç¤ºåœ¨ç€è¦½å™¨ä¸­")
            print("ğŸ‘€ è«‹æŸ¥çœ‹ç€è¦½å™¨è¦–çª—ä¸­çš„é©—è­‰ç¢¼")
            print("="*60)
            
            # ç­‰å¾…ä¸€ä¸‹è®“ä½¿ç”¨è€…çœ‹æ¸…æ¥šé©—è­‰ç¢¼
            await asyncio.sleep(1)
            
            # å¾å‘½ä»¤åˆ—è®€å–ä½¿ç”¨è€…è¼¸å…¥
            captcha_text = input("âŒ¨ï¸  è«‹è¼¸å…¥é©—è­‰ç¢¼: ").strip()
            
            if not captcha_text:
                raise ValueError("é©—è­‰ç¢¼ä¸èƒ½ç‚ºç©º")
            
            print(f"âœ… æ‚¨è¼¸å…¥çš„é©—è­‰ç¢¼: {captcha_text}")
            return captcha_text
            
        else:
            # è‡ªå‹•æ¨¡å¼ï¼šä½¿ç”¨ Gemini API è¾¨è­˜
            print("ğŸ“¸ æ­£åœ¨æˆªå–é©—è­‰ç¢¼åœ–ç‰‡...")
            
            # æˆªå–é©—è­‰ç¢¼åœ–ç‰‡
            captcha_screenshot = await captcha_img.screenshot()
            
            print("ğŸ¤– æ­£åœ¨å‘¼å« Google Gemini API è¾¨è­˜é©—è­‰ç¢¼...")
            
            try:
                # æº–å‚™åœ–ç‰‡
                import PIL.Image
                import io
                image = PIL.Image.open(io.BytesIO(captcha_screenshot))
                
                # å‘¼å« Gemini Vision API
                prompt = (
                    "Please identify the text or numbers in this CAPTCHA image. "
                    "Return ONLY the CAPTCHA text without any explanation, punctuation, or formatting. "
                    "If you see letters and numbers, return them exactly as shown."
                )
                
                response = self.model.generate_content([prompt, image])
                
                # æª¢æŸ¥å›æ‡‰
                if not response.text:
                    raise ValueError("Gemini API å›æ‡‰å…§å®¹ç‚ºç©º")
                
                captcha_text = response.text.strip()
                print(f"âœ… é©—è­‰ç¢¼è¾¨è­˜çµæœ: {captcha_text}")
                return captcha_text
                
            except Exception as e:
                print(f"âŒ Gemini API å‘¼å«å¤±æ•—: {e}")
                raise
    
    async def login(self, page: Page) -> bool:
        """
        åŸ·è¡Œè‡ªå‹•ç™»å…¥
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            ç™»å…¥æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹è‡ªå‹•ç™»å…¥æµç¨‹")
        print("="*60)
        
        # å‰å¾€ç™»å…¥é é¢
        print(f"ğŸ“„ æ­£åœ¨å‰å¾€ç™»å…¥é é¢: {self.login_url}")
        await page.goto(self.login_url)
        await asyncio.sleep(2)
        
        # å¡«å¯«å¸³è™Ÿ
        print(f"âœï¸  å¡«å¯«å¸³è™Ÿ: {self.account}")
        account_input = page.locator('input[name="account2"]')
        await account_input.wait_for(state="visible", timeout=10000)
        await account_input.fill(self.account)
        await asyncio.sleep(0.5)
        
        # å¡«å¯«å¯†ç¢¼
        print("ğŸ”’ å¡«å¯«å¯†ç¢¼...")
        password_input = page.locator('input[name="passwd2"]')
        await password_input.fill(self.password)
        await asyncio.sleep(0.5)
        
        # è¾¨è­˜ä¸¦å¡«å¯«é©—è­‰ç¢¼
        max_retries = 3
        for attempt in range(1, max_retries + 1):
            print(f"\nğŸ” é©—è­‰ç¢¼è¾¨è­˜å˜—è©¦ {attempt}/{max_retries}")
            
            try:
                captcha_text = await self.solve_captcha(page)
                
                # å¡«å¯«é©—è­‰ç¢¼
                print(f"âœï¸  å¡«å¯«é©—è­‰ç¢¼: {captcha_text}")
                valicode_input = page.locator('input[name="valicode"]')
                await valicode_input.fill("")  # å…ˆæ¸…ç©º
                await valicode_input.fill(captcha_text)
                await asyncio.sleep(0.5)
                
                # é»æ“Šç™»å…¥æŒ‰éˆ•
                print("ğŸ–±ï¸  é»æ“Šç™»å…¥æŒ‰éˆ•...")
                login_button = page.locator('a[href="javascript:docheck();"] .login-btn')
                await login_button.click()
                
                # ç­‰å¾…é é¢å°èˆª
                await asyncio.sleep(3)
                
                # æª¢æŸ¥æ˜¯å¦ç™»å…¥æˆåŠŸ
                current_url = page.url
                print(f"ğŸ“ ç•¶å‰ URL: {current_url}")
                
                if "ebook.hyread.com.tw" in current_url and "index.jsp" in current_url:
                    print("\n" + "="*60)
                    print("âœ… ç™»å…¥æˆåŠŸï¼")
                    print("="*60)
                    return True
                
                elif current_url == self.login_url:
                    print(f"âš ï¸  é©—è­‰ç¢¼å¯èƒ½éŒ¯èª¤ï¼Œæº–å‚™é‡è©¦...")
                    
                    if attempt < max_retries:
                        await valicode_input.fill("")
                        await asyncio.sleep(1)
                        continue
                    else:
                        print(f"\nâŒ å·²é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ ({max_retries})ï¼Œç™»å…¥å¤±æ•—")
                        return False
                
            except Exception as e:
                print(f"âŒ é©—è­‰ç¢¼è¾¨è­˜å¤±æ•—: {e}")
                if attempt < max_retries:
                    print("â³ ç­‰å¾…å¾Œé‡è©¦...")
                    await asyncio.sleep(2)
                    continue
                else:
                    raise
        
        return False
    
    async def check_and_borrow_book(self, page: Page, book_id: str) -> bool:
        """
        æª¢æŸ¥ä¸¦å€Ÿé–±æ›¸ç±
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            book_id: æ›¸ç± ID
            
        Returns:
            å€Ÿé–±æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*60)
        print("ğŸ“š é–‹å§‹æª¢æŸ¥æ›¸ç±")
        print("="*60)
        
        # å‰å¾€æ›¸ç±è©³æƒ…é é¢
        book_url = f"{self.base_url}/bookDetail.jsp?id={book_id}"
        print(f"ğŸ“„ æ­£åœ¨å‰å¾€æ›¸ç±é é¢: {book_url}")
        await page.goto(book_url)
        await asyncio.sleep(2)
        
        # æª¢æŸ¥ç·šä¸Šé–±è®€æŒ‰éˆ•
        try:
            # å®šä½ç·šä¸Šé–±è®€æŒ‰éˆ•
            read_button = page.locator('button.btn-collect:has-text("ç·šä¸Šé–±è®€")')
            
            # æª¢æŸ¥æŒ‰éˆ•æ˜¯å¦å­˜åœ¨
            if await read_button.count() == 0:
                print("âŒ æ‰¾ä¸åˆ°ç·šä¸Šé–±è®€æŒ‰éˆ•")
                return False
            
            # ç²å–æŒ‰éˆ•çš„ title å±¬æ€§
            button_title = await read_button.get_attribute('title')
            print(f"ğŸ“Š æŒ‰éˆ•ç‹€æ…‹: {button_title}")
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å¯ç”¨æ•¸é‡
            match = re.search(r'ç·šä¸Šé–±è®€äººæ•¸.*?å°šæœ‰(\d+)æœ¬', button_title, re.DOTALL)
            
            if match:
                available_count = int(match.group(1))
                print(f"ğŸ“Š å¯å€Ÿé–±æ•¸é‡: {available_count} æœ¬")
                
                if available_count > 0:
                    print("âœ… æ›¸ç±å¯å€Ÿé–±ï¼Œæº–å‚™é»æ“Šç·šä¸Šé–±è®€æŒ‰éˆ•...")
                    
                    # é»æ“Šç·šä¸Šé–±è®€æŒ‰éˆ•
                    await read_button.click()
                    await asyncio.sleep(3)
                    
                    # æª¢æŸ¥æ˜¯å¦æˆåŠŸé–‹å•Ÿé–±è®€é é¢
                    # å¯èƒ½æœƒé–‹å•Ÿæ–°åˆ†é æˆ–å½ˆå‡ºè¦–çª—
                    current_url = page.url
                    print(f"ğŸ“ ç•¶å‰ URL: {current_url}")
                    
                    # æª¢æŸ¥æ‰€æœ‰é é¢
                    all_pages = page.context.pages
                    print(f"ğŸ“„ ç›®å‰é–‹å•Ÿçš„é é¢æ•¸: {len(all_pages)}")
                    
                    reading_page = None
                    
                    if len(all_pages) > 1:
                        print("âœ… å·²é–‹å•Ÿæ–°çš„é–±è®€è¦–çª—")
                        # åˆ‡æ›åˆ°æ–°é é¢
                        reading_page = all_pages[-1]
                        await asyncio.sleep(2)
                        print(f"ğŸ“ é–±è®€é é¢ URL: {reading_page.url}")
                    else:
                        # å¦‚æœæ²’æœ‰é–‹å•Ÿæ–°é é¢ï¼Œå¯èƒ½åœ¨ç•¶å‰é é¢ä¸­æ‰“é–‹
                        print("âš ï¸  æœªåµæ¸¬åˆ°æ–°è¦–çª—ï¼Œæª¢æŸ¥ç•¶å‰é é¢...")
                        
                        # ç­‰å¾…é é¢å¯èƒ½çš„è®ŠåŒ–
                        await asyncio.sleep(2)
                        
                        # æª¢æŸ¥ç•¶å‰é é¢ URL æ˜¯å¦æ”¹è®Š
                        if page.url != current_url or "reader" in page.url.lower():
                            print("âœ… é–±è®€å™¨åœ¨ç•¶å‰é é¢ä¸­æ‰“é–‹")
                            reading_page = page
                        else:
                            # å†ç­‰å¾…ä¸¦é‡æ–°æª¢æŸ¥
                            await asyncio.sleep(3)
                            all_pages = page.context.pages
                            if len(all_pages) > 1:
                                reading_page = all_pages[-1]
                                print(f"âœ… å»¶é²åµæ¸¬åˆ°æ–°è¦–çª—: {reading_page.url}")
                            else:
                                print("âš ï¸  ä»æœªåµæ¸¬åˆ°é–±è®€è¦–çª—ï¼Œä½¿ç”¨ç•¶å‰é é¢")
                                reading_page = page
                    
                    print("\n" + "="*60)
                    print("âœ… å€Ÿé–±æˆåŠŸï¼")
                    print("="*60)
                    
                    # å¦‚æœå•Ÿç”¨çˆ¬èŸ²ï¼Œè¿”å›é–±è®€é é¢ç”¨æ–¼å¾ŒçºŒçˆ¬å–
                    if self.enable_scraping:
                        if reading_page:
                            print(f"ğŸ“– å°‡ä½¿ç”¨é é¢é€²è¡Œçˆ¬å–: {reading_page.url}")
                            return reading_page
                        else:
                            print("âŒ ç„¡æ³•ç²å–é–±è®€é é¢")
                            return False
                    else:
                        return True
                else:
                    print("âš ï¸  ç›®å‰æ²’æœ‰å¯å€Ÿé–±çš„å‰¯æœ¬")
                    return False
            else:
                print("âš ï¸  ç„¡æ³•è§£æå¯å€Ÿé–±æ•¸é‡")
                # å˜—è©¦ç›´æ¥é»æ“Šçœ‹çœ‹
                print("ğŸ” å˜—è©¦ç›´æ¥é»æ“ŠæŒ‰éˆ•...")
                await read_button.click()
                await asyncio.sleep(3)
                return True
                
        except Exception as e:
            print(f"âŒ æª¢æŸ¥æˆ–å€Ÿé–±æ›¸ç±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def click_accept_button(self, page: Page) -> bool:
        """
        é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦æˆåŠŸé»æ“Š
        """
        try:
            print("\nğŸ” å°‹æ‰¾ã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•...")
            
            # ç­‰å¾…æŒ‰éˆ•å‡ºç¾
            accept_button = page.locator('button:has-text("æˆ‘çŸ¥é“äº†")')
            
            # ç­‰å¾…æœ€å¤š 10 ç§’
            await accept_button.wait_for(state="visible", timeout=10000)
            
            print("ğŸ–±ï¸  é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•...")
            await accept_button.click()
            await asyncio.sleep(2)
            
            print("âœ… å·²é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•")
            return True
            
        except Exception as e:
            print(f"âš ï¸  æœªæ‰¾åˆ°æˆ–ç„¡æ³•é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•: {e}")
            return False
    
    async def get_current_iframe(self, page: Page) -> FrameLocator:
        """
        ç²å–ç•¶å‰é¡¯ç¤ºçš„ iframe
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            ç•¶å‰çš„ iframe locator
        """
        try:
            # ç›´æ¥æ‰¾åˆ°æ‰€æœ‰ iframe å…ƒç´ 
            iframes = page.locator('iframe')
            iframe_count = await iframes.count()
            
            # éæ­·æ‰€æœ‰ iframeï¼Œæ‰¾åˆ°ç¬¬ä¸€å€‹å¯è¦‹çš„
            for i in range(iframe_count):
                iframe_element = iframes.nth(i)
                
                # æª¢æŸ¥ iframe æ˜¯å¦å¯è¦‹
                is_visible = await iframe_element.is_visible()
                
                if is_visible:
                    # è¿”å›å¯è¦‹çš„ iframe çš„ frame_locator
                    # ä½¿ç”¨ nth(i) ä¾†ç²¾ç¢ºå®šä½
                    return page.frame_locator('iframe').nth(i)
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¯è¦‹çš„ï¼Œè¿”å›ç¬¬ä¸€å€‹
            print("âš ï¸  æœªæ‰¾åˆ°å¯è¦‹çš„ iframeï¼Œä½¿ç”¨ç¬¬ä¸€å€‹")
            return page.frame_locator('iframe').first
            
        except Exception as e:
            print(f"âš ï¸  ç²å– iframe æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # é™ç´šæ–¹æ¡ˆï¼šç›´æ¥è¿”å›ç¬¬ä¸€å€‹ iframe
            return page.frame_locator('iframe').first
    
    async def extract_html_with_formatting(self, element) -> str:
        """
        æå–å…ƒç´ çš„ HTML ä¸¦ä¿ç•™æ ¼å¼æ¨™ç±¤
        
        Args:
            element: Playwright å…ƒç´ 
            
        Returns:
            åŒ…å«æ ¼å¼çš„æ–‡å­—
        """
        try:
            # ç²å–å…ƒç´ çš„ innerHTML
            html = await element.inner_html()
            
            # è½‰æ› HTML æ ¼å¼ç‚º Markdown æ ¼å¼
            # ç²—é«”ï¼š<strong>, <b> -> **text**
            html = re.sub(r'<strong>(.*?)</strong>', r'**\1**', html)
            html = re.sub(r'<b>(.*?)</b>', r'**\1**', html)
            
            # æ–œé«”ï¼š<em>, <i> -> *text*
            html = re.sub(r'<em>(.*?)</em>', r'*\1*', html)
            html = re.sub(r'<i>(.*?)</i>', r'*\1*', html)
            
            # ç§»é™¤å…¶ä»– HTML æ¨™ç±¤ä½†ä¿ç•™å…§å®¹
            html = re.sub(r'<span[^>]*>(.*?)</span>', r'\1', html)
            html = re.sub(r'<div[^>]*>(.*?)</div>', r'\1', html)
            html = re.sub(r'<br\s*/?>', '\n', html)
            
            # ç§»é™¤æ‰€æœ‰å‰©é¤˜çš„ HTML æ¨™ç±¤
            html = re.sub(r'<[^>]+>', '', html)
            
            return html.strip()
            
        except Exception as e:
            # å¦‚æœå‡ºéŒ¯ï¼Œè¿”å›ç´”æ–‡å­—
            return await element.text_content()
    
    async def get_base_url_from_iframe(self, page: Page) -> str:
        """
        å¾ iframe ç²å– base URL
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            base URL æˆ–ç©ºå­—ä¸²
        """
        try:
            iframe = await self.get_current_iframe(page)
            base_element = iframe.locator('base').first
            base_href = await base_element.get_attribute('href')
            return base_href or ''
        except:
            return ''
    
    async def scrape_page_content(self, page: Page) -> Dict[str, any]:
        """
        æŠ“å–ç•¶å‰é é¢çš„å…§å®¹
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            åŒ…å«æ¨™é¡Œã€æ®µè½å’Œåœ–ç‰‡çš„å­—å…¸
        """
        try:
            # ç²å–ç•¶å‰çš„ iframe
            iframe = await self.get_current_iframe(page)
            
            content = {
                'headings': [],
                'paragraphs': [],
                'images': []
            }
            
            # æŠ“å–æ¨™é¡Œ (h1, h2, h3, h4, h5, h6)
            for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                elements = iframe.locator(tag)
                count = await elements.count()
                
                for i in range(count):
                    # ä½¿ç”¨æ–°æ–¹æ³•æå–åŒ…å«æ ¼å¼çš„æ–‡å­—
                    text = await self.extract_html_with_formatting(elements.nth(i))
                    if text and text.strip():
                        content['headings'].append({
                            'level': tag,
                            'text': text.strip()
                        })
            
            # æŠ“å–æ®µè½ï¼ˆåŒ…å«ä¸€èˆ¬æ®µè½å’Œè…³è¨»ï¼‰
            paragraphs = iframe.locator('p')
            p_count = await paragraphs.count()
            
            for i in range(p_count):
                # ä½¿ç”¨æ–°æ–¹æ³•æå–åŒ…å«æ ¼å¼çš„æ–‡å­—
                text = await self.extract_html_with_formatting(paragraphs.nth(i))
                if text and text.strip():
                    content['paragraphs'].append(text.strip())
            
            # é¡å¤–æŠ“å– footnoteï¼ˆè…³è¨»ï¼‰
            footnotes = iframe.locator('.footnote[role="doc-endnote"]')
            footnote_count = await footnotes.count()
            
            if footnote_count > 0:
                content['paragraphs'].append('\n---\n\n**è¨»é‡‹ï¼š**\n')
                
                for i in range(footnote_count):
                    footnote = footnotes.nth(i)
                    # ç²å– footnote å…§çš„æ‰€æœ‰æ®µè½
                    fn_paragraphs = footnote.locator('p')
                    fn_p_count = await fn_paragraphs.count()
                    
                    for j in range(fn_p_count):
                        text = await self.extract_html_with_formatting(fn_paragraphs.nth(j))
                        if text and text.strip():
                            content['paragraphs'].append(text.strip())
            
            # æŠ“å–åœ–ç‰‡ (HTML img æ¨™ç±¤)
            images = iframe.locator('img')
            img_count = await images.count()
            
            for i in range(img_count):
                src = await images.nth(i).get_attribute('src')
                alt = await images.nth(i).get_attribute('alt')
                if src:
                    content['images'].append({
                        'src': src,
                        'alt': alt or ''
                    })
            
            # æŠ“å–åœ–ç‰‡ (SVG image æ¨™ç±¤)
            svg_images = iframe.locator('image')
            svg_img_count = await svg_images.count()
            
            for i in range(svg_img_count):
                # SVG ä½¿ç”¨ xlink:href æˆ– href å±¬æ€§
                src = await svg_images.nth(i).get_attribute('xlink:href')
                if not src:
                    src = await svg_images.nth(i).get_attribute('href')
                
                if src:
                    # è™•ç†ç›¸å°è·¯å¾‘ï¼Œè½‰æ›ç‚ºçµ•å° URL
                    # ç²å– iframe çš„ base URL
                    try:
                        # å˜—è©¦å¾ iframe ç²å–å®Œæ•´ URL
                        base_element = iframe.locator('base').first
                        base_href = await base_element.get_attribute('href')
                        
                        if base_href and src.startswith('../'):
                            # è™•ç†ç›¸å°è·¯å¾‘
                            # ../Images/cover.jpg -> å¾ base_href è¨ˆç®—å®Œæ•´è·¯å¾‘
                            full_url = urljoin(base_href, src)
                            src = full_url
                    except:
                        # å¦‚æœå¤±æ•—ï¼Œä¿æŒåŸæ¨£
                        pass
                    
                    content['images'].append({
                        'src': src,
                        'alt': 'SVG åœ–ç‰‡'
                    })
            
            return content
            
        except Exception as e:
            print(f"âš ï¸  æŠ“å–é é¢å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'headings': [], 'paragraphs': [], 'images': []}
    
    async def download_image(self, url: str, page_number: int, base_url: str = None) -> str:
        """
        ä¸‹è¼‰åœ–ç‰‡åˆ°æœ¬åœ°
        
        Args:
            url: åœ–ç‰‡ URLï¼ˆå¯èƒ½æ˜¯ç›¸å°è·¯å¾‘ï¼‰
            page_number: é ç¢¼
            base_url: åŸºç¤ URLï¼ˆç”¨æ–¼è§£æç›¸å°è·¯å¾‘ï¼‰
            
        Returns:
            æœ¬åœ°åœ–ç‰‡è·¯å¾‘ï¼ˆç›¸å°æ–¼ Markdown æª”æ¡ˆï¼‰
        """
        # æª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
        if url in self.downloaded_images:
            return self.downloaded_images[url]
        
        try:
            # è™•ç†ç›¸å°è·¯å¾‘
            download_url = url
            if not url.startswith(('http://', 'https://')):
                if base_url:
                    # ä½¿ç”¨ urljoin è½‰æ›ç›¸å°è·¯å¾‘ç‚ºçµ•å°è·¯å¾‘
                    download_url = urljoin(base_url, url)
                    print(f"      ğŸ”— è½‰æ› URL: {url} -> {download_url}")
                else:
                    print(f"      âš ï¸  ç„¡æ³•ä¸‹è¼‰ç›¸å°è·¯å¾‘åœ–ç‰‡ï¼ˆç¼ºå°‘ base_urlï¼‰: {url}")
                    return url
            
            # ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆä½¿ç”¨ URL hash + é ç¢¼ï¼‰
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            ext = Path(url).suffix or '.jpg'
            filename = f"page_{page_number:04d}_{url_hash}{ext}"
            
            local_path = self.images_dir / filename
            
            # ä¸‹è¼‰åœ–ç‰‡
            async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
                response = await client.get(download_url)
                response.raise_for_status()
                
                # ä¿å­˜åœ–ç‰‡
                with open(local_path, 'wb') as f:
                    f.write(response.content)
            
            # è¨˜éŒ„ä¸‹è¼‰ï¼ˆç›¸å°æ–¼ downloads ç›®éŒ„çš„è·¯å¾‘ï¼‰
            relative_path = f"images/book_{self.book_id}/{filename}"
            self.downloaded_images[url] = relative_path
            
            print(f"      ğŸ“¥ å·²ä¸‹è¼‰åœ–ç‰‡: {filename}")
            return relative_path
            
        except Exception as e:
            print(f"      âš ï¸  ä¸‹è¼‰åœ–ç‰‡å¤±æ•— ({url}): {e}")
            # ä¸‹è¼‰å¤±æ•—æ™‚è¿”å›åŸ URL
            return url
    
    def convert_to_markdown(self, content: Dict[str, any], page_number: int = 0) -> str:
        """
        å°‡å…§å®¹è½‰æ›ç‚º Markdown æ ¼å¼
        
        Args:
            content: åŒ…å«æ¨™é¡Œã€æ®µè½å’Œåœ–ç‰‡çš„å­—å…¸
            page_number: é ç¢¼ï¼ˆç”¨æ–¼åœ–ç‰‡è·¯å¾‘ï¼‰
            
        Returns:
            Markdown æ ¼å¼çš„æ–‡å­—
        """
        markdown = []
        
        # è½‰æ›æ¨™é¡Œï¼ˆh1 -> ##, h2 -> ###, h3 -> ####, ä»¥æ­¤é¡æ¨ï¼‰
        for heading in content['headings']:
            level = int(heading['level'][1])  # h1 -> 1, h2 -> 2, h3 -> 3
            # h1 å°æ‡‰åˆ° ##ï¼ˆ2å€‹#ï¼‰ï¼Œh2 å°æ‡‰åˆ° ###ï¼ˆ3å€‹#ï¼‰
            prefix = '#' * (level + 1)
            markdown.append(f"{prefix} {heading['text']}\n")
        
        # è½‰æ›æ®µè½ï¼ˆå·²åŒ…å«ç²—é«”å’Œæ–œé«”ï¼‰
        for paragraph in content['paragraphs']:
            markdown.append(f"{paragraph}\n")
        
        # è½‰æ›åœ–ç‰‡ï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘æˆ– URLï¼‰
        for image in content['images']:
            alt_text = image['alt'] or 'åœ–ç‰‡'
            img_path = image.get('local_path', image['src'])  # å„ªå…ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘
            markdown.append(f"![{alt_text}]({img_path})\n")
        
        return '\n'.join(markdown)
    
    async def get_reading_progress(self, page: Page) -> dict:
        """
        ç²å–é–±è®€é€²åº¦ä¿¡æ¯
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            åŒ…å«é€²åº¦ä¿¡æ¯çš„å­—å…¸ {'total_percent': 100, 'chapter_current': 4, 'chapter_total': 4}
        """
        try:
            # å®šä½é€²åº¦å®¹å™¨
            progress_container = page.locator('#page-info-container')
            
            # ç­‰å¾…å…ƒç´ å‡ºç¾
            await progress_container.wait_for(state="visible", timeout=5000)
            
            # ç²å–æ–‡å­—å…§å®¹
            progress_text = await progress_container.text_content()
            
            # è§£æé€²åº¦æ–‡å­—
            # æ ¼å¼ï¼šå…¨æ–‡ 10%ï¼æœ¬ç« ç¬¬ 1 é  / 4 é 
            progress_info = {
                'total_percent': 0,
                'chapter_current': 0,
                'chapter_total': 0,
                'text': progress_text.strip()
            }
            
            # æå–å…¨æ–‡ç™¾åˆ†æ¯”
            total_match = re.search(r'å…¨æ–‡\s*(\d+)%', progress_text)
            if total_match:
                progress_info['total_percent'] = int(total_match.group(1))
            
            # æå–æœ¬ç« é æ•¸
            chapter_match = re.search(r'æœ¬ç« ç¬¬?\s*(\d+)\s*é \s*/\s*(\d+)\s*é ', progress_text)
            if chapter_match:
                progress_info['chapter_current'] = int(chapter_match.group(1))
                progress_info['chapter_total'] = int(chapter_match.group(2))
            
            return progress_info
            
        except Exception as e:
            print(f"      âš ï¸  ç„¡æ³•ç²å–é–±è®€é€²åº¦: {e}")
            return {
                'total_percent': 0,
                'chapter_current': 0,
                'chapter_total': 0,
                'text': ''
            }
    
    async def is_last_page(self, page: Page) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦ç‚ºæœ€å¾Œä¸€é 
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦ç‚ºæœ€å¾Œä¸€é 
        """
        progress = await self.get_reading_progress(page)
        
        # åˆ¤æ–·æ¢ä»¶ï¼šå…¨æ–‡ 100% ä¸”æœ¬ç« åˆ°æœ€å¾Œä¸€é 
        is_last = (
            progress['total_percent'] == 100 and
            progress['chapter_current'] > 0 and
            progress['chapter_current'] == progress['chapter_total']
        )
        
        return is_last
    
    async def turn_page(self, page: Page) -> bool:
        """
        ç¿»åˆ°ä¸‹ä¸€é ï¼ˆæ¨¡æ“¬éµç›¤å³éµï¼‰
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦æˆåŠŸç¿»é 
        """
        try:
            # æŒ‰ä¸‹éµç›¤å³éµ
            await page.keyboard.press('ArrowRight')
            
            # ç­‰å¾…é é¢è¼‰å…¥
            await asyncio.sleep(2)
            
            return True
            
        except Exception as e:
            print(f"âš ï¸  ç¿»é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    async def download_images_for_content(self, content: Dict[str, any], page_number: int, base_url: str = None):
        """
        ä¸‹è¼‰å…§å®¹ä¸­çš„æ‰€æœ‰åœ–ç‰‡
        
        Args:
            content: åŒ…å«åœ–ç‰‡åˆ—è¡¨çš„å…§å®¹å­—å…¸
            page_number: é ç¢¼
            base_url: åŸºç¤ URLï¼ˆç”¨æ–¼è§£æç›¸å°è·¯å¾‘ï¼‰
        """
        if not self.download_images or not content['images']:
            return
        
        for image in content['images']:
            url = image['src']
            
            # ä¸‹è¼‰åœ–ç‰‡ä¸¦æ›´æ–°ç‚ºæœ¬åœ°è·¯å¾‘
            local_path = await self.download_image(url, page_number, base_url)
            image['local_path'] = local_path
    
    async def scrape_entire_book(self, reading_page: Page) -> str:
        """
        çˆ¬å–æ•´æœ¬æ›¸çš„å…§å®¹
        
        Args:
            reading_page: é–±è®€é é¢çš„ Page ç‰©ä»¶
            
        Returns:
            å®Œæ•´çš„ Markdown å…§å®¹
        """
        print("\n" + "="*60)
        print("ğŸ“š é–‹å§‹çˆ¬å–æ›¸ç±å…§å®¹")
        print("="*60)
        
        # å¦‚æœéœ€è¦ä¸‹è¼‰åœ–ç‰‡ï¼Œå»ºç«‹åœ–ç‰‡ç›®éŒ„
        if self.download_images:
            self.images_dir = Path("downloads") / "images" / f"book_{self.book_id}"
            self.images_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ åœ–ç‰‡å°‡ä¿å­˜åˆ°: {self.images_dir}")
        
        # é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•
        await self.click_accept_button(reading_page)
        
        # ç­‰å¾…é é¢å®Œå…¨è¼‰å…¥
        await asyncio.sleep(3)
        
        all_content = []
        previous_markdown = ""  # ç”¨æ–¼æª¢æ¸¬é‡è¤‡
        page_number = 0
        duplicate_count = 0  # é€£çºŒç©ºç™½é è¨ˆæ•¸
        
        # ç²å– base URLï¼ˆç”¨æ–¼åœ–ç‰‡ä¸‹è¼‰ï¼‰
        base_url = await self.get_base_url_from_iframe(reading_page)
        if base_url:
            print(f"ğŸ“ Base URL: {base_url}")
        
        while page_number < self.max_pages:
            page_number += 1
            
            # ç²å–é–±è®€é€²åº¦
            progress = await self.get_reading_progress(reading_page)
            print(f"\nğŸ“– æ­£åœ¨çˆ¬å–ç¬¬ {page_number} é ... [{progress['text']}]")
            
            # æŠ“å–ç•¶å‰é é¢å…§å®¹
            content = await self.scrape_page_content(reading_page)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰å…§å®¹
            has_content = bool(content['headings'] or content['paragraphs'] or content['images'])
            
            if not has_content:
                print("âš ï¸  ç•¶å‰é é¢æ²’æœ‰å…§å®¹")
                duplicate_count += 1
                
                if duplicate_count >= 3:
                    print("âš ï¸  é€£çºŒ 3 é æ²’æœ‰å…§å®¹ï¼Œå¯èƒ½å·²åˆ°é”çµå°¾")
                    break
            else:
                duplicate_count = 0
                print(f"   âœ“ æœ‰å…§å®¹: æ¨™é¡Œ={len(content['headings'])}, æ®µè½={len(content['paragraphs'])}, åœ–ç‰‡={len(content['images'])}")
            
            # ä¸‹è¼‰åœ–ç‰‡ï¼ˆå¦‚æœå•Ÿç”¨ï¼‰
            if self.download_images and content['images']:
                await self.download_images_for_content(content, page_number, base_url)
            
            # è½‰æ›ç‚º Markdown
            markdown = self.convert_to_markdown(content, page_number)
            
            # æª¢æŸ¥æ˜¯å¦èˆ‡ä¸Šä¸€é å®Œå…¨ç›¸åŒï¼ˆé¿å…é‡è¤‡ä¿å­˜ï¼‰
            if markdown.strip() and markdown != previous_markdown:
                all_content.append(markdown)
                previous_markdown = markdown
                print(f"   ğŸ’¾ å·²ä¿å­˜å…§å®¹")
            elif markdown == previous_markdown:
                print(f"   âš ï¸  å…§å®¹èˆ‡ä¸Šä¸€é ç›¸åŒï¼Œè·³éä¿å­˜")
            else:
                print(f"   âš ï¸  å…§å®¹ç‚ºç©ºï¼Œè·³éä¿å­˜")
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºæœ€å¾Œä¸€é ï¼ˆä½¿ç”¨é–±è®€é€²åº¦ï¼‰
            if await self.is_last_page(reading_page):
                print("âœ… å·²åˆ°é”æœ€å¾Œä¸€é ï¼ˆå…¨æ–‡ 100% ä¸”æœ¬ç« æœ€å¾Œä¸€é ï¼‰")
                break
            
            # å‚™ç”¨æª¢æŸ¥ï¼šåµæ¸¬çµæŸæ¨™èªŒ
            combined_text = ' '.join(content['paragraphs'])
            if any(keyword in combined_text for keyword in ['ç‰ˆæ¬Šé ', 'ç‰ˆæ¬Šæ‰€æœ‰', 'Copyright', 'The End', 'å…¨æ›¸å®Œ']):
                print("âœ… åµæ¸¬åˆ°çµæŸæ¨™èªŒ")
                break
            
            # é¡¯ç¤ºçµ±è¨ˆï¼ˆä¸é‡è¤‡é¡¯ç¤ºï¼Œå‰é¢å·²ç¶“é¡¯ç¤ºéï¼‰
            # print(f"   - æ¨™é¡Œ: {len(content['headings'])} å€‹")
            # print(f"   - æ®µè½: {len(content['paragraphs'])} æ®µ")
            # print(f"   - åœ–ç‰‡: {len(content['images'])} å¼µ")
            
            # ç¿»åˆ°ä¸‹ä¸€é 
            if page_number < self.max_pages:
                success = await self.turn_page(reading_page)
                if not success:
                    print("âš ï¸  ç¿»é å¤±æ•—ï¼Œåœæ­¢çˆ¬å–")
                    break
        
        print("\n" + "="*60)
        print(f"âœ… çˆ¬å–å®Œæˆï¼å…± {page_number} é ")
        print("="*60)
        
        # ç”Ÿæˆå®Œæ•´çš„ Markdown æ–‡ä»¶ï¼ˆä¸åŒ…å«åˆ†é æ¨™è¨˜ï¼‰
        # å°‡æ‰€æœ‰å…§å®¹åˆä½µï¼Œç”¨å–®å€‹æ›è¡Œåˆ†éš”
        return '\n'.join(all_content)
    
    async def run(self, headless: bool = False, slow_mo: int = 100, wait_time: int = 30) -> bool:
        """
        åŸ·è¡Œå®Œæ•´çš„å€Ÿé–±æµç¨‹ï¼ˆåŒ…å«çˆ¬èŸ²ï¼‰
        
        Args:
            headless: æ˜¯å¦ä½¿ç”¨ç„¡é ­æ¨¡å¼ï¼ˆä¸é¡¯ç¤ºç€è¦½å™¨è¦–çª—ï¼‰
            slow_mo: æ¸›æ…¢æ“ä½œé€Ÿåº¦ï¼ˆæ¯«ç§’ï¼‰ï¼Œä¾¿æ–¼è§€å¯Ÿ
            wait_time: æˆåŠŸå¾Œç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œè®“ä½¿ç”¨è€…çœ‹åˆ°çµæœ
            
        Returns:
            åŸ·è¡Œæ˜¯å¦æˆåŠŸ
        """
        async with async_playwright() as p:
            # å•Ÿå‹•ç€è¦½å™¨
            print(f"ğŸŒ æ­£åœ¨å•Ÿå‹•ç€è¦½å™¨ (headless={headless})...")
            browser: Browser = await p.chromium.launch(
                headless=headless,
                slow_mo=slow_mo
            )
            
            try:
                # å»ºç«‹æ–°é é¢
                page: Page = await browser.new_page()
                
                # æ­¥é©Ÿ 1: ç™»å…¥
                login_success = await self.login(page)
                if not login_success:
                    print("\nâŒ ç™»å…¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
                    return False
                
                # æ­¥é©Ÿ 2: æª¢æŸ¥ä¸¦å€Ÿé–±æ›¸ç±
                borrow_result = await self.check_and_borrow_book(page, self.book_id)
                
                if not borrow_result:
                    print("\nâŒ å€Ÿé–±å¤±æ•—")
                    return False
                
                # æ­¥é©Ÿ 3: å¦‚æœå•Ÿç”¨çˆ¬èŸ²ä¸”æˆåŠŸå€Ÿé–±ï¼Œé–‹å§‹çˆ¬å–å…§å®¹
                if self.enable_scraping and isinstance(borrow_result, Page):
                    reading_page = borrow_result
                    
                    # çˆ¬å–æ•´æœ¬æ›¸
                    markdown_content = await self.scrape_entire_book(reading_page)
                    
                    # å„²å­˜ç‚ºæª”æ¡ˆ
                    output_dir = Path("downloads")
                    output_dir.mkdir(exist_ok=True)
                    
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    output_file = output_dir / f"book_{self.book_id}_{timestamp}.md"
                    
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(markdown_content)
                    
                    print(f"\nğŸ’¾ å·²å„²å­˜è‡³: {output_file}")
                    print(f"ğŸ“Š æª”æ¡ˆå¤§å°: {output_file.stat().st_size / 1024:.2f} KB")
                    
                    # ç­‰å¾…ä¸€æ®µæ™‚é–“è®“ä½¿ç”¨è€…çœ‹åˆ°çµæœ
                    if not headless:
                        print(f"\nâ³ å°‡åœ¨ {wait_time} ç§’å¾Œé—œé–‰ç€è¦½å™¨...")
                        await asyncio.sleep(wait_time)
                    
                    return True
                
                elif not self.enable_scraping:
                    # åªå€Ÿé–±ï¼Œä¸çˆ¬èŸ²
                    if not headless:
                        print(f"\nâ³ å°‡åœ¨ {wait_time} ç§’å¾Œé—œé–‰ç€è¦½å™¨...")
                        await asyncio.sleep(wait_time)
                    return True
                
                return False
                
            except Exception as e:
                print(f"\nâŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback
                traceback.print_exc()
                return False
                
            finally:
                # é—œé–‰ç€è¦½å™¨
                await browser.close()
                print("\nğŸ”š ç€è¦½å™¨å·²é—œé–‰")


async def main():
    """ä¸»ç¨‹å¼"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±å·¥å…·                â•‘
â•‘                                                              â•‘
â•‘  ä½¿ç”¨ Playwright + Google Gemini API è‡ªå‹•è¾¨è­˜é©—è­‰ç¢¼         â•‘
â•‘  è‡ªå‹•ç™»å…¥ â†’ æª¢æŸ¥å¯å€Ÿæ•¸é‡ â†’ å€Ÿé–±é›»å­æ›¸                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    try:
        # åˆå§‹åŒ–å€Ÿé–±å™¨
        scraper = HyReadScraper(env_file=".env_hyread")
        
        # åŸ·è¡Œå€Ÿé–±æµç¨‹
        # headless=False: é¡¯ç¤ºç€è¦½å™¨è¦–çª—ï¼ˆæ–¹ä¾¿è§€å¯Ÿï¼‰
        # headless=True: ç„¡é ­æ¨¡å¼ï¼ˆé©åˆè‡ªå‹•åŒ–åŸ·è¡Œï¼‰
        # wait_time: æˆåŠŸå¾Œç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰
        success = await scraper.run(
            headless=False, 
            slow_mo=100,
            wait_time=30
        )
        
        if success:
            print("\nâœ¨ å€Ÿé–±æµç¨‹å®Œæˆï¼")
            sys.exit(0)
        else:
            print("\nâš ï¸  å€Ÿé–±æµç¨‹æœªæˆåŠŸå®Œæˆ")
            sys.exit(1)
            
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("\nè«‹ç¢ºä¿ä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ä¸¦åŒ…å«å¿…è¦çš„è¨­å®š:")
        print("   .env_hyread")
        sys.exit(1)
        
    except ImportError as e:
        print(f"\nâŒ å¥—ä»¶éŒ¯èª¤: {e}")
        sys.exit(1)
        
    except ValueError as e:
        print(f"\nâŒ è¨­å®šéŒ¯èª¤: {e}")
        sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # åŸ·è¡Œä¸»ç¨‹å¼
    asyncio.run(main())


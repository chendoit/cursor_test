#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±å·¥å…·
ä½¿ç”¨ Playwright å’Œ Google Gemini API é€²è¡Œé©—è­‰ç¢¼è¾¨è­˜å’Œè‡ªå‹•å€Ÿé–±
"""

import asyncio
import os
import re
import sys
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from urllib.parse import urljoin
import hashlib

from dotenv import load_dotenv
from playwright.async_api import async_playwright, Page, Browser, FrameLocator
import httpx

try:
    import google.generativeai as genai
    HAS_GEMINI = True
except ImportError:
    HAS_GEMINI = False


class HyReadScraper:
    """æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±é¡åˆ¥"""
    
    def __init__(self, env_file: str = ".env_hyread"):
        """
        åˆå§‹åŒ–å€Ÿé–±å™¨
        
        Args:
            env_file: ç’°å¢ƒè®Šæ•¸æª”æ¡ˆè·¯å¾‘
        """
        # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
        env_path = Path(env_file)
        if not env_path.exists():
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸æª”æ¡ˆ: {env_file}")
        
        load_dotenv(env_path)
        
        # è®€å–è¨­å®š
        self.account = os.getenv("HYREAD_ACCOUNT")
        self.password = os.getenv("HYREAD_PASSWORD")
        self.google_api_key = os.getenv("OPENAI_API_KEY")
        self.model_name = os.getenv("OPENAI_MODEL", "gemini-2.0-flash-exp")
        self.book_id = os.getenv("HYREAD_BOOK_ID", "279235")  # é è¨­æ›¸ç± ID
        self.captcha_mode = os.getenv("CAPTCHA_MODE", "manual").lower()  # é©—è­‰ç¢¼æ¨¡å¼
        self.enable_scraping = os.getenv("ENABLE_SCRAPING", "true").lower() == "true"  # æ˜¯å¦å•Ÿç”¨çˆ¬èŸ²
        self.max_pages = int(os.getenv("MAX_PAGES", "999"))  # æœ€å¤§çˆ¬å–é æ•¸
        self.download_images = os.getenv("DOWNLOAD_IMAGES", "true").lower() == "true"  # æ˜¯å¦ä¸‹è¼‰åœ–ç‰‡
        
        # åœ–ç‰‡ä¸‹è¼‰ç›¸é—œ
        self.images_dir = None
        self.downloaded_images = {}  # URL -> æœ¬åœ°è·¯å¾‘æ˜ å°„
        self.book_title = None  # æ›¸å
        
        # é©—è­‰å¿…è¦åƒæ•¸
        if not all([self.account, self.password]):
            raise ValueError("è«‹ç¢ºä¿ .env_hyread ä¸­åŒ…å« HYREAD_ACCOUNT å’Œ HYREAD_PASSWORD")
        
        # å¦‚æœä½¿ç”¨è‡ªå‹•æ¨¡å¼ï¼Œéœ€è¦æª¢æŸ¥ API Key å’Œ Gemini SDK
        if self.captcha_mode == "auto":
            if not self.google_api_key:
                raise ValueError("è‡ªå‹•æ¨¡å¼éœ€è¦ OPENAI_API_KEYï¼Œæˆ–å°‡ CAPTCHA_MODE è¨­ç‚º manual")
            
            if not HAS_GEMINI:
                raise ImportError(
                    "è«‹å®‰è£ Google Gemini SDK:\n"
                    "pip install google-generativeai Pillow"
                )
            
            # è¨­å®š Gemini API
            genai.configure(api_key=self.google_api_key)
            
            # åˆå§‹åŒ–æ¨¡å‹
            self.model = genai.GenerativeModel(self.model_name)
        
        # URL è¨­å®š
        self.login_url = "https://tycccgov.ebook.hyread.com.tw/Template/RWD3.0/liblogin.jsp"
        self.base_url = "https://tycccgov.ebook.hyread.com.tw"
        
        print(f"âœ… å·²è¼‰å…¥è¨­å®š:")
        print(f"   - å¸³è™Ÿ: {self.account}")
        print(f"   - é©—è­‰ç¢¼æ¨¡å¼: {'è‡ªå‹•è¾¨è­˜ (Gemini)' if self.captcha_mode == 'auto' else 'æ‰‹å‹•è¼¸å…¥'}")
        if self.captcha_mode == "auto":
            print(f"   - Gemini æ¨¡å‹: {self.model_name}")
        print(f"   - ç›®æ¨™æ›¸ç± ID: {self.book_id}")
        print(f"   - çˆ¬èŸ²æ¨¡å¼: {'å•Ÿç”¨' if self.enable_scraping else 'åœç”¨'}")
        if self.enable_scraping:
            print(f"   - æœ€å¤§çˆ¬å–é æ•¸: {self.max_pages}")
            print(f"   - ä¸‹è¼‰åœ–ç‰‡: {'æ˜¯' if self.download_images else 'å¦'}")
    
    async def solve_captcha(self, page: Page) -> str:
        """
        è§£æ±ºé©—è­‰ç¢¼
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            è¾¨è­˜å‡ºçš„é©—è­‰ç¢¼æ–‡å­—
        """
        # å®šä½é©—è­‰ç¢¼åœ–ç‰‡
        captcha_img = page.locator("#conImg")
        await captcha_img.wait_for(state="visible", timeout=10000)
        
        if self.captcha_mode == "manual":
            # æ‰‹å‹•æ¨¡å¼ï¼šé¡¯ç¤ºé©—è­‰ç¢¼ä¸¦ç­‰å¾…ä½¿ç”¨è€…è¼¸å…¥
            print("ğŸ“¸ é©—è­‰ç¢¼åœ–ç‰‡å·²é¡¯ç¤ºåœ¨ç€è¦½å™¨ä¸­")
            print("ğŸ‘€ è«‹æŸ¥çœ‹ç€è¦½å™¨è¦–çª—ä¸­çš„é©—è­‰ç¢¼")
            print("="*60)
            
            # ç­‰å¾…ä¸€ä¸‹è®“ä½¿ç”¨è€…çœ‹æ¸…æ¥šé©—è­‰ç¢¼
            await asyncio.sleep(1)
            
            # å¾å‘½ä»¤åˆ—è®€å–ä½¿ç”¨è€…è¼¸å…¥
            captcha_text = input("âŒ¨ï¸  è«‹è¼¸å…¥é©—è­‰ç¢¼: ").strip()
            
            if not captcha_text:
                raise ValueError("é©—è­‰ç¢¼ä¸èƒ½ç‚ºç©º")
            
            print(f"âœ… æ‚¨è¼¸å…¥çš„é©—è­‰ç¢¼: {captcha_text}")
            return captcha_text
            
        else:
            # è‡ªå‹•æ¨¡å¼ï¼šä½¿ç”¨ Gemini API è¾¨è­˜
            print("ğŸ“¸ æ­£åœ¨æˆªå–é©—è­‰ç¢¼åœ–ç‰‡...")
            
            # æˆªå–é©—è­‰ç¢¼åœ–ç‰‡
            captcha_screenshot = await captcha_img.screenshot()
            
            print("ğŸ¤– æ­£åœ¨å‘¼å« Google Gemini API è¾¨è­˜é©—è­‰ç¢¼...")
            
            try:
                # æº–å‚™åœ–ç‰‡
                import PIL.Image
                import io
                image = PIL.Image.open(io.BytesIO(captcha_screenshot))
                
                # å‘¼å« Gemini Vision API
                prompt = (
                    "Please identify the text or numbers in this CAPTCHA image. "
                    "Return ONLY the CAPTCHA text without any explanation, punctuation, or formatting. "
                    "If you see letters and numbers, return them exactly as shown."
                )
                
                response = self.model.generate_content([prompt, image])
                
                # æª¢æŸ¥å›æ‡‰
                if not response.text:
                    raise ValueError("Gemini API å›æ‡‰å…§å®¹ç‚ºç©º")
                
                captcha_text = response.text.strip()
                print(f"âœ… é©—è­‰ç¢¼è¾¨è­˜çµæœ: {captcha_text}")
                return captcha_text
                
            except Exception as e:
                print(f"âŒ Gemini API å‘¼å«å¤±æ•—: {e}")
                raise
    
    async def login(self, page: Page) -> bool:
        """
        åŸ·è¡Œè‡ªå‹•ç™»å…¥
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            ç™»å…¥æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*60)
        print("ğŸš€ é–‹å§‹è‡ªå‹•ç™»å…¥æµç¨‹")
        print("="*60)
        
        # å‰å¾€ç™»å…¥é é¢
        print(f"ğŸ“„ æ­£åœ¨å‰å¾€ç™»å…¥é é¢: {self.login_url}")
        await page.goto(self.login_url)
        await asyncio.sleep(2)
        
        # å¡«å¯«å¸³è™Ÿ
        print(f"âœï¸  å¡«å¯«å¸³è™Ÿ: {self.account}")
        account_input = page.locator('input[name="account2"]')
        await account_input.wait_for(state="visible", timeout=10000)
        await account_input.fill(self.account)
        await asyncio.sleep(0.5)
        
        # å¡«å¯«å¯†ç¢¼
        print("ğŸ”’ å¡«å¯«å¯†ç¢¼...")
        password_input = page.locator('input[name="passwd2"]')
        await password_input.fill(self.password)
        await asyncio.sleep(0.5)
        
        # è¾¨è­˜ä¸¦å¡«å¯«é©—è­‰ç¢¼
        max_retries = 3
        for attempt in range(1, max_retries + 1):
            print(f"\nğŸ” é©—è­‰ç¢¼è¾¨è­˜å˜—è©¦ {attempt}/{max_retries}")
            
            try:
                captcha_text = await self.solve_captcha(page)
                
                # å¡«å¯«é©—è­‰ç¢¼
                print(f"âœï¸  å¡«å¯«é©—è­‰ç¢¼: {captcha_text}")
                valicode_input = page.locator('input[name="valicode"]')
                await valicode_input.fill("")  # å…ˆæ¸…ç©º
                await valicode_input.fill(captcha_text)
                await asyncio.sleep(0.5)
                
                # é»æ“Šç™»å…¥æŒ‰éˆ•
                print("ğŸ–±ï¸  é»æ“Šç™»å…¥æŒ‰éˆ•...")
                login_button = page.locator('a[href="javascript:docheck();"] .login-btn')
                await login_button.click()
                
                # ç­‰å¾…é é¢å°èˆª
                await asyncio.sleep(3)
                
                # æª¢æŸ¥æ˜¯å¦ç™»å…¥æˆåŠŸ
                current_url = page.url
                print(f"ğŸ“ ç•¶å‰ URL: {current_url}")
                
                if "ebook.hyread.com.tw" in current_url and "index.jsp" in current_url:
                    print("\n" + "="*60)
                    print("âœ… ç™»å…¥æˆåŠŸï¼")
                    print("="*60)
                    return True
                
                elif current_url == self.login_url:
                    print(f"âš ï¸  é©—è­‰ç¢¼å¯èƒ½éŒ¯èª¤ï¼Œæº–å‚™é‡è©¦...")
                    
                    if attempt < max_retries:
                        await valicode_input.fill("")
                        await asyncio.sleep(1)
                        continue
                    else:
                        print(f"\nâŒ å·²é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ ({max_retries})ï¼Œç™»å…¥å¤±æ•—")
                        return False
                
            except Exception as e:
                print(f"âŒ é©—è­‰ç¢¼è¾¨è­˜å¤±æ•—: {e}")
                if attempt < max_retries:
                    print("â³ ç­‰å¾…å¾Œé‡è©¦...")
                    await asyncio.sleep(2)
                    continue
                else:
                    raise
        
        return False
    
    async def check_and_borrow_book(self, page: Page, book_id: str) -> bool:
        """
        æª¢æŸ¥ä¸¦å€Ÿé–±æ›¸ç±
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            book_id: æ›¸ç± ID
            
        Returns:
            å€Ÿé–±æ˜¯å¦æˆåŠŸ
        """
        print("\n" + "="*60)
        print("ğŸ“š é–‹å§‹æª¢æŸ¥æ›¸ç±")
        print("="*60)
        
        # å‰å¾€æ›¸ç±è©³æƒ…é é¢
        book_url = f"{self.base_url}/bookDetail.jsp?id={book_id}"
        print(f"ğŸ“„ æ­£åœ¨å‰å¾€æ›¸ç±é é¢: {book_url}")
        await page.goto(book_url)
        await asyncio.sleep(2)
        
        # æå–æ›¸åï¼ˆå–åˆ°ç¬¬ä¸€å€‹æ¨™é»ç¬¦è™Ÿï¼‰
        try:
            book_title_element = page.locator('.book-detail h3')
            if await book_title_element.count() > 0:
                full_title = await book_title_element.text_content()
                
                if full_title:
                    # å–åˆ°ç¬¬ä¸€å€‹æ¨™é»ç¬¦è™Ÿï¼ˆï¼š:ã€ã€‚ï¼ï¼Ÿï¼‰
                    import re
                    match = re.search(r'^([^ï¼š:ã€ã€‚ï¼ï¼Ÿ]+)', full_title.strip())
                    if match:
                        short_title = match.group(1).strip()
                        self.book_title = short_title
                        print(f"ğŸ“– æ›¸å: {short_title}")
                    else:
                        self.book_title = full_title.strip()
                        print(f"ğŸ“– æ›¸å: {self.book_title}")
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•æå–æ›¸å: {e}")
            self.book_title = f"book_{book_id}"
        
        # æª¢æŸ¥ç·šä¸Šé–±è®€æŒ‰éˆ•
        try:
            # å®šä½ç·šä¸Šé–±è®€æŒ‰éˆ•
            read_button = page.locator('button.btn-collect:has-text("ç·šä¸Šé–±è®€")')
            
            # æª¢æŸ¥æŒ‰éˆ•æ˜¯å¦å­˜åœ¨
            if await read_button.count() == 0:
                print("âŒ æ‰¾ä¸åˆ°ç·šä¸Šé–±è®€æŒ‰éˆ•")
                return False
            
            # ç²å–æŒ‰éˆ•çš„ title å±¬æ€§
            button_title = await read_button.get_attribute('title')
            print(f"ğŸ“Š æŒ‰éˆ•ç‹€æ…‹: {button_title}")
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å¯ç”¨æ•¸é‡
            match = re.search(r'ç·šä¸Šé–±è®€äººæ•¸.*?å°šæœ‰(\d+)æœ¬', button_title, re.DOTALL)
            
            if match:
                available_count = int(match.group(1))
                print(f"ğŸ“Š å¯å€Ÿé–±æ•¸é‡: {available_count} æœ¬")
                
                if available_count > 0:
                    print("âœ… æ›¸ç±å¯å€Ÿé–±ï¼Œæº–å‚™é»æ“Šç·šä¸Šé–±è®€æŒ‰éˆ•...")
                    
                    # é»æ“Šç·šä¸Šé–±è®€æŒ‰éˆ•
                    await read_button.click()
                    await asyncio.sleep(3)
                    
                    # æª¢æŸ¥æ˜¯å¦æˆåŠŸé–‹å•Ÿé–±è®€é é¢
                    # å¯èƒ½æœƒé–‹å•Ÿæ–°åˆ†é æˆ–å½ˆå‡ºè¦–çª—
                    current_url = page.url
                    print(f"ğŸ“ ç•¶å‰ URL: {current_url}")
                    
                    # æª¢æŸ¥æ‰€æœ‰é é¢
                    all_pages = page.context.pages
                    print(f"ğŸ“„ ç›®å‰é–‹å•Ÿçš„é é¢æ•¸: {len(all_pages)}")
                    
                    reading_page = None
                    
                    if len(all_pages) > 1:
                        print("âœ… å·²é–‹å•Ÿæ–°çš„é–±è®€è¦–çª—")
                        # åˆ‡æ›åˆ°æ–°é é¢
                        reading_page = all_pages[-1]
                        await asyncio.sleep(2)
                        print(f"ğŸ“ é–±è®€é é¢ URL: {reading_page.url}")
                    else:
                        # å¦‚æœæ²’æœ‰é–‹å•Ÿæ–°é é¢ï¼Œå¯èƒ½åœ¨ç•¶å‰é é¢ä¸­æ‰“é–‹
                        print("âš ï¸  æœªåµæ¸¬åˆ°æ–°è¦–çª—ï¼Œæª¢æŸ¥ç•¶å‰é é¢...")
                        
                        # ç­‰å¾…é é¢å¯èƒ½çš„è®ŠåŒ–
                        await asyncio.sleep(2)
                        
                        # æª¢æŸ¥ç•¶å‰é é¢ URL æ˜¯å¦æ”¹è®Š
                        if page.url != current_url or "reader" in page.url.lower():
                            print("âœ… é–±è®€å™¨åœ¨ç•¶å‰é é¢ä¸­æ‰“é–‹")
                            reading_page = page
                        else:
                            # å†ç­‰å¾…ä¸¦é‡æ–°æª¢æŸ¥
                            await asyncio.sleep(3)
                            all_pages = page.context.pages
                            if len(all_pages) > 1:
                                reading_page = all_pages[-1]
                                print(f"âœ… å»¶é²åµæ¸¬åˆ°æ–°è¦–çª—: {reading_page.url}")
                            else:
                                print("âš ï¸  ä»æœªåµæ¸¬åˆ°é–±è®€è¦–çª—ï¼Œä½¿ç”¨ç•¶å‰é é¢")
                                reading_page = page
                    
                    print("\n" + "="*60)
                    print("âœ… å€Ÿé–±æˆåŠŸï¼")
                    print("="*60)
                    
                    # å¦‚æœå•Ÿç”¨çˆ¬èŸ²ï¼Œè¿”å›é–±è®€é é¢ç”¨æ–¼å¾ŒçºŒçˆ¬å–
                    if self.enable_scraping:
                        if reading_page:
                            print(f"ğŸ“– å°‡ä½¿ç”¨é é¢é€²è¡Œçˆ¬å–: {reading_page.url}")
                            return reading_page
                        else:
                            print("âŒ ç„¡æ³•ç²å–é–±è®€é é¢")
                            return False
                    else:
                        return True
                else:
                    print("âš ï¸  ç›®å‰æ²’æœ‰å¯å€Ÿé–±çš„å‰¯æœ¬")
                    return False
            else:
                print("âš ï¸  ç„¡æ³•è§£æå¯å€Ÿé–±æ•¸é‡")
                # å˜—è©¦ç›´æ¥é»æ“Šçœ‹çœ‹
                print("ğŸ” å˜—è©¦ç›´æ¥é»æ“ŠæŒ‰éˆ•...")
                await read_button.click()
                await asyncio.sleep(3)
                return True
                
        except Exception as e:
            print(f"âŒ æª¢æŸ¥æˆ–å€Ÿé–±æ›¸ç±æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    async def click_accept_button(self, page: Page) -> bool:
        """
        é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦æˆåŠŸé»æ“Š
        """
        try:
            print("\nğŸ” å°‹æ‰¾ã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•...")
            
            # ç­‰å¾…æŒ‰éˆ•å‡ºç¾
            accept_button = page.locator('button:has-text("æˆ‘çŸ¥é“äº†")')
            
            # ç­‰å¾…æœ€å¤š 10 ç§’
            await accept_button.wait_for(state="visible", timeout=10000)
            
            print("ğŸ–±ï¸  é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•...")
            await accept_button.click()
            await asyncio.sleep(2)
            
            print("âœ… å·²é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•")
            return True
            
        except Exception as e:
            print(f"âš ï¸  æœªæ‰¾åˆ°æˆ–ç„¡æ³•é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•: {e}")
            return False
    
    async def get_all_visible_iframes(self, page: Page) -> list:
        """
        ç²å–æ‰€æœ‰å¯è¦‹çš„ iframe
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ‰€æœ‰å¯è¦‹ iframe çš„ FrameLocator åˆ—è¡¨
        """
        try:
            visible_iframes = []
            
            # ç›´æ¥æ‰¾åˆ°æ‰€æœ‰ iframe å…ƒç´ 
            iframes = page.locator('iframe')
            iframe_count = await iframes.count()
            
            print(f"   ğŸ” æ‰¾åˆ° {iframe_count} å€‹ iframe")
            
            # éæ­·æ‰€æœ‰ iframe
            for i in range(iframe_count):
                iframe_element = iframes.nth(i)
                
                # æª¢æŸ¥ iframe æ˜¯å¦å¯è¦‹
                is_visible = await iframe_element.is_visible()
                
                if is_visible:
                    frame_locator = page.frame_locator('iframe').nth(i)
                    visible_iframes.append(frame_locator)
                    print(f"      âœ“ iframe[{i}] å¯è¦‹")
                else:
                    print(f"      âœ— iframe[{i}] ä¸å¯è¦‹")
            
            if not visible_iframes:
                print("   âš ï¸  æ²’æœ‰æ‰¾åˆ°å¯è¦‹çš„ iframeï¼Œä½¿ç”¨ç¬¬ä¸€å€‹")
                visible_iframes.append(page.frame_locator('iframe').first)
            
            return visible_iframes
            
        except Exception as e:
            print(f"   âš ï¸  ç²å– iframe æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # é™ç´šæ–¹æ¡ˆï¼šè¿”å›ç¬¬ä¸€å€‹ iframe
            return [page.frame_locator('iframe').first]
    
    async def get_current_iframe(self, page: Page) -> FrameLocator:
        """
        ç²å–ç•¶å‰é¡¯ç¤ºçš„ iframeï¼ˆå‘å¾Œå…¼å®¹çš„æ–¹æ³•ï¼‰
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            ç•¶å‰çš„ iframe locator
        """
        visible_iframes = await self.get_all_visible_iframes(page)
        return visible_iframes[0] if visible_iframes else page.frame_locator('iframe').first
    
    async def extract_html_with_formatting(self, element) -> str:
        """
        æå–å…ƒç´ çš„ HTML ä¸¦ä¿ç•™æ ¼å¼æ¨™ç±¤
        
        Args:
            element: Playwright å…ƒç´ 
            
        Returns:
            åŒ…å«æ ¼å¼çš„æ–‡å­—
        """
        try:
            # ç²å–å…ƒç´ çš„ innerHTML
            html = await element.inner_html()
            
            # è½‰æ› HTML æ ¼å¼ç‚º Markdown æ ¼å¼
            # ç²—é«”ï¼š<strong>, <b> -> **text**
            html = re.sub(r'<strong>(.*?)</strong>', r'**\1**', html)
            html = re.sub(r'<b>(.*?)</b>', r'**\1**', html)
            
            # æ–œé«”ï¼š<em>, <i> -> *text*
            html = re.sub(r'<em>(.*?)</em>', r'*\1*', html)
            html = re.sub(r'<i>(.*?)</i>', r'*\1*', html)
            
            # ç§»é™¤å…¶ä»– HTML æ¨™ç±¤ä½†ä¿ç•™å…§å®¹
            html = re.sub(r'<span[^>]*>(.*?)</span>', r'\1', html)
            html = re.sub(r'<div[^>]*>(.*?)</div>', r'\1', html)
            html = re.sub(r'<br\s*/?>', '\n', html)
            
            # ç§»é™¤æ‰€æœ‰å‰©é¤˜çš„ HTML æ¨™ç±¤
            html = re.sub(r'<[^>]+>', '', html)
            
            return html.strip()
            
        except Exception as e:
            # å¦‚æœå‡ºéŒ¯ï¼Œè¿”å›ç´”æ–‡å­—
            return await element.text_content()
    
    async def get_base_url_from_iframe(self, page: Page) -> str:
        """
        å¾ iframe ç²å– base URL
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            base URL æˆ–ç©ºå­—ä¸²
        """
        try:
            iframe = await self.get_current_iframe(page)
            base_element = iframe.locator('base').first
            base_href = await base_element.get_attribute('href')
            return base_href or ''
        except:
            return ''
    
    async def scrape_page_content(self, page: Page) -> Dict[str, any]:
        """
        æŠ“å–ç•¶å‰é é¢çš„å…§å®¹ï¼ˆå¾æ‰€æœ‰å¯è¦‹çš„ iframeï¼‰
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            åŒ…å«æ¨™é¡Œã€æ®µè½å’Œåœ–ç‰‡çš„å­—å…¸
        """
        try:
            # ç²å–æ‰€æœ‰å¯è¦‹çš„ iframe
            visible_iframes = await self.get_all_visible_iframes(page)
            
            content = {
                'headings': [],
                'paragraphs': [],
                'images': []
            }
            
            # å¾æ‰€æœ‰å¯è¦‹çš„ iframe ä¸­æŠ“å–å…§å®¹
            for iframe_index, iframe in enumerate(visible_iframes):
                print(f"      ğŸ“„ æ­£åœ¨æŠ“å– iframe[{iframe_index}] çš„å…§å®¹...")
                iframe_content = await self._scrape_from_single_iframe(iframe)
                
                # åˆä½µå…§å®¹
                content['headings'].extend(iframe_content['headings'])
                content['paragraphs'].extend(iframe_content['paragraphs'])
                content['images'].extend(iframe_content['images'])
                
                print(f"         æ‰¾åˆ°: æ¨™é¡Œ={len(iframe_content['headings'])}, æ®µè½={len(iframe_content['paragraphs'])}, åœ–ç‰‡={len(iframe_content['images'])}")
            
            return content
            
        except Exception as e:
            print(f"âš ï¸  æŠ“å–é é¢å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'headings': [], 'paragraphs': [], 'images': []}
    
    async def _extract_figure_content(self, figure_element) -> dict:
        """
        å¾ figure å…ƒç´ ä¸­æå–åœ–ç‰‡å’Œèªªæ˜æ–‡å­—
        
        Args:
            figure_element: figure å…ƒç´ 
            
        Returns:
            åŒ…å« caption å’Œ image_src çš„å­—å…¸
        """
        try:
            caption_parts = []
            image_src = None
            
            # æå– figcaption
            figcaption = figure_element.locator('figcaption')
            if await figcaption.count() > 0:
                figcaption_text = await self.extract_html_with_formatting(figcaption.first)
                if figcaption_text.strip():
                    caption_parts.append(figcaption_text.strip())
            
            # æå– p.boldï¼ˆåœ–ç‰‡æ¨™é¡Œï¼‰
            bold_p = figure_element.locator('p.bold')
            if await bold_p.count() > 0:
                bold_text = await self.extract_html_with_formatting(bold_p.first)
                if bold_text.strip():
                    caption_parts.append(bold_text.strip())
            
            # æå–åœ–ç‰‡ src
            img = figure_element.locator('img')
            if await img.count() > 0:
                image_src = await img.first.get_attribute('src')
            
            if image_src:
                # åˆä½µæ‰€æœ‰èªªæ˜æ–‡å­—
                full_caption = ' - '.join(caption_parts) if caption_parts else 'åœ–ç‰‡'
                
                return {
                    'caption': full_caption,
                    'image_src': image_src,
                    'image_alt': full_caption
                }
            
            return None
            
        except Exception as e:
            print(f"         âš ï¸  æå– figure å…§å®¹å¤±æ•—: {e}")
            return None
    
    async def extract_chapter_name(self, iframe: FrameLocator) -> str:
        """
        å¾ iframe ä¸­æå–ç« ç¯€åç¨±
        
        Args:
            iframe: iframe locator
            
        Returns:
            ç« ç¯€åç¨±ï¼ˆå¦‚æœæ²’æœ‰å‰‡è¿”å›ç©ºå­—ä¸²ï¼‰
        """
        try:
            # æ‰¾åˆ° h1 æ¨™ç±¤
            h1_elements = iframe.locator('h1')
            h1_count = await h1_elements.count()
            
            for i in range(h1_count):
                h1 = h1_elements.nth(i)
                # åœ¨ h1 ä¸­æ‰¾ span.num2
                span_num2 = h1.locator('span.num2')
                if await span_num2.count() > 0:
                    # ç²å–æ•´å€‹ h1 çš„æ–‡å­—ä½œç‚ºç« ç¯€å
                    chapter_name = await self.extract_html_with_formatting(h1)
                    return chapter_name.strip()
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦åªæ‰¾ç¬¬ä¸€å€‹ h1
            if h1_count > 0:
                first_h1 = await self.extract_html_with_formatting(h1_elements.first)
                return first_h1.strip()
            
            return ""
            
        except Exception as e:
            print(f"         âš ï¸  æå–ç« ç¯€åç¨±å¤±æ•—: {e}")
            return ""
    
    async def scrape_chapter_from_iframe(self, iframe: FrameLocator, base_url: str = None) -> Dict[str, any]:
        """
        å¾å–®å€‹ iframe æŠ“å–å®Œæ•´ç« ç¯€å…§å®¹ï¼ˆä¿æŒå…ƒç´ é †åºï¼‰
        
        Args:
            iframe: iframe locator
            base_url: åŸºç¤ URLï¼ˆç”¨æ–¼è§£æåœ–ç‰‡ç›¸å°è·¯å¾‘ï¼‰
            
        Returns:
            ç« ç¯€è³‡æ–™å­—å…¸ï¼ŒåŒ…å«ç« ç¯€åå’Œæœ‰åºå…§å®¹åˆ—è¡¨
        """
        try:
            # æå–ç« ç¯€åç¨±
            chapter_name = await self.extract_chapter_name(iframe)
            
            if not chapter_name:
                # å¦‚æœæ²’æœ‰ç« ç¯€åï¼Œä½¿ç”¨ç‰¹æ®Šæ¨™è¨˜ï¼ˆå¯èƒ½æ˜¯å°é¢æˆ–å‰è¨€ï¼‰
                chapter_name = "__no_chapter__"
            
            # æŒ‰é †åºæŠ“å–æ‰€æœ‰å…§å®¹å…ƒç´ ï¼ˆä¿æŒ DOM é †åºï¼‰
            content_items = []
            
            # æŠ“å– body å…§çš„æ‰€æœ‰å…ƒç´ 
            body = iframe.locator('body')
            
            # ä¸€æ¬¡æ€§æŠ“å–æ‰€æœ‰å…§å®¹å…ƒç´ ï¼ˆh1, h2, h3, h4, h5, h6, p, figureï¼‰ä¸¦ä¿æŒé †åº
            # ä½¿ç”¨ CSS é¸æ“‡å™¨ä¾†é¸æ“‡å¤šå€‹å…ƒç´ ä¸¦ä¿æŒé †åº
            all_elements = body.locator('h1, h2, h3, h4, h5, h6, p, figure')
            element_count = await all_elements.count()
            
            for i in range(element_count):
                element = all_elements.nth(i)
                
                # ç²å–å…ƒç´ çš„æ¨™ç±¤å
                tag_name = await element.evaluate('el => el.tagName.toLowerCase()')
                
                if tag_name == 'figure':
                    # è™•ç† figure å…ƒç´ ï¼ˆåœ–ç‰‡ + èªªæ˜æ–‡å­—ï¼‰
                    figure_data = await self._extract_figure_content(element)
                    if figure_data:
                        # å°‡ figure ä½œç‚ºç‰¹æ®Šçš„å…§å®¹é …ç›®
                        content_items.append({
                            'type': 'figure',
                            'content': figure_data['caption'],
                            'image_src': figure_data['image_src'],
                            'image_alt': figure_data['image_alt']
                        })
                else:
                    # ç²å–å…ƒç´ çš„æ–‡å­—å…§å®¹ï¼ˆä¿ç•™æ ¼å¼ï¼‰
                    text_content = await self.extract_html_with_formatting(element)
                    
                    if text_content.strip():
                        content_items.append({
                            'type': tag_name,
                            'content': text_content.strip()
                        })
            
            # æŠ“å–ä¸åœ¨ figure å…§çš„ç¨ç«‹åœ–ç‰‡
            images = []
            
            # ä¸€èˆ¬åœ–ç‰‡ï¼ˆæ’é™¤ figure å…§çš„ï¼‰
            img_elements = body.locator('img:not(figure img)')
            img_count = await img_elements.count()
            
            for i in range(img_count):
                img = img_elements.nth(i)
                src = await img.get_attribute('src')
                alt = await img.get_attribute('alt') or 'åœ–ç‰‡'
                
                if src:
                    images.append({
                        'src': src,
                        'alt': alt
                    })
            
            # SVG åœ–ç‰‡ï¼ˆæ’é™¤ figure å…§çš„ï¼‰
            svg_images = body.locator('svg:not(figure svg) image')
            svg_count = await svg_images.count()
            
            for i in range(svg_count):
                svg_img = svg_images.nth(i)
                
                # å„ªå…ˆå˜—è©¦ xlink:href
                src = await svg_img.get_attribute('xlink:href')
                if not src:
                    src = await svg_img.get_attribute('href')
                
                if src:
                    images.append({
                        'src': src,
                        'alt': 'SVG åœ–ç‰‡'
                    })
            
            # æŠ“å–è¨»é‡‹
            footnotes = []
            footnote_elements = body.locator('div.footnote[role="doc-endnote"]')
            footnote_count = await footnote_elements.count()
            
            if footnote_count > 0:
                for i in range(footnote_count):
                    footnote = footnote_elements.nth(i)
                    footnote_ps = footnote.locator('p')
                    p_count = await footnote_ps.count()
                    
                    for j in range(p_count):
                        p_text = await self.extract_html_with_formatting(footnote_ps.nth(j))
                        if p_text.strip():
                            footnotes.append(p_text.strip())
            
            # æ”¶é›† figure ä¸­çš„åœ–ç‰‡
            figure_images = []
            for item in content_items:
                if item['type'] == 'figure' and 'image_src' in item:
                    figure_images.append({
                        'src': item['image_src'],
                        'alt': item['image_alt']
                    })
            
            return {
                'name': chapter_name,
                'content_items': content_items,
                'images': images,
                'figure_images': figure_images,  # figure ä¸­çš„åœ–ç‰‡
                'footnotes': footnotes
            }
            
        except Exception as e:
            print(f"         âš ï¸  å¾ iframe æŠ“å–ç« ç¯€æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    async def _scrape_from_single_iframe(self, iframe: FrameLocator) -> Dict[str, any]:
        """
        å¾å–®å€‹ iframe æŠ“å–å…§å®¹ï¼ˆèˆŠç‰ˆæœ¬ï¼Œä¿ç•™å‘å¾Œå…¼å®¹ï¼‰
        
        Args:
            iframe: iframe locator
            
        Returns:
            åŒ…å«æ¨™é¡Œã€æ®µè½å’Œåœ–ç‰‡çš„å­—å…¸
        """
        content = {
            'headings': [],
            'paragraphs': [],
            'images': []
        }
        
        try:
            
            # æŠ“å–æ¨™é¡Œ (h1, h2, h3, h4, h5, h6)
            for tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
                elements = iframe.locator(tag)
                count = await elements.count()
                
                for i in range(count):
                    # ä½¿ç”¨æ–°æ–¹æ³•æå–åŒ…å«æ ¼å¼çš„æ–‡å­—
                    text = await self.extract_html_with_formatting(elements.nth(i))
                    if text and text.strip():
                        content['headings'].append({
                            'level': tag,
                            'text': text.strip()
                        })
            
            # æŠ“å–æ®µè½ï¼ˆåŒ…å«ä¸€èˆ¬æ®µè½å’Œè…³è¨»ï¼‰
            paragraphs = iframe.locator('p')
            p_count = await paragraphs.count()
            
            for i in range(p_count):
                # ä½¿ç”¨æ–°æ–¹æ³•æå–åŒ…å«æ ¼å¼çš„æ–‡å­—
                text = await self.extract_html_with_formatting(paragraphs.nth(i))
                if text and text.strip():
                    content['paragraphs'].append(text.strip())
            
            # é¡å¤–æŠ“å– footnoteï¼ˆè…³è¨»ï¼‰
            footnotes = iframe.locator('.footnote[role="doc-endnote"]')
            footnote_count = await footnotes.count()
            
            if footnote_count > 0:
                content['paragraphs'].append('\n---\n\n**è¨»é‡‹ï¼š**\n')
                
                for i in range(footnote_count):
                    footnote = footnotes.nth(i)
                    # ç²å– footnote å…§çš„æ‰€æœ‰æ®µè½
                    fn_paragraphs = footnote.locator('p')
                    fn_p_count = await fn_paragraphs.count()
                    
                    for j in range(fn_p_count):
                        text = await self.extract_html_with_formatting(fn_paragraphs.nth(j))
                        if text and text.strip():
                            content['paragraphs'].append(text.strip())
            
            # æŠ“å–åœ–ç‰‡ (HTML img æ¨™ç±¤)
            images = iframe.locator('img')
            img_count = await images.count()
            
            for i in range(img_count):
                src = await images.nth(i).get_attribute('src')
                alt = await images.nth(i).get_attribute('alt')
                if src:
                    content['images'].append({
                        'src': src,
                        'alt': alt or ''
                    })
            
            # æŠ“å–åœ–ç‰‡ (SVG image æ¨™ç±¤)
            svg_images = iframe.locator('image')
            svg_img_count = await svg_images.count()
            
            for i in range(svg_img_count):
                # SVG ä½¿ç”¨ xlink:href æˆ– href å±¬æ€§
                src = await svg_images.nth(i).get_attribute('xlink:href')
                if not src:
                    src = await svg_images.nth(i).get_attribute('href')
                
                if src:
                    # è™•ç†ç›¸å°è·¯å¾‘ï¼Œè½‰æ›ç‚ºçµ•å° URL
                    # ç²å– iframe çš„ base URL
                    try:
                        # å˜—è©¦å¾ iframe ç²å–å®Œæ•´ URL
                        base_element = iframe.locator('base').first
                        base_href = await base_element.get_attribute('href')
                        
                        if base_href and src.startswith('../'):
                            # è™•ç†ç›¸å°è·¯å¾‘
                            # ../Images/cover.jpg -> å¾ base_href è¨ˆç®—å®Œæ•´è·¯å¾‘
                            full_url = urljoin(base_href, src)
                            src = full_url
                    except:
                        # å¦‚æœå¤±æ•—ï¼Œä¿æŒåŸæ¨£
                        pass
                    
                    content['images'].append({
                        'src': src,
                        'alt': 'SVG åœ–ç‰‡'
                    })
            
            return content
            
        except Exception as e:
            print(f"         âš ï¸  å¾ iframe æŠ“å–å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {'headings': [], 'paragraphs': [], 'images': []}
    
    async def download_image(self, url: str, page_number: int, base_url: str = None) -> str:
        """
        ä¸‹è¼‰åœ–ç‰‡åˆ°æœ¬åœ°
        
        Args:
            url: åœ–ç‰‡ URLï¼ˆå¯èƒ½æ˜¯ç›¸å°è·¯å¾‘ï¼‰
            page_number: é ç¢¼
            base_url: åŸºç¤ URLï¼ˆç”¨æ–¼è§£æç›¸å°è·¯å¾‘ï¼‰
            
        Returns:
            æœ¬åœ°åœ–ç‰‡è·¯å¾‘ï¼ˆç›¸å°æ–¼ Markdown æª”æ¡ˆï¼‰
        """
        # æª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
        if url in self.downloaded_images:
            return self.downloaded_images[url]
        
        try:
            # è™•ç†ç›¸å°è·¯å¾‘
            download_url = url
            if not url.startswith(('http://', 'https://')):
                if base_url:
                    # ä½¿ç”¨ urljoin è½‰æ›ç›¸å°è·¯å¾‘ç‚ºçµ•å°è·¯å¾‘
                    download_url = urljoin(base_url, url)
                    print(f"      ğŸ”— è½‰æ› URL: {url} -> {download_url}")
                else:
                    print(f"      âš ï¸  ç„¡æ³•ä¸‹è¼‰ç›¸å°è·¯å¾‘åœ–ç‰‡ï¼ˆç¼ºå°‘ base_urlï¼‰: {url}")
                    return url
            
            # ç”Ÿæˆæª”æ¡ˆåç¨±ï¼ˆä½¿ç”¨ URL hash + é ç¢¼ï¼‰
            url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
            ext = Path(url).suffix or '.jpg'
            filename = f"page_{page_number:04d}_{url_hash}{ext}"
            
            local_path = self.images_dir / filename
            
            # ä¸‹è¼‰åœ–ç‰‡
            async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
                response = await client.get(download_url)
                response.raise_for_status()
                
                # ä¿å­˜åœ–ç‰‡
                with open(local_path, 'wb') as f:
                    f.write(response.content)
            
            # è¨˜éŒ„ä¸‹è¼‰ï¼ˆç›¸å°æ–¼ downloads ç›®éŒ„çš„è·¯å¾‘ï¼‰
            relative_path = f"images/book_{self.book_id}/{filename}"
            self.downloaded_images[url] = relative_path
            
            print(f"      ğŸ“¥ å·²ä¸‹è¼‰åœ–ç‰‡: {filename}")
            return relative_path
            
        except Exception as e:
            print(f"      âš ï¸  ä¸‹è¼‰åœ–ç‰‡å¤±æ•— ({url}): {e}")
            # ä¸‹è¼‰å¤±æ•—æ™‚è¿”å›åŸ URL
            return url
    
    def extract_chapter_number(self, chapter_name: str) -> tuple:
        """
        å¾ç« ç¯€åç¨±ä¸­æå–ç« ç¯€ç·¨è™Ÿ
        
        Args:
            chapter_name: ç« ç¯€åç¨±
            
        Returns:
            (ç« ç¯€é¡å‹, ç« ç¯€ç·¨è™Ÿ) 
            - ç« ç¯€é¡å‹: 'front' (å‰ç½®), 'main' (æ­£æ–‡), 'back' (å¾Œç½®)
            - ç« ç¯€ç·¨è™Ÿ: æ•¸å­—æˆ– None
        """
        import re
        
        # å‰ç½®å…§å®¹çš„é—œéµå­—åŠå…¶å„ªå…ˆé †åº
        front_keywords = {
            '__no_chapter__': 0,  # å°é¢
            'å°é¢': 0,
            'cover': 0,
            'æ¨è–¦åº': 1,
            'æ¨è–¦': 1,
            'recommendation': 1,
            'åº': 2,
            'preface': 2,
            'å‰è¨€': 3,
            'foreword': 3,
            'introduction': 3,
            'å°è®€': 4,
            'ç›®éŒ„': 5,
            'contents': 5,
            'table of contents': 5,
            'ç›®æ¬¡': 5,
        }
        
        # å¾Œç½®å…§å®¹çš„é—œéµå­—
        back_keywords = [
            'é™„éŒ„', 'appendix', 'åƒè€ƒæ–‡ç»', 'references', 
            'ç‰ˆæ¬Š', 'copyright', 'è‡´è¬', 'acknowledgment',
            'ä½œè€…', 'author', 'é—œæ–¼ä½œè€…', 'about the author',
            'å¾Œè¨˜', 'epilogue', 'afterword'
        ]
        
        chapter_lower = chapter_name.lower().strip()
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå‰ç½®å…§å®¹
        for keyword, priority in front_keywords.items():
            if keyword in chapter_lower:
                return ('front', priority)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå¾Œç½®å…§å®¹
        for keyword in back_keywords:
            if keyword in chapter_lower:
                return ('back', 0)
        
        # å˜—è©¦æå–ç« ç¯€ç·¨è™Ÿï¼ˆæ­£æ–‡ï¼‰
        # æ¨¡å¼ 1: Chapter 1, Chapter 2, CHAPTER 1, etc.
        match = re.search(r'chapter\s+(\d+)', chapter_lower)
        if match:
            return ('main', int(match.group(1)))
        
        # æ¨¡å¼ 2: ç¬¬ä¸€ç« , ç¬¬äºŒç« , ç¬¬1ç« , ç¬¬2ç« 
        match = re.search(r'ç¬¬\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾\d]+)\s*ç« ', chapter_name)
        if match:
            num_str = match.group(1)
            # è½‰æ›ä¸­æ–‡æ•¸å­—ç‚ºé˜¿æ‹‰ä¼¯æ•¸å­—
            chinese_nums = {'ä¸€': 1, 'äºŒ': 2, 'ä¸‰': 3, 'å››': 4, 'äº”': 5, 
                          'å…­': 6, 'ä¸ƒ': 7, 'å…«': 8, 'ä¹': 9, 'å': 10,
                          'åä¸€': 11, 'åäºŒ': 12, 'åä¸‰': 13, 'åå››': 14, 'åäº”': 15,
                          'åå…­': 16, 'åä¸ƒ': 17, 'åå…«': 18, 'åä¹': 19, 'äºŒå': 20}
            if num_str in chinese_nums:
                return ('main', chinese_nums[num_str])
            elif num_str.isdigit():
                return ('main', int(num_str))
        
        # æ¨¡å¼ 3: 1. æ¨™é¡Œ, 2. æ¨™é¡Œ
        match = re.search(r'^(\d+)[\.ã€]\s*', chapter_name)
        if match:
            return ('main', int(match.group(1)))
        
        # æ¨¡å¼ 4: Chapter I, Chapter II (ç¾…é¦¬æ•¸å­—)
        match = re.search(r'chapter\s+([ivxlcdm]+)', chapter_lower)
        if match:
            roman = match.group(1).upper()
            # ç°¡å–®çš„ç¾…é¦¬æ•¸å­—è½‰æ›
            roman_values = {'I': 1, 'II': 2, 'III': 3, 'IV': 4, 'V': 5,
                          'VI': 6, 'VII': 7, 'VIII': 8, 'IX': 9, 'X': 10}
            if roman in roman_values:
                return ('main', roman_values[roman])
        
        # å¦‚æœç„¡æ³•è­˜åˆ¥ï¼Œè¦–ç‚ºå‰ç½®å…§å®¹ï¼Œæ”¾åœ¨æœ€å¾Œ
        return ('front', 999)
    
    def sort_chapters(self, chapter_order: list) -> list:
        """
        å°ç« ç¯€é€²è¡Œæ™ºèƒ½æ’åº
        
        Args:
            chapter_order: åŸå§‹ç« ç¯€é †åºåˆ—è¡¨
            
        Returns:
            æ’åºå¾Œçš„ç« ç¯€åˆ—è¡¨
        """
        # ç‚ºæ¯å€‹ç« ç¯€æå–æ’åºè³‡è¨Š
        chapter_info = []
        for chapter_name in chapter_order:
            chapter_type, chapter_num = self.extract_chapter_number(chapter_name)
            chapter_info.append((chapter_name, chapter_type, chapter_num))
        
        # æ’åºè¦å‰‡ï¼š
        # 1. å…ˆæŒ‰é¡å‹æ’åºï¼šfront < main < back
        # 2. åŒé¡å‹å…§æŒ‰ç·¨è™Ÿæ’åº
        type_order = {'front': 0, 'main': 1, 'back': 2}
        
        def sort_key(item):
            name, ch_type, ch_num = item
            type_priority = type_order[ch_type]
            num_priority = ch_num if ch_num is not None else 999
            return (type_priority, num_priority)
        
        sorted_info = sorted(chapter_info, key=sort_key)
        
        # è¿”å›æ’åºå¾Œçš„ç« ç¯€åç¨±åˆ—è¡¨
        return [name for name, _, _ in sorted_info]
    
    async def download_images_for_chapter(self, chapter_data: Dict[str, any], page_number: int, base_url: str = None):
        """
        ç‚ºç« ç¯€ä¸‹è¼‰æ‰€æœ‰åœ–ç‰‡ï¼ˆåŒ…å« figure ä¸­çš„åœ–ç‰‡ï¼‰
        
        Args:
            chapter_data: ç« ç¯€è³‡æ–™å­—å…¸
            page_number: é ç¢¼ï¼ˆç”¨æ–¼ç”Ÿæˆæª”æ¡ˆåï¼‰
            base_url: åŸºç¤ URL
        """
        # ä¸‹è¼‰ç¨ç«‹åœ–ç‰‡
        for image in chapter_data['images']:
            url = image['src']
            local_path = await self.download_image(url, page_number, base_url)
            image['local_path'] = local_path
        
        # ä¸‹è¼‰ figure ä¸­çš„åœ–ç‰‡
        for image in chapter_data.get('figure_images', []):
            url = image['src']
            local_path = await self.download_image(url, page_number, base_url)
            image['local_path'] = local_path
    
    async def convert_chapter_to_markdown(self, chapter_data: Dict[str, any]) -> str:
        """
        å°‡ç« ç¯€è³‡æ–™è½‰æ›ç‚º Markdown æ ¼å¼
        
        Args:
            chapter_data: ç« ç¯€è³‡æ–™å­—å…¸
            
        Returns:
            Markdown æ ¼å¼çš„æ–‡å­—
        """
        markdown_lines = []
        
        # è™•ç†æœ‰åºå…§å®¹ï¼ˆåŒ…å« figureï¼‰
        for item in chapter_data['content_items']:
            item_type = item['type']
            content = item['content']
            
            if item_type == 'h1':
                markdown_lines.append(f"\n## {content}\n")
            elif item_type == 'h2':
                markdown_lines.append(f"\n### {content}\n")
            elif item_type == 'h3':
                markdown_lines.append(f"\n#### {content}\n")
            elif item_type == 'h4':
                markdown_lines.append(f"\n##### {content}\n")
            elif item_type == 'h5':
                markdown_lines.append(f"\n###### {content}\n")
            elif item_type == 'h6':
                markdown_lines.append(f"\n###### {content}\n")
            elif item_type == 'p':
                markdown_lines.append(f"{content}\n")
            elif item_type == 'figure':
                # è™•ç† figureï¼ˆåœ–ç‰‡ + èªªæ˜ï¼‰
                img_src = item.get('image_src', '')
                img_alt = item.get('image_alt', 'åœ–ç‰‡')
                
                # ä½¿ç”¨æœ¬åœ°è·¯å¾‘ï¼ˆå¦‚æœå·²ä¸‹è¼‰ï¼‰
                # æ³¨æ„ï¼šé€™è£¡éœ€è¦å¾ images åˆ—è¡¨ä¸­æŸ¥æ‰¾å°æ‡‰çš„æœ¬åœ°è·¯å¾‘
                img_path = img_src
                for img in chapter_data.get('figure_images', []):
                    if img['src'] == img_src:
                        img_path = img.get('local_path', img_src)
                        break
                
                markdown_lines.append(f"\n![{img_alt}]({img_path})\n\n")
        
        # è™•ç†ç¨ç«‹åœ–ç‰‡ï¼ˆä¸åœ¨ figure å…§çš„ï¼‰
        if chapter_data['images']:
            markdown_lines.append("\n")
            for image in chapter_data['images']:
                # å„ªå…ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘
                img_path = image.get('local_path', image['src'])
                alt_text = image.get('alt', 'åœ–ç‰‡')
                markdown_lines.append(f"![{alt_text}]({img_path})\n")
        
        # è™•ç†è¨»é‡‹
        if chapter_data['footnotes']:
            markdown_lines.append("\n---\n\n**è¨»é‡‹ï¼š**\n\n")
            for footnote in chapter_data['footnotes']:
                markdown_lines.append(f"{footnote}\n\n")
        
        return ''.join(markdown_lines)
    
    def convert_to_markdown(self, content: Dict[str, any], page_number: int = 0) -> str:
        """
        å°‡å…§å®¹è½‰æ›ç‚º Markdown æ ¼å¼
        
        Args:
            content: åŒ…å«æ¨™é¡Œã€æ®µè½å’Œåœ–ç‰‡çš„å­—å…¸
            page_number: é ç¢¼ï¼ˆç”¨æ–¼åœ–ç‰‡è·¯å¾‘ï¼‰
            
        Returns:
            Markdown æ ¼å¼çš„æ–‡å­—
        """
        markdown = []
        
        # è½‰æ›æ¨™é¡Œï¼ˆh1 -> ##, h2 -> ###, h3 -> ####, ä»¥æ­¤é¡æ¨ï¼‰
        for heading in content['headings']:
            level = int(heading['level'][1])  # h1 -> 1, h2 -> 2, h3 -> 3
            # h1 å°æ‡‰åˆ° ##ï¼ˆ2å€‹#ï¼‰ï¼Œh2 å°æ‡‰åˆ° ###ï¼ˆ3å€‹#ï¼‰
            prefix = '#' * (level + 1)
            markdown.append(f"{prefix} {heading['text']}\n")
        
        # è½‰æ›æ®µè½ï¼ˆå·²åŒ…å«ç²—é«”å’Œæ–œé«”ï¼‰
        for paragraph in content['paragraphs']:
            markdown.append(f"{paragraph}\n")
        
        # è½‰æ›åœ–ç‰‡ï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘æˆ– URLï¼‰
        for image in content['images']:
            alt_text = image['alt'] or 'åœ–ç‰‡'
            img_path = image.get('local_path', image['src'])  # å„ªå…ˆä½¿ç”¨æœ¬åœ°è·¯å¾‘
            markdown.append(f"![{alt_text}]({img_path})\n")
        
        return '\n'.join(markdown)
    
    async def get_reading_progress(self, page: Page) -> dict:
        """
        ç²å–é–±è®€é€²åº¦ä¿¡æ¯
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            åŒ…å«é€²åº¦ä¿¡æ¯çš„å­—å…¸ {'total_percent': 100, 'chapter_current': 4, 'chapter_total': 4}
        """
        try:
            # å®šä½é€²åº¦å®¹å™¨
            progress_container = page.locator('#page-info-container')
            
            # ç­‰å¾…å…ƒç´ å‡ºç¾
            await progress_container.wait_for(state="visible", timeout=5000)
            
            # ç²å–æ–‡å­—å…§å®¹
            progress_text = await progress_container.text_content()
            
            # è§£æé€²åº¦æ–‡å­—
            # æ ¼å¼ï¼šå…¨æ–‡ 10%ï¼æœ¬ç« ç¬¬ 1 é  / 4 é 
            progress_info = {
                'total_percent': 0,
                'chapter_current': 0,
                'chapter_total': 0,
                'text': progress_text.strip()
            }
            
            # æå–å…¨æ–‡ç™¾åˆ†æ¯”
            total_match = re.search(r'å…¨æ–‡\s*(\d+)%', progress_text)
            if total_match:
                progress_info['total_percent'] = int(total_match.group(1))
            
            # æå–æœ¬ç« é æ•¸
            chapter_match = re.search(r'æœ¬ç« ç¬¬?\s*(\d+)\s*é \s*/\s*(\d+)\s*é ', progress_text)
            if chapter_match:
                progress_info['chapter_current'] = int(chapter_match.group(1))
                progress_info['chapter_total'] = int(chapter_match.group(2))
            
            return progress_info
            
        except Exception as e:
            print(f"      âš ï¸  ç„¡æ³•ç²å–é–±è®€é€²åº¦: {e}")
            return {
                'total_percent': 0,
                'chapter_current': 0,
                'chapter_total': 0,
                'text': ''
            }
    
    async def is_last_page(self, page: Page) -> bool:
        """
        æª¢æŸ¥æ˜¯å¦ç‚ºæœ€å¾Œä¸€é 
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦ç‚ºæœ€å¾Œä¸€é 
        """
        progress = await self.get_reading_progress(page)
        
        # åˆ¤æ–·æ¢ä»¶ï¼šå…¨æ–‡ 100% ä¸”æœ¬ç« åˆ°æœ€å¾Œä¸€é 
        is_last = (
            progress['total_percent'] == 100 and
            progress['chapter_current'] > 0 and
            progress['chapter_current'] == progress['chapter_total']
        )
        
        return is_last
    
    async def turn_page(self, page: Page) -> bool:
        """
        ç¿»åˆ°ä¸‹ä¸€é ï¼ˆæ¨¡æ“¬éµç›¤å³éµï¼‰
        
        Args:
            page: Playwright é é¢ç‰©ä»¶
            
        Returns:
            æ˜¯å¦æˆåŠŸç¿»é 
        """
        try:
            # æŒ‰ä¸‹éµç›¤å³éµ
            await page.keyboard.press('ArrowRight')
            
            # ç­‰å¾…é é¢è¼‰å…¥
            await asyncio.sleep(2)
            
            return True
            
        except Exception as e:
            print(f"âš ï¸  ç¿»é æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    async def download_images_for_content(self, content: Dict[str, any], page_number: int, base_url: str = None):
        """
        ä¸‹è¼‰å…§å®¹ä¸­çš„æ‰€æœ‰åœ–ç‰‡
        
        Args:
            content: åŒ…å«åœ–ç‰‡åˆ—è¡¨çš„å…§å®¹å­—å…¸
            page_number: é ç¢¼
            base_url: åŸºç¤ URLï¼ˆç”¨æ–¼è§£æç›¸å°è·¯å¾‘ï¼‰
        """
        if not self.download_images or not content['images']:
            return
        
        for image in content['images']:
            url = image['src']
            
            # ä¸‹è¼‰åœ–ç‰‡ä¸¦æ›´æ–°ç‚ºæœ¬åœ°è·¯å¾‘
            local_path = await self.download_image(url, page_number, base_url)
            image['local_path'] = local_path

    async def scrape_entire_book(self, reading_page: Page) -> str:
        """
        çˆ¬å–æ•´æœ¬æ›¸çš„å…§å®¹ï¼ˆä»¥ç« ç¯€ç‚ºå–®ä½ï¼‰
        
        Args:
            reading_page: é–±è®€é é¢çš„ Page ç‰©ä»¶
            
        Returns:
            å®Œæ•´çš„ Markdown å…§å®¹
        """
        print("\n" + "=" * 60)
        print("ğŸ“š é–‹å§‹çˆ¬å–æ›¸ç±å…§å®¹ï¼ˆä»¥ç« ç¯€ç‚ºå–®ä½ï¼‰")
        print("=" * 60)

        # å¦‚æœéœ€è¦ä¸‹è¼‰åœ–ç‰‡ï¼Œå»ºç«‹åœ–ç‰‡ç›®éŒ„
        if self.download_images:
            self.images_dir = Path("downloads") / "images" / f"book_{self.book_id}"
            self.images_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ åœ–ç‰‡å°‡ä¿å­˜åˆ°: {self.images_dir}")

        # é»æ“Šã€Œæˆ‘çŸ¥é“äº†ã€æŒ‰éˆ•
        await self.click_accept_button(reading_page)

        # ç­‰å¾…é é¢å®Œå…¨è¼‰å…¥
        await asyncio.sleep(3)

        # å„²å­˜ç« ç¯€ï¼Œkey = ç« ç¯€åï¼Œvalue = ç« ç¯€è³‡æ–™
        chapters = {}
        chapter_order = []  # è¨˜éŒ„ç« ç¯€å‡ºç¾é †åº
        
        page_number = 0
        full_progress_count = 0  # è¨˜éŒ„é€£çºŒå‡ºç¾å…¨æ–‡ 100% çš„æ¬¡æ•¸

        # ç²å– base URLï¼ˆç”¨æ–¼åœ–ç‰‡ä¸‹è¼‰ï¼‰
        base_url = await self.get_base_url_from_iframe(reading_page)
        if base_url:
            print(f"ğŸ“ Base URL: {base_url}")

        while page_number < self.max_pages:
            page_number += 1

            # ç²å–é–±è®€é€²åº¦
            progress = await self.get_reading_progress(reading_page)
            print(f"\nğŸ“– æ­£åœ¨æƒæç¬¬ {page_number} é ... [{progress['text']}] (é€²åº¦: {progress['total_percent']}%)")

            # ç²å–æ‰€æœ‰å¯è¦‹çš„ iframe
            visible_iframes = await self.get_all_visible_iframes(reading_page)
            
            found_new_chapter = False
            
            # å¾æ¯å€‹ iframe æŠ“å–ç« ç¯€
            for iframe_index, iframe in enumerate(visible_iframes):
                print(f"      ğŸ“„ æ­£åœ¨æŠ“å– iframe[{iframe_index}] çš„ç« ç¯€...")
                
                # æŠ“å–ç« ç¯€è³‡æ–™
                chapter_data = await self.scrape_chapter_from_iframe(iframe, base_url)
                
                if not chapter_data:
                    print(f"         âš ï¸  iframe[{iframe_index}] æ²’æœ‰å…§å®¹")
                    continue
                
                chapter_name = chapter_data['name']
                
                # æª¢æŸ¥æ˜¯å¦ç‚ºæ–°ç« ç¯€
                if chapter_name not in chapters:
                    chapters[chapter_name] = chapter_data
                    chapter_order.append(chapter_name)
                    found_new_chapter = True
                    
                    # é¡¯ç¤ºç« ç¯€é è¦½
                    display_name = chapter_name if chapter_name != "__no_chapter__" else "ã€ç„¡ç« ç¯€åç¨±ï¼ˆå¯èƒ½æ˜¯å°é¢æˆ–å‰è¨€ï¼‰ã€‘"
                    print(f"         âœ… æ–°ç« ç¯€: {display_name}")
                    
                    # DEBUG: é¡¯ç¤ºå…§å®¹é è¦½
                    if chapter_data['content_items']:
                        first_item = chapter_data['content_items'][0]
                        last_item = chapter_data['content_items'][-1]
                        print(f"         ğŸ” ç¬¬ä¸€é … ({first_item['type']}): {first_item['content'][:80]}...")
                        print(f"         ğŸ” æœ€å¾Œé … ({last_item['type']}): {last_item['content'][:80]}...")
                    
                    total_images = len(chapter_data['images']) + len(chapter_data.get('figure_images', []))
                    print(f"         ğŸ“Š çµ±è¨ˆ: {len(chapter_data['content_items'])} å€‹å…ƒç´ , {total_images} å¼µåœ–ç‰‡")
                    
                    # ä¸‹è¼‰åœ–ç‰‡ï¼ˆåŒ…æ‹¬ figure ä¸­çš„åœ–ç‰‡ï¼‰
                    if self.download_images and total_images > 0:
                        await self.download_images_for_chapter(chapter_data, page_number, base_url)
                else:
                    print(f"         âš ï¸  é‡è¤‡ç« ç¯€: {chapter_name}")
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ–°ç« ç¯€ï¼Œåªæ˜¯æç¤ºï¼Œä¸ä½œç‚ºçµ‚æ­¢æ¢ä»¶
            if not found_new_chapter:
                print(f"   â„¹ï¸  æœ¬é æ²’æœ‰æ–°ç« ç¯€ï¼ˆå¯èƒ½é‚„åœ¨åŒä¸€ç« ç¯€ä¸­ï¼‰")

            # æª¢æŸ¥æ˜¯å¦ç‚ºæœ€å¾Œä¸€é ï¼ˆä¸»è¦çµ‚æ­¢æ¢ä»¶ï¼‰
            if await self.is_last_page(reading_page):
                print("âœ… å·²åˆ°é”æœ€å¾Œä¸€é ï¼ˆå…¨æ–‡ 100% ä¸”æœ¬ç« æœ€å¾Œä¸€é ï¼‰")
                break
            
            # å®‰å…¨æ©Ÿåˆ¶ï¼šæª¢æ¸¬å…¨æ–‡ 100% çš„æƒ…æ³
            if progress['total_percent'] >= 100:
                full_progress_count += 1
                
                if not found_new_chapter:
                    # å¦‚æœå…¨æ–‡ 100% ä¸”æ²’æœ‰æ–°ç« ç¯€
                    print(f"   âš ï¸  å·²é”å…¨æ–‡ 100% ä¸”ç„¡æ–°ç« ç¯€ï¼ˆç¬¬ {full_progress_count} æ¬¡ï¼‰")
                    
                    if full_progress_count >= 5:
                        # é€£çºŒ 5 æ¬¡ 100% ä¸”ç„¡æ–°ç« ç¯€ï¼Œæå‰çµ‚æ­¢
                        print("   ğŸ›‘ é€£çºŒ 5 æ¬¡åµæ¸¬åˆ°å…¨æ–‡ 100% ä¸”ç„¡æ–°ç« ç¯€ï¼Œåœæ­¢çˆ¬å–")
                        print("   ğŸ’¡ æç¤ºï¼šé€™å¯èƒ½æ˜¯ç¶²ç«™é€²åº¦é¡¯ç¤ºéŒ¯èª¤ï¼ˆä¾‹å¦‚ï¼šå…¨æ–‡ 100%ï¼æœ¬ç« ç¬¬ 1 é  / 2 é ï¼‰")
                        break
                else:
                    # æœ‰æ–°ç« ç¯€ï¼Œèªªæ˜é‚„æ²’çµæŸï¼Œåªæ˜¯é¡¯ç¤º 100%
                    print(f"   â„¹ï¸  å·²é”å…¨æ–‡ 100% ä½†ç™¼ç¾æ–°ç« ç¯€ï¼Œç¹¼çºŒçˆ¬å–...")
                    full_progress_count = 0
                
                if full_progress_count >= 10:
                    # ä¿éšªæ©Ÿåˆ¶ï¼šç„¡è«–å¦‚ä½•ï¼Œé€£çºŒ 10 æ¬¡ 100% å°±åœæ­¢
                    print("   ğŸ›‘ é€£çºŒ 10 æ¬¡åµæ¸¬åˆ°å…¨æ–‡ 100%ï¼Œå¼·åˆ¶åœæ­¢çˆ¬å–")
                    break
            else:
                # é‡ç½®è¨ˆæ•¸å™¨
                full_progress_count = 0

            # æ™ºèƒ½ç¿»é ï¼šæ ¹æ“šæœ¬ç« å‰©é¤˜é æ•¸æ±ºå®šç¿»å¤šå°‘é 
            remaining_pages = progress['chapter_total'] - progress['chapter_current']
            
            if remaining_pages <= 0:
                # ç« ç¯€çµæŸï¼Œç¿» 1 é åˆ°ä¸‹ä¸€ç« 
                pages_to_turn = 1
                print(f"   â­ï¸  ç« ç¯€å·²çµæŸï¼Œç¿» 1 é åˆ°ä¸‹ä¸€ç« ...")
            elif remaining_pages <= 2:
                # æ¥è¿‘ç« ç¯€å°¾éƒ¨ï¼Œç¿» 1 é 
                pages_to_turn = 1
                print(f"   â­ï¸  æœ¬ç« å‰©é¤˜ {remaining_pages} é ï¼Œè¬¹æ…ç¿» 1 é ...")
            elif remaining_pages <= 5:
                # ç« ç¯€ä¸­å¾Œæ®µï¼Œç¿» 2 é 
                pages_to_turn = 2
                print(f"   â­ï¸  æœ¬ç« å‰©é¤˜ {remaining_pages} é ï¼Œç¿» 2 é ...")
            elif remaining_pages > 10:
                # ç« ç¯€å‰æ®µï¼Œç›´æ¥è·³åˆ°å€’æ•¸ç¬¬ 3 é 
                pages_to_turn = remaining_pages - 3
                print(f"   ğŸš€ æœ¬ç« å‰©é¤˜ {remaining_pages} é ï¼Œç›´æ¥è·³åˆ°å€’æ•¸ç¬¬ 3 é ï¼ˆç¿» {pages_to_turn} é ï¼‰...")
            else:
                # ç« ç¯€ä¸­æ®µï¼ˆ6-10é ï¼‰ï¼Œç¿» remaining - 3 æˆ– 3 é 
                pages_to_turn = max(3, remaining_pages - 3)
                print(f"   â­ï¸  æœ¬ç« å‰©é¤˜ {remaining_pages} é ï¼Œç¿» {pages_to_turn} é ...")
            
            for i in range(pages_to_turn):
                if page_number + i >= self.max_pages:
                    break
                
                success = await self.turn_page(reading_page)
                if not success:
                    print(f"   âš ï¸  ç¬¬ {i+1} æ¬¡ç¿»é å¤±æ•—")
                    break
                
                # çŸ­æš«ç­‰å¾…ï¼ˆç¿»é å¤šæ™‚æ¸›å°‘ç­‰å¾…ï¼‰
                if pages_to_turn > 5:
                    await asyncio.sleep(0.3)  # å¿«é€Ÿç¿»é æ™‚ç¸®çŸ­ç­‰å¾…
                else:
                    await asyncio.sleep(0.5)
            
            page_number += (pages_to_turn - 1)  # å¾ªç’°æœƒå† +1

        print("\n" + "=" * 60)
        print(f"âœ… çˆ¬å–å®Œæˆï¼å…±æ‰¾åˆ° {len(chapters)} å€‹ä¸é‡è¤‡çš„ç« ç¯€ (æƒæ {page_number} é )")
        print("=" * 60)

        # å°ç« ç¯€é€²è¡Œæ™ºèƒ½æ’åº
        sorted_chapter_order = self.sort_chapters(chapter_order)
        
        print("\n" + "=" * 60)
        print("ğŸ“– ç« ç¯€æ’åºçµæœï¼š")
        print("=" * 60)

        # æŒ‰ç…§æ’åºå¾Œçš„é †åºè½‰æ›ç« ç¯€ç‚º Markdown
        all_markdown = []
        
        for idx, chapter_name in enumerate(sorted_chapter_order, 1):
            chapter_data = chapters[chapter_name]
            
            display_name = chapter_name if chapter_name != "__no_chapter__" else "å‰è¨€/å°é¢"
            print(f"ğŸ“ ç¬¬ {idx} ç« : {display_name}")
            
            chapter_markdown = await self.convert_chapter_to_markdown(chapter_data)
            all_markdown.append(chapter_markdown)
        
        return '\n\n'.join(all_markdown)
    
    async def run(self, headless: bool = False, slow_mo: int = 100, wait_time: int = 30) -> bool:
        """
        åŸ·è¡Œå®Œæ•´çš„å€Ÿé–±æµç¨‹ï¼ˆåŒ…å«çˆ¬èŸ²ï¼‰
        
        Args:
            headless: æ˜¯å¦ä½¿ç”¨ç„¡é ­æ¨¡å¼ï¼ˆä¸é¡¯ç¤ºç€è¦½å™¨è¦–çª—ï¼‰
            slow_mo: æ¸›æ…¢æ“ä½œé€Ÿåº¦ï¼ˆæ¯«ç§’ï¼‰ï¼Œä¾¿æ–¼è§€å¯Ÿ
            wait_time: æˆåŠŸå¾Œç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰ï¼Œè®“ä½¿ç”¨è€…çœ‹åˆ°çµæœ
            
        Returns:
            åŸ·è¡Œæ˜¯å¦æˆåŠŸ
        """
        async with async_playwright() as p:
            # å•Ÿå‹•ç€è¦½å™¨
            print(f"ğŸŒ æ­£åœ¨å•Ÿå‹•ç€è¦½å™¨ (headless={headless})...")
            browser: Browser = await p.chromium.launch(
                headless=headless,
                slow_mo=slow_mo
            )
            
            try:
                # å»ºç«‹æ–°é é¢
                page: Page = await browser.new_page()
                
                # æ­¥é©Ÿ 1: ç™»å…¥
                login_success = await self.login(page)
                if not login_success:
                    print("\nâŒ ç™»å…¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
                    return False
                
                # æ­¥é©Ÿ 2: æª¢æŸ¥ä¸¦å€Ÿé–±æ›¸ç±
                borrow_result = await self.check_and_borrow_book(page, self.book_id)
                
                if not borrow_result:
                    print("\nâŒ å€Ÿé–±å¤±æ•—")
                    return False
                
                # æ­¥é©Ÿ 3: å¦‚æœå•Ÿç”¨çˆ¬èŸ²ä¸”æˆåŠŸå€Ÿé–±ï¼Œé–‹å§‹çˆ¬å–å…§å®¹
                if self.enable_scraping and isinstance(borrow_result, Page):
                    reading_page = borrow_result
                    
                    # çˆ¬å–æ•´æœ¬æ›¸
                    markdown_content = await self.scrape_entire_book(reading_page)
                    
                    # å„²å­˜ç‚ºæª”æ¡ˆ
                    output_dir = Path("downloads")
                    output_dir.mkdir(exist_ok=True)
                    
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                    
                    # ä½¿ç”¨æ›¸åä½œç‚ºæª”æ¡ˆåï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
                    if self.book_title:
                        # ç§»é™¤æª”æ¡ˆåä¸­ä¸å…è¨±çš„å­—å…ƒ
                        safe_title = re.sub(r'[<>:"/\\|?*]', '_', self.book_title)
                        output_file = output_dir / f"{safe_title}_{timestamp}.md"
                    else:
                        output_file = output_dir / f"book_{self.book_id}_{timestamp}.md"
                    
                    # ç”Ÿæˆ Markdown æ¨™é¡Œ
                    header = f"# {self.book_title if self.book_title else 'æ›¸ç±å…§å®¹'}\n\n"
                    if self.book_title:
                        header += f"- æ›¸å: {self.book_title}\n"
                    header += f"- æ›¸ç± ID: {self.book_id}\n"
                    header += f"- çˆ¬å–æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                    header += "---\n\n"
                    
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(header + markdown_content)
                    
                    print(f"\nğŸ’¾ å·²å„²å­˜è‡³: {output_file}")
                    print(f"ğŸ“Š æª”æ¡ˆå¤§å°: {output_file.stat().st_size / 1024:.2f} KB")
                    
                    # ç­‰å¾…ä¸€æ®µæ™‚é–“è®“ä½¿ç”¨è€…çœ‹åˆ°çµæœ
                    if not headless:
                        print(f"\nâ³ å°‡åœ¨ {wait_time} ç§’å¾Œé—œé–‰ç€è¦½å™¨...")
                        await asyncio.sleep(wait_time)
                    
                    return True
                
                elif not self.enable_scraping:
                    # åªå€Ÿé–±ï¼Œä¸çˆ¬èŸ²
                    if not headless:
                        print(f"\nâ³ å°‡åœ¨ {wait_time} ç§’å¾Œé—œé–‰ç€è¦½å™¨...")
                        await asyncio.sleep(wait_time)
                    return True
                
                return False
                
            except Exception as e:
                print(f"\nâŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
                import traceback
                traceback.print_exc()
                return False
                
            finally:
                # é—œé–‰ç€è¦½å™¨
                await browser.close()
                print("\nğŸ”š ç€è¦½å™¨å·²é—œé–‰")


async def main():
    """ä¸»ç¨‹å¼"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     æ¡ƒåœ’å¸‚ç«‹åœ–æ›¸é¤¨ HyRead é›»å­æ›¸è‡ªå‹•å€Ÿé–±å·¥å…·                â•‘
â•‘                                                              â•‘
â•‘  ä½¿ç”¨ Playwright + Google Gemini API è‡ªå‹•è¾¨è­˜é©—è­‰ç¢¼         â•‘
â•‘  è‡ªå‹•ç™»å…¥ â†’ æª¢æŸ¥å¯å€Ÿæ•¸é‡ â†’ å€Ÿé–±é›»å­æ›¸                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    try:
        # åˆå§‹åŒ–å€Ÿé–±å™¨
        scraper = HyReadScraper(env_file=".env_hyread")
        
        # åŸ·è¡Œå€Ÿé–±æµç¨‹
        # headless=False: é¡¯ç¤ºç€è¦½å™¨è¦–çª—ï¼ˆæ–¹ä¾¿è§€å¯Ÿï¼‰
        # headless=True: ç„¡é ­æ¨¡å¼ï¼ˆé©åˆè‡ªå‹•åŒ–åŸ·è¡Œï¼‰
        # wait_time: æˆåŠŸå¾Œç­‰å¾…æ™‚é–“ï¼ˆç§’ï¼‰
        success = await scraper.run(
            headless=False, 
            slow_mo=100,
            wait_time=30
        )
        
        if success:
            print("\nâœ¨ å€Ÿé–±æµç¨‹å®Œæˆï¼")
            sys.exit(0)
        else:
            print("\nâš ï¸  å€Ÿé–±æµç¨‹æœªæˆåŠŸå®Œæˆ")
            sys.exit(1)
            
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        print("\nè«‹ç¢ºä¿ä»¥ä¸‹æª”æ¡ˆå­˜åœ¨ä¸¦åŒ…å«å¿…è¦çš„è¨­å®š:")
        print("   .env_hyread")
        sys.exit(1)
        
    except ImportError as e:
        print(f"\nâŒ å¥—ä»¶éŒ¯èª¤: {e}")
        sys.exit(1)
        
    except ValueError as e:
        print(f"\nâŒ è¨­å®šéŒ¯èª¤: {e}")
        sys.exit(1)
        
    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    # åŸ·è¡Œä¸»ç¨‹å¼
    asyncio.run(main())

